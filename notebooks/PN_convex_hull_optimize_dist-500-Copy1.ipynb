{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.1\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import artm\n",
    "import seaborn as sns\n",
    "print artm.version()\n",
    "\n",
    "from os import path, mkdir\n",
    "from datetime import datetime\n",
    "sys.path.insert(0, '..\\\\modules\\\\helpers')\n",
    "from plot_helper import PlotMaker\n",
    "from config_helper import ConfigPaths\n",
    "from print_helper import PrintHelper\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from numpy.linalg import norm as euclidean_norm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = ConfigPaths('config.cfg')\n",
    "plot_maker = PlotMaker()\n",
    "printer = PrintHelper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:\\\\topic_modeling\\\\csi_science_collections.git\\experiments\\UCI_filtered_ngramm_trimmed_without_names\\np_10_12_500_opt_dists\\models.txt\n"
     ]
    }
   ],
   "source": [
    "print config.models_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_file = open(config.models_file_name, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(current_dictionary, n_topics, n_doc_passes, seed_value, n_top_tokens, p_mass_threshold):    \n",
    "    print '[{}] creating model'.format(datetime.now())\n",
    "    model = artm.ARTM(num_topics=n_topics, dictionary=current_dictionary, cache_theta=True, seed=seed_value, \n",
    "                  class_ids={'ngramm': 1.0, 'author_id': 0.0, 'author': 0.0, \n",
    "                             'post_tag': 0.0, 'projects': 0.0, 'category': 0.0,\n",
    "                             'following_users': 0.0})\n",
    "    model.num_document_passes = n_doc_passes\n",
    "    add_scores_to_model(model, n_top_tokens=n_top_tokens, p_mass_threshold=p_mass_threshold)\n",
    "    return model\n",
    "\n",
    "\n",
    "def add_scores_to_model(artm_model, n_top_tokens, p_mass_threshold):\n",
    "    print '[{}] adding scores'.format(datetime.now())\n",
    "    artm_model.scores.add(artm.PerplexityScore(name='perplexity_score',\n",
    "                                      use_unigram_document_model=False,\n",
    "                                      dictionary=dictionary))\n",
    "    artm_model.scores.add(artm.SparsityPhiScore(name='sparsity_phi_score', class_id='ngramm'))\n",
    "    artm_model.scores.add(artm.SparsityThetaScore(name='sparsity_theta_score'))\n",
    "    artm_model.scores.add(artm.TopicKernelScore(name='topic_kernel_score', class_id='ngramm', \n",
    "                                                probability_mass_threshold=p_mass_threshold))\n",
    "    artm_model.scores.add(artm.TopTokensScore(name='top_tokens_score', class_id='ngramm', num_tokens=n_top_tokens))\n",
    "def fit_one_model(model, _n_iterations, _model_name=''): \n",
    "    print '[{}] fitting'.format(datetime.now())\n",
    "    model.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=_n_iterations)\n",
    "    print '[{}] outputting'.format(datetime.now())\n",
    "    printer.print_artm_model(model, _model_name, _n_iterations, output_file=models_file)\n",
    "    model_pics_file_name =  path.join(config.experiment_path, _model_name)\n",
    "    plot_maker.make_tm_plots(model, model_pics_file_name)\n",
    "    model_output_file_name = path.join(config.experiment_path, _model_name + '.txt')\n",
    "    printer.print_scores(model, _model_name, _n_iterations, model_output_file_name)\n",
    "    printer.print_top_tokens(model, model_output_file_name)\n",
    "    return model\n",
    "def save_pickle_file(dists, filename):\n",
    "    pickle_filename = path.join(config.experiment_path, filename)\n",
    "    pickle_file = open(pickle_filename, 'wb')\n",
    "    pickle.dump(dists, pickle_file)\n",
    "    pickle_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_vectorizer = artm.BatchVectorizer(data_path=config.output_batches_path,\n",
    "                                        data_format='batches')\n",
    "dictionary = artm.Dictionary()\n",
    "dictionary.load(dictionary_path=config.dictionary_path + '.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016-12-10 20:33:32.478000] creating model\n",
      "[2016-12-10 20:33:35.009000] adding scores\n",
      "[2016-12-10 20:33:35.036000] fitting\n",
      "[2016-12-10 20:36:52.445000] outputting\n",
      "name = model1, n_topics = 500, n_doc_passes = 5, seed_value = 100, n_iterations = 20, n_top_tokens = 15, p_threshold = 0.25\n",
      "ss_theta_regularizer, tau = -0.1\n",
      "decorrelator_phi_regularizer, tau = 100\n",
      "ss_phi_regularizer, tau = -0.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp_model = create_model(current_dictionary=dictionary, n_topics=500, n_doc_passes=5, seed_value=100,\n",
    "                            n_top_tokens=15, p_mass_threshold=0.25)\n",
    "tmp_model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_regularizer', class_ids=['ngramm']))\n",
    "tmp_model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='ss_theta_regularizer'))\n",
    "tmp_model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='ss_phi_regularizer', class_ids=['ngramm']))\n",
    "tmp_model.regularizers['decorrelator_phi_regularizer'].tau = 100\n",
    "tmp_model.regularizers['ss_theta_regularizer'].tau = -0.1\n",
    "tmp_model.regularizers['ss_phi_regularizer'].tau = -0.05\n",
    "tmp_model = fit_one_model(tmp_model, _n_iterations=20, _model_name='model1')\n",
    "model1 = tmp_model; tmp_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016-12-10 20:37:33.773000] creating model\n",
      "[2016-12-10 20:37:35.541000] adding scores\n",
      "[2016-12-10 20:37:35.552000] fitting\n",
      "[2016-12-10 20:37:54.947000] outputting\n",
      "name = model2, n_topics = 10, n_doc_passes = 5, seed_value = 100, n_iterations = 20, n_top_tokens = 15, p_threshold = 0.25\n",
      "ss_theta_regularizer, tau = -0.1\n",
      "decorrelator_phi_regularizer, tau = 100\n",
      "ss_phi_regularizer, tau = -0.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp_model = create_model(current_dictionary=dictionary, n_topics=10, n_doc_passes=5, seed_value=100,\n",
    "                            n_top_tokens=15, p_mass_threshold=0.25)\n",
    "tmp_model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_regularizer', class_ids=['ngramm']))\n",
    "tmp_model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='ss_theta_regularizer'))\n",
    "tmp_model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='ss_phi_regularizer', class_ids=['ngramm']))\n",
    "tmp_model.regularizers['decorrelator_phi_regularizer'].tau = 100\n",
    "tmp_model.regularizers['ss_theta_regularizer'].tau = -0.1\n",
    "tmp_model.regularizers['ss_phi_regularizer'].tau = -0.05\n",
    "tmp_model = fit_one_model(tmp_model, _n_iterations=20, _model_name='model2')\n",
    "model2 = tmp_model; tmp_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euc_dist(p, q):\n",
    "    return euclidean_norm(p - q)\n",
    "def euc_dist_grad(b, A, x):\n",
    "    x = x.reshape(-1, 1)\n",
    "    b = b.reshape(-1, 1)\n",
    "    norm = euc_dist(A.dot(x), b)\n",
    "    res = A.T.dot(A.dot(x) - b)\n",
    "    if norm != 0:\n",
    "        res = res / norm\n",
    "    return res\n",
    "def cos_dist(p, q):\n",
    "    p = p.reshape(-1, 1)\n",
    "    q = q.reshape(-1, 1)\n",
    "    return cosine_distances(p, q)[0][0]\n",
    "def cos_dist_grad(b, A, x):\n",
    "    x = x.reshape(-1, 1)\n",
    "    b = b.reshape(-1, 1)\n",
    "    y = A.dot(x)\n",
    "    u = b.T.dot(y) # number\n",
    "    deriv_u = A.T.dot(b) * x\n",
    "    v = euclidean_norm(y) * euclidean_norm(b)\n",
    "    nom = deriv_u * v - A.T.dot(A).dot(x) * u[0][0] * euclidean_norm(b) / euclidean_norm(y)\n",
    "    denom = v * v\n",
    "    if denom != 0:\n",
    "        res = nom / denom\n",
    "    else:\n",
    "        res = nom\n",
    "    return -res\n",
    "def hellinger_dist(p, q):\n",
    "    return np.sqrt(np.sum((np.sqrt(p) - np.sqrt(q)) ** 2)) / np.sqrt(2) \n",
    "def hellinger_dist_grad(b, A, x):\n",
    "    y = A.dot(x)\n",
    "    nom = np.divide(np.sqrt(y) - np.sqrt(b), np.sqrt(y)).dot(A)\n",
    "    denom = 2 * hellinger_dist(y, b) * np.sqrt(2)\n",
    "    res = nom / denom \n",
    "    return res\n",
    "def hellinger_dist_grad_nan(b, A, x):\n",
    "    y = A.dot(x)\n",
    "    tmp = np.divide(np.sqrt(y) - np.sqrt(b), np.sqrt(y))\n",
    "    tmp[np.isnan(tmp)] = 0\n",
    "    nom = tmp.dot(A)\n",
    "    denom = 2 * hellinger_dist(y, b) * np.sqrt(2)\n",
    "    res = nom / denom \n",
    "    return res\n",
    "def hellinger_dist_grad_eps(b, A, x):\n",
    "    y = A.dot(x)\n",
    "    y[y == 0] = 1e-3\n",
    "    tmp = np.divide(np.sqrt(y) - np.sqrt(b), np.sqrt(y))\n",
    "    nom = tmp.dot(A)\n",
    "    denom = 2 * hellinger_dist(y, b) * np.sqrt(2)\n",
    "    res = nom / denom \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_optimal_solution_eps(_sol):\n",
    "    _eps = 1e-2\n",
    "    x = _sol.x\n",
    "    c = _sol.column_names\n",
    "    x_mask = x >_eps\n",
    "    x_cut = x[x_mask]\n",
    "    c_cut = c[x_mask]\n",
    "    combination = ', '.join(['{} : {}'.format(c_cut[ind], x_cut[ind]) for ind in range(len(x_cut))])\n",
    "    print 'fun = {}, optimized = {}'.format(_sol.fun, _sol.success)\n",
    "    print '{}: {}'.format(_sol.optimized_column, combination)\n",
    "def print_optimal_solution(_sol, _distances=None, _saved_top_tokens=None):\n",
    "    x = _sol.x\n",
    "    c = _sol.column_names\n",
    "    sorted_x = sorted(zip(x, c), reverse=True)[0 : NUM_INDICES]\n",
    "    if _distances is not None:\n",
    "        combination = ', '.join(['{0} : {1:0.2f} [{2:0.2f}]'.format(item[1], item[0], _distances[_sol.optimized_column][item[1]]) for item in sorted_x])\n",
    "        combination += '\\n' + distances_to_str_row(_distances, _sol.optimized_column, _n_topics=NUM_INDICES)\n",
    "    else:\n",
    "        combination = ', '.join(['{0} : {1:0.2f}'.format(item[1], item[0]) for item in sorted_x])\n",
    "    print '============================'\n",
    "    print 'fun = {}, optimized = {}'.format(_sol.fun, _sol.success)\n",
    "    print '{} | {}'.format(_sol.optimized_column, combination)\n",
    "    if _saved_top_tokens is not None:\n",
    "        topics_str = optimal_solution_topics_to_str(_saved_top_tokens, _sol.optimized_column, sorted_x)\n",
    "        print topics_str\n",
    "    print '============================'\n",
    "def unicode_list_to_str(_name, _list):\n",
    "    return _name + ': ' + ' '.join(_list)\n",
    "def optimal_solution_topics_to_str(_saved_top_tokens, topic_name, sorted_x):\n",
    "    topics = [item[1] for item in sorted_x]\n",
    "    topics.insert(0, topic_name)\n",
    "    str = \"\"\n",
    "    for topic_name in topics:\n",
    "        str += unicode_list_to_str(topic_name, _saved_top_tokens[topic_name]) + '\\n'\n",
    "    return str\n",
    "def calculate_distances(dist_fun, _phi, _phi_other):\n",
    "    print '[{}] take_distances between {} columns and {} columns'.format(datetime.now(), len(_phi.columns), len(_phi_other.columns))\n",
    "    distances = pd.DataFrame(0, index = _phi.columns, columns=_phi_other.columns)\n",
    "    for idx, col in enumerate(_phi.columns):\n",
    "        print '[{}] column num {} of {}'.format(datetime.now(), idx, len(_phi.columns))\n",
    "        for idx_other, col_other in enumerate(_phi_other.columns):\n",
    "            distance = dist_fun(_phi[col], _phi_other[col_other])\n",
    "            distances.iloc[idx, idx_other] = distance\n",
    "    return distances\n",
    "def distances_to_str_row(distances, topic, _n_topics):\n",
    "    values = distances[topic].sort_values().head(_n_topics)\n",
    "    value = ', '.join(['{0} : [{1:0.2f}]'.format(values.index[ind], values[ind]) for ind in range(len(values))])\n",
    "    str = 'closest by distance to {} | {}\\n'.format(topic, value)\n",
    "    return str\n",
    "def calculate_distances_one_col(dist, phi, column): \n",
    "    distances = pd.DataFrame(0, index = range(1), columns=phi.columns)\n",
    "    for idx, col in enumerate(phi.columns):\n",
    "        distance = dist(column, phi[col])\n",
    "        distances.iloc[0, idx] = distance\n",
    "    return distances\n",
    "def get_optimization_result(dist_fn, jac_dist_fn, phi, distances):\n",
    "    opt_results = {}\n",
    "    for col_idx, col in enumerate(phi.columns):\n",
    "        print '[{}] get_optimization_result for column {}'.format(datetime.now(), col_idx)\n",
    "        opt_results[col] = solve_optimization_problem(dist_fn, jac_dist_fn, col_idx, phi, distances)\n",
    "    return opt_results\n",
    "def solve_optimization_problem(dist_fn, jac_dist_fn, col_idx, phi, distances, verbose=False):\n",
    "    max_iter = 50\n",
    "    col_name = phi.columns[col_idx]\n",
    "    col = phi[col_name]\n",
    "    # get n closest topics\n",
    "    closest_indices = distances[col_name].sort_values().head(N_CLOSEST_TOPICS).index.values\n",
    "    phi_closest = phi[closest_indices]\n",
    "    # delete zero rows from matrix\n",
    "    phi_closest_nz = phi_closest[(phi_closest.T != 0).any()]\n",
    "    col_nz = phi_closest_nz[col_name]\n",
    "    # delete col from phi\n",
    "    phi_cut_nz = phi_closest_nz.drop(col_name, axis=1)\n",
    "    \n",
    "    # opt solver\n",
    "    n_columns = phi_cut_nz.shape[1] \n",
    "    bnds = [(0, 1)] * n_columns\n",
    "    constraints = cons = ({'type': 'eq', 'fun': lambda x:  np.sum(x) - 1, 'jac': lambda x: [1] * n_columns})\n",
    "    opt_fun = lambda x: dist_fn(col_nz, phi_cut_nz.dot(x))\n",
    "    jac_fun = lambda x: jac_dist_fn(col_nz, phi_cut_nz, x)\n",
    "    \n",
    "    is_optimized = False\n",
    "    it = 0\n",
    "    while (not is_optimized) and it != 4:\n",
    "        it += 1\n",
    "        init_x = np.random.uniform(0, 1, (1, n_columns))\n",
    "        init_x /= np.sum(init_x)\n",
    "        if jac_dist_fn is not None:\n",
    "            res = minimize(opt_fun, jac=jac_fun, x0=init_x, method='SLSQP', bounds=bnds, constraints=cons, options={'maxiter': max_iter, 'disp': verbose})\n",
    "        else:\n",
    "            res = minimize(opt_fun, x0=init_x, method='SLSQP', bounds=bnds, constraints=cons, options={'maxiter': max_iter, 'disp': verbose})\n",
    "        is_optimized = res.success\n",
    "    res['column_names'] = phi_cut_nz.columns\n",
    "    res['optimized_column'] = col_name\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_CLOSEST_TOPICS = 25\n",
    "phi1 = model1.get_phi()\n",
    "phi1 = phi1[(phi1.T != 0).any()]\n",
    "saved_top_tokens1 = model1.score_tracker['top_tokens_score'].last_tokens\n",
    "phi = phi1\n",
    "saved_top_tokens = saved_top_tokens1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016-12-10 22:03:41.944000] calculating distances\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.860765081112\n",
      "            Iterations: 35\n",
      "            Function evaluations: 953\n",
      "            Gradient evaluations: 35\n"
     ]
    }
   ],
   "source": [
    "ds_zero_col = solve_optimization_problem(hellinger_dist, None, 0, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016-12-10 22:19:02.426000] caclulating dist for column 0\n",
      "[2016-12-10 22:19:04.127000] caclulating dist for column 1\n",
      "[2016-12-10 22:19:05.808000] caclulating dist for column 2\n",
      "[2016-12-10 22:19:07.510000] caclulating dist for column 3\n",
      "[2016-12-10 22:19:09.736000] caclulating dist for column 4\n",
      "[2016-12-10 22:19:11.102000] caclulating dist for column 5\n",
      "[2016-12-10 22:19:12.773000] caclulating dist for column 6\n",
      "[2016-12-10 22:19:14.360000] caclulating dist for column 7\n",
      "[2016-12-10 22:19:16.021000] caclulating dist for column 8\n",
      "[2016-12-10 22:19:17.855000] caclulating dist for column 9\n",
      "[2016-12-10 22:19:19.401000] caclulating dist for column 10\n",
      "[2016-12-10 22:19:21.006000] caclulating dist for column 11\n",
      "[2016-12-10 22:19:22.558000] caclulating dist for column 12\n",
      "[2016-12-10 22:19:24.311000] caclulating dist for column 13\n",
      "[2016-12-10 22:19:25.830000] caclulating dist for column 14\n",
      "[2016-12-10 22:19:27.430000] caclulating dist for column 15\n",
      "[2016-12-10 22:19:29.001000] caclulating dist for column 16\n",
      "[2016-12-10 22:19:30.663000] caclulating dist for column 17\n",
      "[2016-12-10 22:19:32.520000] caclulating dist for column 18\n",
      "[2016-12-10 22:19:34.874000] caclulating dist for column 19\n",
      "[2016-12-10 22:19:37.084000] caclulating dist for column 20\n",
      "[2016-12-10 22:19:39.592000] caclulating dist for column 21\n",
      "[2016-12-10 22:19:41.999000] caclulating dist for column 22\n",
      "[2016-12-10 22:19:43.745000] caclulating dist for column 23\n",
      "[2016-12-10 22:19:45.436000] caclulating dist for column 24\n",
      "[2016-12-10 22:19:46.923000] caclulating dist for column 25\n",
      "[2016-12-10 22:19:48.310000] caclulating dist for column 26\n",
      "[2016-12-10 22:19:49.845000] caclulating dist for column 27\n",
      "[2016-12-10 22:19:51.506000] caclulating dist for column 28\n",
      "[2016-12-10 22:19:53.618000] caclulating dist for column 29\n",
      "[2016-12-10 22:19:55.320000] caclulating dist for column 30\n",
      "[2016-12-10 22:19:56.955000] caclulating dist for column 31\n",
      "[2016-12-10 22:19:58.796000] caclulating dist for column 32\n",
      "[2016-12-10 22:20:00.582000] caclulating dist for column 33\n",
      "[2016-12-10 22:20:02.447000] caclulating dist for column 34\n",
      "[2016-12-10 22:20:03.933000] caclulating dist for column 35\n",
      "[2016-12-10 22:20:05.436000] caclulating dist for column 36\n",
      "[2016-12-10 22:20:07.226000] caclulating dist for column 37\n",
      "[2016-12-10 22:20:08.996000] caclulating dist for column 38\n",
      "[2016-12-10 22:20:11.250000] caclulating dist for column 39\n",
      "[2016-12-10 22:20:13.022000] caclulating dist for column 40\n",
      "[2016-12-10 22:20:14.988000] caclulating dist for column 41\n",
      "[2016-12-10 22:20:16.529000] caclulating dist for column 42\n",
      "[2016-12-10 22:20:18.063000] caclulating dist for column 43\n",
      "[2016-12-10 22:20:19.633000] caclulating dist for column 44\n",
      "[2016-12-10 22:20:21.114000] caclulating dist for column 45\n",
      "[2016-12-10 22:20:22.701000] caclulating dist for column 46\n",
      "[2016-12-10 22:20:24.799000] caclulating dist for column 47\n",
      "[2016-12-10 22:20:26.482000] caclulating dist for column 48\n",
      "[2016-12-10 22:20:28.032000] caclulating dist for column 49\n",
      "[2016-12-10 22:20:29.719000] caclulating dist for column 50\n",
      "[2016-12-10 22:20:31.336000] caclulating dist for column 51\n",
      "[2016-12-10 22:20:33.326000] caclulating dist for column 52\n",
      "[2016-12-10 22:20:34.844000] caclulating dist for column 53\n",
      "[2016-12-10 22:20:36.300000] caclulating dist for column 54\n",
      "[2016-12-10 22:20:37.934000] caclulating dist for column 55\n",
      "[2016-12-10 22:20:39.806000] caclulating dist for column 56\n",
      "[2016-12-10 22:20:41.992000] caclulating dist for column 57\n",
      "[2016-12-10 22:20:43.732000] caclulating dist for column 58\n",
      "[2016-12-10 22:20:45.513000] caclulating dist for column 59\n",
      "[2016-12-10 22:20:47.154000] caclulating dist for column 60\n",
      "[2016-12-10 22:20:48.994000] caclulating dist for column 61\n",
      "[2016-12-10 22:20:50.772000] caclulating dist for column 62\n",
      "[2016-12-10 22:20:53.090000] caclulating dist for column 63\n",
      "[2016-12-10 22:20:54.675000] caclulating dist for column 64\n",
      "[2016-12-10 22:20:56.762000] caclulating dist for column 65\n",
      "[2016-12-10 22:20:58.323000] caclulating dist for column 66\n",
      "[2016-12-10 22:21:00.045000] caclulating dist for column 67\n",
      "[2016-12-10 22:21:01.831000] caclulating dist for column 68\n",
      "[2016-12-10 22:21:03.331000] caclulating dist for column 69\n",
      "[2016-12-10 22:21:04.753000] caclulating dist for column 70\n",
      "[2016-12-10 22:21:06.371000] caclulating dist for column 71\n",
      "[2016-12-10 22:21:08.121000] caclulating dist for column 72\n",
      "[2016-12-10 22:21:09.743000] caclulating dist for column 73\n",
      "[2016-12-10 22:21:11.713000] caclulating dist for column 74\n",
      "[2016-12-10 22:21:13.434000] caclulating dist for column 75\n",
      "[2016-12-10 22:21:15.400000] caclulating dist for column 76\n",
      "[2016-12-10 22:21:16.906000] caclulating dist for column 77\n",
      "[2016-12-10 22:21:18.490000] caclulating dist for column 78\n",
      "[2016-12-10 22:21:20.313000] caclulating dist for column 79\n",
      "[2016-12-10 22:21:21.924000] caclulating dist for column 80\n",
      "[2016-12-10 22:21:23.657000] caclulating dist for column 81\n",
      "[2016-12-10 22:21:25.255000] caclulating dist for column 82\n",
      "[2016-12-10 22:21:27.143000] caclulating dist for column 83\n",
      "[2016-12-10 22:21:28.984000] caclulating dist for column 84\n",
      "[2016-12-10 22:21:30.603000] caclulating dist for column 85\n",
      "[2016-12-10 22:21:32.137000] caclulating dist for column 86\n",
      "[2016-12-10 22:21:33.810000] caclulating dist for column 87\n",
      "[2016-12-10 22:21:35.276000] caclulating dist for column 88\n",
      "[2016-12-10 22:21:36.915000] caclulating dist for column 89\n",
      "[2016-12-10 22:21:38.929000] caclulating dist for column 90\n",
      "[2016-12-10 22:21:40.521000] caclulating dist for column 91\n",
      "[2016-12-10 22:21:42.039000] caclulating dist for column 92\n",
      "[2016-12-10 22:21:43.607000] caclulating dist for column 93\n",
      "[2016-12-10 22:21:45.335000] caclulating dist for column 94\n",
      "[2016-12-10 22:21:46.932000] caclulating dist for column 95\n",
      "[2016-12-10 22:21:48.304000] caclulating dist for column 96\n",
      "[2016-12-10 22:21:49.937000] caclulating dist for column 97\n",
      "[2016-12-10 22:21:51.455000] caclulating dist for column 98\n",
      "[2016-12-10 22:21:53.291000] caclulating dist for column 99\n",
      "[2016-12-10 22:21:54.926000] caclulating dist for column 100\n",
      "[2016-12-10 22:21:56.437000] caclulating dist for column 101\n",
      "[2016-12-10 22:21:58.004000] caclulating dist for column 102\n",
      "[2016-12-10 22:21:59.641000] caclulating dist for column 103\n",
      "[2016-12-10 22:22:01.811000] caclulating dist for column 104\n",
      "[2016-12-10 22:22:03.213000] caclulating dist for column 105\n",
      "[2016-12-10 22:22:05.244000] caclulating dist for column 106\n",
      "[2016-12-10 22:22:07.357000] caclulating dist for column 107\n",
      "[2016-12-10 22:22:09.227000] caclulating dist for column 108\n",
      "[2016-12-10 22:22:11.046000] caclulating dist for column 109\n",
      "[2016-12-10 22:22:12.648000] caclulating dist for column 110\n",
      "[2016-12-10 22:22:14.367000] caclulating dist for column 111\n",
      "[2016-12-10 22:22:16.047000] caclulating dist for column 112\n",
      "[2016-12-10 22:22:17.748000] caclulating dist for column 113\n",
      "[2016-12-10 22:22:19.624000] caclulating dist for column 114\n",
      "[2016-12-10 22:22:22.113000] caclulating dist for column 115\n",
      "[2016-12-10 22:22:24.182000] caclulating dist for column 116\n",
      "[2016-12-10 22:22:25.871000] caclulating dist for column 117\n",
      "[2016-12-10 22:22:27.687000] caclulating dist for column 118\n",
      "[2016-12-10 22:22:29.481000] caclulating dist for column 119\n",
      "[2016-12-10 22:22:31.134000] caclulating dist for column 120\n",
      "[2016-12-10 22:22:32.903000] caclulating dist for column 121\n",
      "[2016-12-10 22:22:34.671000] caclulating dist for column 122\n",
      "[2016-12-10 22:22:36.274000] caclulating dist for column 123\n",
      "[2016-12-10 22:22:38.009000] caclulating dist for column 124\n",
      "[2016-12-10 22:22:39.791000] caclulating dist for column 125\n",
      "[2016-12-10 22:22:41.599000] caclulating dist for column 126\n",
      "[2016-12-10 22:22:43.318000] caclulating dist for column 127\n",
      "[2016-12-10 22:22:45.184000] caclulating dist for column 128\n",
      "[2016-12-10 22:22:47.386000] caclulating dist for column 129\n",
      "[2016-12-10 22:22:48.957000] caclulating dist for column 130\n",
      "[2016-12-10 22:22:50.576000] caclulating dist for column 131\n",
      "[2016-12-10 22:22:52.477000] caclulating dist for column 132\n",
      "[2016-12-10 22:22:54.164000] caclulating dist for column 133\n",
      "[2016-12-10 22:22:55.963000] caclulating dist for column 134\n",
      "[2016-12-10 22:22:57.429000] caclulating dist for column 135\n",
      "[2016-12-10 22:22:59.206000] caclulating dist for column 136\n",
      "[2016-12-10 22:23:01.647000] caclulating dist for column 137\n",
      "[2016-12-10 22:23:03.690000] caclulating dist for column 138\n",
      "[2016-12-10 22:23:05.508000] caclulating dist for column 139\n",
      "[2016-12-10 22:23:07.142000] caclulating dist for column 140\n",
      "[2016-12-10 22:23:09.015000] caclulating dist for column 141\n",
      "[2016-12-10 22:23:10.748000] caclulating dist for column 142\n",
      "[2016-12-10 22:23:12.934000] caclulating dist for column 143\n",
      "[2016-12-10 22:23:14.603000] caclulating dist for column 144\n",
      "[2016-12-10 22:23:16.336000] caclulating dist for column 145\n",
      "[2016-12-10 22:23:18.321000] caclulating dist for column 146\n",
      "[2016-12-10 22:23:20.630000] caclulating dist for column 147\n",
      "[2016-12-10 22:23:22.324000] caclulating dist for column 148\n",
      "[2016-12-10 22:23:23.941000] caclulating dist for column 149\n",
      "[2016-12-10 22:23:25.837000] caclulating dist for column 150\n",
      "[2016-12-10 22:23:27.544000] caclulating dist for column 151\n",
      "[2016-12-10 22:23:29.144000] caclulating dist for column 152\n",
      "[2016-12-10 22:23:30.977000] caclulating dist for column 153\n",
      "[2016-12-10 22:23:33.563000] caclulating dist for column 154\n",
      "[2016-12-10 22:23:35.568000] caclulating dist for column 155\n",
      "[2016-12-10 22:23:37.433000] caclulating dist for column 156\n",
      "[2016-12-10 22:23:39.049000] caclulating dist for column 157\n",
      "[2016-12-10 22:23:41.112000] caclulating dist for column 158\n",
      "[2016-12-10 22:23:42.973000] caclulating dist for column 159\n",
      "[2016-12-10 22:23:44.605000] caclulating dist for column 160\n",
      "[2016-12-10 22:23:46.650000] caclulating dist for column 161\n",
      "[2016-12-10 22:23:48.316000] caclulating dist for column 162\n",
      "[2016-12-10 22:23:49.980000] caclulating dist for column 163\n",
      "[2016-12-10 22:23:51.596000] caclulating dist for column 164\n",
      "[2016-12-10 22:23:53.496000] caclulating dist for column 165\n",
      "[2016-12-10 22:23:55.130000] caclulating dist for column 166\n",
      "[2016-12-10 22:23:56.917000] caclulating dist for column 167\n",
      "[2016-12-10 22:23:58.681000] caclulating dist for column 168\n",
      "[2016-12-10 22:24:00.337000] caclulating dist for column 169\n",
      "[2016-12-10 22:24:02.173000] caclulating dist for column 170\n",
      "[2016-12-10 22:24:03.693000] caclulating dist for column 171\n",
      "[2016-12-10 22:24:05.976000] caclulating dist for column 172\n",
      "[2016-12-10 22:24:07.824000] caclulating dist for column 173\n",
      "[2016-12-10 22:24:09.932000] caclulating dist for column 174\n",
      "[2016-12-10 22:24:11.387000] caclulating dist for column 175\n",
      "[2016-12-10 22:24:13.281000] caclulating dist for column 176\n",
      "[2016-12-10 22:24:15.054000] caclulating dist for column 177\n",
      "[2016-12-10 22:24:17.026000] caclulating dist for column 178\n",
      "[2016-12-10 22:24:18.512000] caclulating dist for column 179\n",
      "[2016-12-10 22:24:20.131000] caclulating dist for column 180\n",
      "[2016-12-10 22:24:21.833000] caclulating dist for column 181\n",
      "[2016-12-10 22:24:23.882000] caclulating dist for column 182\n",
      "[2016-12-10 22:24:25.534000] caclulating dist for column 183\n",
      "[2016-12-10 22:24:27.749000] caclulating dist for column 184\n",
      "[2016-12-10 22:24:29.599000] caclulating dist for column 185\n",
      "[2016-12-10 22:24:31.401000] caclulating dist for column 186\n",
      "[2016-12-10 22:24:32.769000] caclulating dist for column 187\n",
      "[2016-12-10 22:24:34.487000] caclulating dist for column 188\n",
      "[2016-12-10 22:24:36.089000] caclulating dist for column 189\n",
      "[2016-12-10 22:24:37.442000] caclulating dist for column 190\n",
      "[2016-12-10 22:24:39.260000] caclulating dist for column 191\n",
      "[2016-12-10 22:24:40.778000] caclulating dist for column 192\n",
      "[2016-12-10 22:24:42.915000] caclulating dist for column 193\n",
      "[2016-12-10 22:24:45.721000] caclulating dist for column 194\n",
      "[2016-12-10 22:24:47.238000] caclulating dist for column 195\n",
      "[2016-12-10 22:24:49.052000] caclulating dist for column 196\n",
      "[2016-12-10 22:24:50.983000] caclulating dist for column 197\n",
      "[2016-12-10 22:24:53.258000] caclulating dist for column 198\n",
      "[2016-12-10 22:24:55.260000] caclulating dist for column 199\n",
      "[2016-12-10 22:24:56.816000] caclulating dist for column 200\n",
      "[2016-12-10 22:24:58.416000] caclulating dist for column 201\n",
      "[2016-12-10 22:25:00.523000] caclulating dist for column 202\n",
      "[2016-12-10 22:25:02.364000] caclulating dist for column 203\n",
      "[2016-12-10 22:25:04.421000] caclulating dist for column 204\n",
      "[2016-12-10 22:25:06.204000] caclulating dist for column 205\n",
      "[2016-12-10 22:25:08.060000] caclulating dist for column 206\n",
      "[2016-12-10 22:25:10.071000] caclulating dist for column 207\n",
      "[2016-12-10 22:25:11.743000] caclulating dist for column 208\n",
      "[2016-12-10 22:25:14.001000] caclulating dist for column 209\n",
      "[2016-12-10 22:25:15.538000] caclulating dist for column 210\n",
      "[2016-12-10 22:25:17.087000] caclulating dist for column 211\n",
      "[2016-12-10 22:25:18.528000] caclulating dist for column 212\n",
      "[2016-12-10 22:25:20.093000] caclulating dist for column 213\n",
      "[2016-12-10 22:25:22.066000] caclulating dist for column 214\n",
      "[2016-12-10 22:25:24.763000] caclulating dist for column 215\n",
      "[2016-12-10 22:25:26.319000] caclulating dist for column 216\n",
      "[2016-12-10 22:25:27.984000] caclulating dist for column 217\n",
      "[2016-12-10 22:25:30.616000] caclulating dist for column 218\n",
      "[2016-12-10 22:25:32.272000] caclulating dist for column 219\n",
      "[2016-12-10 22:25:33.908000] caclulating dist for column 220\n",
      "[2016-12-10 22:25:35.574000] caclulating dist for column 221\n",
      "[2016-12-10 22:25:37.590000] caclulating dist for column 222\n",
      "[2016-12-10 22:25:39.152000] caclulating dist for column 223\n",
      "[2016-12-10 22:25:40.804000] caclulating dist for column 224\n",
      "[2016-12-10 22:25:42.389000] caclulating dist for column 225\n",
      "[2016-12-10 22:25:44.215000] caclulating dist for column 226\n",
      "[2016-12-10 22:25:46.224000] caclulating dist for column 227\n",
      "[2016-12-10 22:25:47.858000] caclulating dist for column 228\n",
      "[2016-12-10 22:25:49.406000] caclulating dist for column 229\n",
      "[2016-12-10 22:25:51.208000] caclulating dist for column 230\n",
      "[2016-12-10 22:25:52.987000] caclulating dist for column 231\n",
      "[2016-12-10 22:25:54.570000] caclulating dist for column 232\n",
      "[2016-12-10 22:25:56.442000] caclulating dist for column 233\n",
      "[2016-12-10 22:25:58.290000] caclulating dist for column 234\n",
      "[2016-12-10 22:25:59.959000] caclulating dist for column 235\n",
      "[2016-12-10 22:26:01.512000] caclulating dist for column 236\n",
      "[2016-12-10 22:26:03.101000] caclulating dist for column 237\n",
      "[2016-12-10 22:26:04.741000] caclulating dist for column 238\n",
      "[2016-12-10 22:26:06.430000] caclulating dist for column 239\n",
      "[2016-12-10 22:26:08.080000] caclulating dist for column 240\n",
      "[2016-12-10 22:26:09.710000] caclulating dist for column 241\n",
      "[2016-12-10 22:26:11.445000] caclulating dist for column 242\n",
      "[2016-12-10 22:26:12.989000] caclulating dist for column 243\n",
      "[2016-12-10 22:26:14.550000] caclulating dist for column 244\n",
      "[2016-12-10 22:26:16.406000] caclulating dist for column 245\n",
      "[2016-12-10 22:26:18.140000] caclulating dist for column 246\n",
      "[2016-12-10 22:26:19.791000] caclulating dist for column 247\n",
      "[2016-12-10 22:26:21.476000] caclulating dist for column 248\n",
      "[2016-12-10 22:26:23.465000] caclulating dist for column 249\n",
      "[2016-12-10 22:26:25.067000] caclulating dist for column 250\n",
      "[2016-12-10 22:26:26.908000] caclulating dist for column 251\n",
      "[2016-12-10 22:26:28.490000] caclulating dist for column 252\n",
      "[2016-12-10 22:26:30.940000] caclulating dist for column 253\n",
      "[2016-12-10 22:26:32.849000] caclulating dist for column 254\n",
      "[2016-12-10 22:26:34.733000] caclulating dist for column 255\n",
      "[2016-12-10 22:26:37.118000] caclulating dist for column 256\n",
      "[2016-12-10 22:26:39.010000] caclulating dist for column 257\n",
      "[2016-12-10 22:26:40.977000] caclulating dist for column 258\n",
      "[2016-12-10 22:26:42.708000] caclulating dist for column 259\n",
      "[2016-12-10 22:26:44.395000] caclulating dist for column 260\n",
      "[2016-12-10 22:26:46.467000] caclulating dist for column 261\n",
      "[2016-12-10 22:26:48.686000] caclulating dist for column 262\n",
      "[2016-12-10 22:26:51.002000] caclulating dist for column 263\n",
      "[2016-12-10 22:26:52.857000] caclulating dist for column 264\n",
      "[2016-12-10 22:26:54.456000] caclulating dist for column 265\n",
      "[2016-12-10 22:26:56.201000] caclulating dist for column 266\n",
      "[2016-12-10 22:26:58.225000] caclulating dist for column 267\n",
      "[2016-12-10 22:27:00.012000] caclulating dist for column 268\n",
      "[2016-12-10 22:27:01.888000] caclulating dist for column 269\n",
      "[2016-12-10 22:27:03.587000] caclulating dist for column 270\n",
      "[2016-12-10 22:27:05.300000] caclulating dist for column 271\n",
      "[2016-12-10 22:27:07.050000] caclulating dist for column 272\n",
      "[2016-12-10 22:27:08.856000] caclulating dist for column 273\n",
      "[2016-12-10 22:27:10.712000] caclulating dist for column 274\n",
      "[2016-12-10 22:27:12.381000] caclulating dist for column 275\n",
      "[2016-12-10 22:27:13.888000] caclulating dist for column 276\n",
      "[2016-12-10 22:27:15.589000] caclulating dist for column 277\n",
      "[2016-12-10 22:27:17.411000] caclulating dist for column 278\n",
      "[2016-12-10 22:27:19.345000] caclulating dist for column 279\n",
      "[2016-12-10 22:27:21.064000] caclulating dist for column 280\n",
      "[2016-12-10 22:27:23.071000] caclulating dist for column 281\n",
      "[2016-12-10 22:27:24.690000] caclulating dist for column 282\n",
      "[2016-12-10 22:27:26.407000] caclulating dist for column 283\n",
      "[2016-12-10 22:27:28.356000] caclulating dist for column 284\n",
      "[2016-12-10 22:27:30.029000] caclulating dist for column 285\n",
      "[2016-12-10 22:27:31.695000] caclulating dist for column 286\n",
      "[2016-12-10 22:27:33.567000] caclulating dist for column 287\n",
      "[2016-12-10 22:27:34.984000] caclulating dist for column 288\n",
      "[2016-12-10 22:27:36.741000] caclulating dist for column 289\n",
      "[2016-12-10 22:27:38.776000] caclulating dist for column 290\n",
      "[2016-12-10 22:27:40.443000] caclulating dist for column 291\n",
      "[2016-12-10 22:27:42.197000] caclulating dist for column 292\n",
      "[2016-12-10 22:27:43.996000] caclulating dist for column 293\n",
      "[2016-12-10 22:27:45.657000] caclulating dist for column 294\n",
      "[2016-12-10 22:27:47.527000] caclulating dist for column 295\n",
      "[2016-12-10 22:27:49.787000] caclulating dist for column 296\n",
      "[2016-12-10 22:27:51.455000] caclulating dist for column 297\n",
      "[2016-12-10 22:27:52.997000] caclulating dist for column 298\n",
      "[2016-12-10 22:27:54.610000] caclulating dist for column 299\n",
      "[2016-12-10 22:27:56.348000] caclulating dist for column 300\n",
      "[2016-12-10 22:27:58.230000] caclulating dist for column 301\n",
      "[2016-12-10 22:28:00.166000] caclulating dist for column 302\n",
      "[2016-12-10 22:28:01.816000] caclulating dist for column 303\n",
      "[2016-12-10 22:28:03.703000] caclulating dist for column 304\n",
      "[2016-12-10 22:28:05.259000] caclulating dist for column 305\n",
      "[2016-12-10 22:28:06.909000] caclulating dist for column 306\n",
      "[2016-12-10 22:28:08.713000] caclulating dist for column 307\n",
      "[2016-12-10 22:28:10.468000] caclulating dist for column 308\n",
      "[2016-12-10 22:28:12.218000] caclulating dist for column 309\n",
      "[2016-12-10 22:28:14.090000] caclulating dist for column 310\n",
      "[2016-12-10 22:28:15.741000] caclulating dist for column 311\n",
      "[2016-12-10 22:28:17.297000] caclulating dist for column 312\n",
      "[2016-12-10 22:28:18.953000] caclulating dist for column 313\n",
      "[2016-12-10 22:28:20.533000] caclulating dist for column 314\n",
      "[2016-12-10 22:28:22.136000] caclulating dist for column 315\n",
      "[2016-12-10 22:28:23.783000] caclulating dist for column 316\n",
      "[2016-12-10 22:28:25.446000] caclulating dist for column 317\n",
      "[2016-12-10 22:28:26.881000] caclulating dist for column 318\n",
      "[2016-12-10 22:28:28.552000] caclulating dist for column 319\n",
      "[2016-12-10 22:28:30.224000] caclulating dist for column 320\n",
      "[2016-12-10 22:28:31.804000] caclulating dist for column 321\n",
      "[2016-12-10 22:28:33.397000] caclulating dist for column 322\n",
      "[2016-12-10 22:28:35.017000] caclulating dist for column 323\n",
      "[2016-12-10 22:28:36.631000] caclulating dist for column 324\n",
      "[2016-12-10 22:28:38.384000] caclulating dist for column 325\n",
      "[2016-12-10 22:28:40.187000] caclulating dist for column 326\n",
      "[2016-12-10 22:28:41.959000] caclulating dist for column 327\n",
      "[2016-12-10 22:28:44.115000] caclulating dist for column 328\n",
      "[2016-12-10 22:28:45.803000] caclulating dist for column 329\n",
      "[2016-12-10 22:28:47.352000] caclulating dist for column 330\n",
      "[2016-12-10 22:28:49.067000] caclulating dist for column 331\n",
      "[2016-12-10 22:28:50.901000] caclulating dist for column 332\n",
      "[2016-12-10 22:28:52.796000] caclulating dist for column 333\n",
      "[2016-12-10 22:28:54.657000] caclulating dist for column 334\n",
      "[2016-12-10 22:28:56.409000] caclulating dist for column 335\n",
      "[2016-12-10 22:28:58.147000] caclulating dist for column 336\n",
      "[2016-12-10 22:28:59.797000] caclulating dist for column 337\n",
      "[2016-12-10 22:29:01.453000] caclulating dist for column 338\n",
      "[2016-12-10 22:29:03.556000] caclulating dist for column 339\n",
      "[2016-12-10 22:29:05.259000] caclulating dist for column 340\n",
      "[2016-12-10 22:29:06.994000] caclulating dist for column 341\n",
      "[2016-12-10 22:29:08.766000] caclulating dist for column 342\n",
      "[2016-12-10 22:29:10.561000] caclulating dist for column 343\n",
      "[2016-12-10 22:29:12.058000] caclulating dist for column 344\n",
      "[2016-12-10 22:29:13.698000] caclulating dist for column 345\n",
      "[2016-12-10 22:29:15.498000] caclulating dist for column 346\n",
      "[2016-12-10 22:29:17.318000] caclulating dist for column 347\n",
      "[2016-12-10 22:29:18.985000] caclulating dist for column 348\n",
      "[2016-12-10 22:29:21.729000] caclulating dist for column 349\n",
      "[2016-12-10 22:29:23.347000] caclulating dist for column 350\n",
      "[2016-12-10 22:29:25.189000] caclulating dist for column 351\n",
      "[2016-12-10 22:29:26.776000] caclulating dist for column 352\n",
      "[2016-12-10 22:29:28.279000] caclulating dist for column 353\n",
      "[2016-12-10 22:29:29.880000] caclulating dist for column 354\n",
      "[2016-12-10 22:29:31.560000] caclulating dist for column 355\n",
      "[2016-12-10 22:29:33.465000] caclulating dist for column 356\n",
      "[2016-12-10 22:29:35.521000] caclulating dist for column 357\n",
      "[2016-12-10 22:29:37.170000] caclulating dist for column 358\n",
      "[2016-12-10 22:29:39.947000] caclulating dist for column 359\n",
      "[2016-12-10 22:29:42.010000] caclulating dist for column 360\n",
      "[2016-12-10 22:29:43.745000] caclulating dist for column 361\n",
      "[2016-12-10 22:29:45.362000] caclulating dist for column 362\n",
      "[2016-12-10 22:29:47.233000] caclulating dist for column 363\n",
      "[2016-12-10 22:29:49.352000] caclulating dist for column 364\n",
      "[2016-12-10 22:29:50.871000] caclulating dist for column 365\n",
      "[2016-12-10 22:29:53.405000] caclulating dist for column 366\n",
      "[2016-12-10 22:29:54.962000] caclulating dist for column 367\n",
      "[2016-12-10 22:29:56.611000] caclulating dist for column 368\n",
      "[2016-12-10 22:29:58.271000] caclulating dist for column 369\n",
      "[2016-12-10 22:29:59.926000] caclulating dist for column 370\n",
      "[2016-12-10 22:30:01.629000] caclulating dist for column 371\n",
      "[2016-12-10 22:30:03.348000] caclulating dist for column 372\n",
      "[2016-12-10 22:30:05.368000] caclulating dist for column 373\n",
      "[2016-12-10 22:30:07.475000] caclulating dist for column 374\n",
      "[2016-12-10 22:30:09.111000] caclulating dist for column 375\n",
      "[2016-12-10 22:30:10.760000] caclulating dist for column 376\n",
      "[2016-12-10 22:30:12.567000] caclulating dist for column 377\n",
      "[2016-12-10 22:30:14.185000] caclulating dist for column 378\n",
      "[2016-12-10 22:30:15.877000] caclulating dist for column 379\n",
      "[2016-12-10 22:30:17.767000] caclulating dist for column 380\n",
      "[2016-12-10 22:30:19.286000] caclulating dist for column 381\n",
      "[2016-12-10 22:30:21.040000] caclulating dist for column 382\n",
      "[2016-12-10 22:30:22.596000] caclulating dist for column 383\n",
      "[2016-12-10 22:30:24.845000] caclulating dist for column 384\n",
      "[2016-12-10 22:30:26.429000] caclulating dist for column 385\n",
      "[2016-12-10 22:30:28.183000] caclulating dist for column 386\n",
      "[2016-12-10 22:30:29.918000] caclulating dist for column 387\n",
      "[2016-12-10 22:30:31.504000] caclulating dist for column 388\n",
      "[2016-12-10 22:30:33.270000] caclulating dist for column 389\n",
      "[2016-12-10 22:30:35.023000] caclulating dist for column 390\n",
      "[2016-12-10 22:30:36.532000] caclulating dist for column 391\n",
      "[2016-12-10 22:30:37.950000] caclulating dist for column 392\n",
      "[2016-12-10 22:30:39.500000] caclulating dist for column 393\n",
      "[2016-12-10 22:30:41.098000] caclulating dist for column 394\n",
      "[2016-12-10 22:30:42.747000] caclulating dist for column 395\n",
      "[2016-12-10 22:30:44.414000] caclulating dist for column 396\n",
      "[2016-12-10 22:30:46.149000] caclulating dist for column 397\n",
      "[2016-12-10 22:30:47.839000] caclulating dist for column 398\n",
      "[2016-12-10 22:30:49.572000] caclulating dist for column 399\n",
      "[2016-12-10 22:30:51.585000] caclulating dist for column 400\n",
      "[2016-12-10 22:30:53.155000] caclulating dist for column 401\n",
      "[2016-12-10 22:30:55.043000] caclulating dist for column 402\n",
      "[2016-12-10 22:30:56.646000] caclulating dist for column 403\n",
      "[2016-12-10 22:30:58.395000] caclulating dist for column 404\n",
      "[2016-12-10 22:31:00.136000] caclulating dist for column 405\n",
      "[2016-12-10 22:31:01.787000] caclulating dist for column 406\n",
      "[2016-12-10 22:31:03.414000] caclulating dist for column 407\n",
      "[2016-12-10 22:31:05.216000] caclulating dist for column 408\n",
      "[2016-12-10 22:31:06.919000] caclulating dist for column 409\n",
      "[2016-12-10 22:31:08.707000] caclulating dist for column 410\n",
      "[2016-12-10 22:31:10.448000] caclulating dist for column 411\n",
      "[2016-12-10 22:31:11.978000] caclulating dist for column 412\n",
      "[2016-12-10 22:31:13.749000] caclulating dist for column 413\n",
      "[2016-12-10 22:31:15.606000] caclulating dist for column 414\n",
      "[2016-12-10 22:31:17.360000] caclulating dist for column 415\n",
      "[2016-12-10 22:31:19.531000] caclulating dist for column 416\n",
      "[2016-12-10 22:31:21.269000] caclulating dist for column 417\n",
      "[2016-12-10 22:31:22.854000] caclulating dist for column 418\n",
      "[2016-12-10 22:31:24.305000] caclulating dist for column 419\n",
      "[2016-12-10 22:31:26.193000] caclulating dist for column 420\n",
      "[2016-12-10 22:31:27.916000] caclulating dist for column 421\n",
      "[2016-12-10 22:31:29.534000] caclulating dist for column 422\n",
      "[2016-12-10 22:31:30.954000] caclulating dist for column 423\n",
      "[2016-12-10 22:31:32.524000] caclulating dist for column 424\n",
      "[2016-12-10 22:31:34.243000] caclulating dist for column 425\n",
      "[2016-12-10 22:31:36.208000] caclulating dist for column 426\n",
      "[2016-12-10 22:31:37.909000] caclulating dist for column 427\n",
      "[2016-12-10 22:31:39.435000] caclulating dist for column 428\n",
      "[2016-12-10 22:31:41.078000] caclulating dist for column 429\n",
      "[2016-12-10 22:31:42.663000] caclulating dist for column 430\n",
      "[2016-12-10 22:31:44.181000] caclulating dist for column 431\n",
      "[2016-12-10 22:31:45.880000] caclulating dist for column 432\n",
      "[2016-12-10 22:31:47.529000] caclulating dist for column 433\n",
      "[2016-12-10 22:31:49.280000] caclulating dist for column 434\n",
      "[2016-12-10 22:31:50.925000] caclulating dist for column 435\n",
      "[2016-12-10 22:31:52.557000] caclulating dist for column 436\n",
      "[2016-12-10 22:31:54.308000] caclulating dist for column 437\n",
      "[2016-12-10 22:31:55.863000] caclulating dist for column 438\n",
      "[2016-12-10 22:31:57.484000] caclulating dist for column 439\n",
      "[2016-12-10 22:31:59.431000] caclulating dist for column 440\n",
      "[2016-12-10 22:32:01.149000] caclulating dist for column 441\n",
      "[2016-12-10 22:32:02.768000] caclulating dist for column 442\n",
      "[2016-12-10 22:32:04.609000] caclulating dist for column 443\n",
      "[2016-12-10 22:32:06.290000] caclulating dist for column 444\n",
      "[2016-12-10 22:32:09.015000] caclulating dist for column 445\n",
      "[2016-12-10 22:32:10.705000] caclulating dist for column 446\n",
      "[2016-12-10 22:32:12.391000] caclulating dist for column 447\n",
      "[2016-12-10 22:32:14.063000] caclulating dist for column 448\n",
      "[2016-12-10 22:32:15.866000] caclulating dist for column 449\n",
      "[2016-12-10 22:32:17.467000] caclulating dist for column 450\n",
      "[2016-12-10 22:32:19.272000] caclulating dist for column 451\n",
      "[2016-12-10 22:32:20.936000] caclulating dist for column 452\n",
      "[2016-12-10 22:32:22.476000] caclulating dist for column 453\n",
      "[2016-12-10 22:32:24.179000] caclulating dist for column 454\n",
      "[2016-12-10 22:32:26.207000] caclulating dist for column 455\n",
      "[2016-12-10 22:32:27.993000] caclulating dist for column 456\n",
      "[2016-12-10 22:32:29.722000] caclulating dist for column 457\n",
      "[2016-12-10 22:32:31.290000] caclulating dist for column 458\n",
      "[2016-12-10 22:32:33.239000] caclulating dist for column 459\n",
      "[2016-12-10 22:32:34.909000] caclulating dist for column 460\n",
      "[2016-12-10 22:32:36.674000] caclulating dist for column 461\n",
      "[2016-12-10 22:32:38.747000] caclulating dist for column 462\n",
      "[2016-12-10 22:32:40.264000] caclulating dist for column 463\n",
      "[2016-12-10 22:32:42.035000] caclulating dist for column 464\n",
      "[2016-12-10 22:32:44.153000] caclulating dist for column 465\n",
      "[2016-12-10 22:32:45.970000] caclulating dist for column 466\n",
      "[2016-12-10 22:32:47.687000] caclulating dist for column 467\n",
      "[2016-12-10 22:32:49.388000] caclulating dist for column 468\n",
      "[2016-12-10 22:32:51.075000] caclulating dist for column 469\n",
      "[2016-12-10 22:32:52.994000] caclulating dist for column 470\n",
      "[2016-12-10 22:32:55.265000] caclulating dist for column 471\n",
      "[2016-12-10 22:32:56.982000] caclulating dist for column 472\n",
      "[2016-12-10 22:32:59.499000] caclulating dist for column 473\n",
      "[2016-12-10 22:33:01.567000] caclulating dist for column 474\n",
      "[2016-12-10 22:33:03.824000] caclulating dist for column 475\n",
      "[2016-12-10 22:33:05.634000] caclulating dist for column 476\n",
      "[2016-12-10 22:33:07.803000] caclulating dist for column 477\n",
      "[2016-12-10 22:33:09.751000] caclulating dist for column 478\n",
      "[2016-12-10 22:33:11.512000] caclulating dist for column 479\n",
      "[2016-12-10 22:33:13.395000] caclulating dist for column 480\n",
      "[2016-12-10 22:33:15.597000] caclulating dist for column 481\n",
      "[2016-12-10 22:33:17.726000] caclulating dist for column 482\n",
      "[2016-12-10 22:33:20.014000] caclulating dist for column 483\n",
      "[2016-12-10 22:33:21.974000] caclulating dist for column 484\n",
      "[2016-12-10 22:33:23.899000] caclulating dist for column 485\n",
      "[2016-12-10 22:33:26.275000] caclulating dist for column 486\n",
      "[2016-12-10 22:33:28.047000] caclulating dist for column 487\n",
      "[2016-12-10 22:33:29.820000] caclulating dist for column 488\n",
      "[2016-12-10 22:33:31.489000] caclulating dist for column 489\n",
      "[2016-12-10 22:33:33.795000] caclulating dist for column 490\n",
      "[2016-12-10 22:33:36.034000] caclulating dist for column 491\n",
      "[2016-12-10 22:33:38.484000] caclulating dist for column 492\n",
      "[2016-12-10 22:33:40.842000] caclulating dist for column 493\n",
      "[2016-12-10 22:33:42.724000] caclulating dist for column 494\n",
      "[2016-12-10 22:33:44.848000] caclulating dist for column 495\n",
      "[2016-12-10 22:33:46.606000] caclulating dist for column 496\n",
      "[2016-12-10 22:33:48.215000] caclulating dist for column 497\n",
      "[2016-12-10 22:33:49.915000] caclulating dist for column 498\n",
      "[2016-12-10 22:33:51.686000] caclulating dist for column 499\n"
     ]
    }
   ],
   "source": [
    "distances = calculate_distances(hellinger_dist, phi, phi)\n",
    "ds = get_optimization_result(hellinger_dist, None, phi, distances)\n",
    "save_pickle_file(ds, 'dists_h_none.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x31977978>"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFoCAYAAADZ17inAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRESKUlgQERGRohQWREREpKj/H/S+JpOiLxm5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x254e1be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#    distances\n",
    "vals = distances.values.flatten()\n",
    "sns.distplot(vals[vals != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#    opt_fun "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27ca92b0>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFoCAYAAADZ17inAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQEksAAAlsQAAlMQCAFASCwBA6Qb24WM1HyIaHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27c30f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fs = [ds[col].fun for col in phi.columns]\n",
    "sns.distplot(fs, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#   ,  < 0.76  > 0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 8\n"
     ]
    }
   ],
   "source": [
    "low_th, high_th = 0.76, 0.89\n",
    "small_dist_opts = {col: ds[col] for col in phi.columns if ds[col].fun < low_th}\n",
    "large_dist_opts = {col: ds[col] for col in phi.columns if ds[col].fun > high_th}\n",
    "print len(small_dist_opts), len(large_dist_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.709351444397, optimized = True\n",
      "topic_57 | topic_145 : 0.53, topic_498 : 0.17, topic_177 : 0.08, topic_80 : 0.05, topic_399 : 0.04\n",
      "============================\n",
      "============================\n",
      "fun = 0.738238209879, optimized = True\n",
      "topic_38 | topic_58 : 0.31, topic_359 : 0.26, topic_346 : 0.06, topic_161 : 0.06, topic_379 : 0.05\n",
      "============================\n",
      "============================\n",
      "fun = 0.743417370783, optimized = True\n",
      "topic_373 | topic_67 : 0.10, topic_178 : 0.10, topic_284 : 0.10, topic_136 : 0.10, topic_51 : 0.07\n",
      "============================\n",
      "============================\n",
      "fun = 0.755007645115, optimized = True\n",
      "topic_359 | topic_38 : 0.34, topic_363 : 0.28, topic_439 : 0.10, topic_401 : 0.06, topic_491 : 0.03\n",
      "============================\n",
      "============================\n",
      "fun = 0.749524709385, optimized = True\n",
      "topic_358 | topic_122 : 0.32, topic_117 : 0.26, topic_263 : 0.19, topic_163 : 0.05, topic_413 : 0.04\n",
      "============================\n",
      "============================\n",
      "fun = 0.754684684987, optimized = True\n",
      "topic_418 | topic_8 : 0.14, topic_241 : 0.12, topic_240 : 0.12, topic_3 : 0.09, topic_416 : 0.08\n",
      "============================\n",
      "============================\n",
      "fun = 0.749000183063, optimized = True\n",
      "topic_419 | topic_137 : 0.27, topic_381 : 0.18, topic_255 : 0.15, topic_49 : 0.11, topic_20 : 0.08\n",
      "============================\n",
      "============================\n",
      "fun = 0.727051142601, optimized = True\n",
      "topic_355 | topic_71 : 0.26, topic_78 : 0.22, topic_356 : 0.18, topic_84 : 0.13, topic_401 : 0.08\n",
      "============================\n",
      "============================\n",
      "fun = 0.721139289431, optimized = True\n",
      "topic_356 | topic_71 : 0.35, topic_355 : 0.22, topic_442 : 0.15, topic_440 : 0.12, topic_401 : 0.07\n",
      "============================\n",
      "============================\n",
      "fun = 0.742522040364, optimized = True\n",
      "topic_439 | topic_399 : 0.33, topic_346 : 0.10, topic_38 : 0.10, topic_359 : 0.09, topic_80 : 0.07\n",
      "============================\n",
      "============================\n",
      "fun = 0.750065030465, optimized = True\n",
      "topic_177 | topic_136 : 0.16, topic_498 : 0.16, topic_399 : 0.11, topic_90 : 0.11, topic_407 : 0.09\n",
      "============================\n",
      "============================\n",
      "fun = 0.754730641578, optimized = True\n",
      "topic_475 | topic_163 : 0.21, topic_184 : 0.13, topic_124 : 0.07, topic_403 : 0.06, topic_6 : 0.06\n",
      "============================\n",
      "============================\n",
      "fun = 0.719470714355, optimized = True\n",
      "topic_399 | topic_214 : 0.24, topic_439 : 0.23, topic_145 : 0.13, topic_177 : 0.09, topic_407 : 0.07\n",
      "============================\n",
      "============================\n",
      "fun = 0.736274434606, optimized = True\n",
      "topic_278 | topic_280 : 0.43, topic_95 : 0.22, topic_64 : 0.11, topic_39 : 0.05, topic_162 : 0.05\n",
      "============================\n",
      "============================\n",
      "fun = 0.750153662328, optimized = True\n",
      "topic_83 | topic_18 : 0.19, topic_456 : 0.19, topic_176 : 0.14, topic_7 : 0.11, topic_140 : 0.06\n",
      "============================\n",
      "============================\n",
      "fun = 0.744080905474, optimized = True\n",
      "topic_230 | topic_182 : 0.23, topic_429 : 0.10, topic_110 : 0.09, topic_289 : 0.09, topic_107 : 0.06\n",
      "============================\n",
      "============================\n",
      "fun = 0.735853486773, optimized = True\n",
      "topic_117 | topic_358 : 0.24, topic_39 : 0.15, topic_263 : 0.10, topic_95 : 0.10, topic_181 : 0.07\n",
      "============================\n",
      "============================\n",
      "fun = 0.754858215591, optimized = True\n",
      "topic_272 | topic_276 : 0.13, topic_383 : 0.13, topic_120 : 0.09, topic_106 : 0.08, topic_433 : 0.08\n",
      "============================\n",
      "============================\n",
      "fun = 0.759953366513, optimized = True\n",
      "topic_3 | topic_350 : 0.45, topic_219 : 0.20, topic_396 : 0.17, topic_8 : 0.14, topic_428 : 0.01\n",
      "============================\n",
      "============================\n",
      "fun = 0.740950025382, optimized = True\n",
      "topic_428 | topic_92 : 0.53, topic_3 : 0.08, topic_416 : 0.06, topic_226 : 0.06, topic_194 : 0.05\n",
      "============================\n",
      "============================\n",
      "fun = 0.730630205856, optimized = True\n",
      "topic_184 | topic_208 : 0.53, topic_475 : 0.16, topic_49 : 0.07, topic_122 : 0.07, topic_242 : 0.05\n",
      "============================\n",
      "============================\n",
      "fun = 0.72466505756, optimized = True\n",
      "topic_327 | topic_108 : 0.40, topic_448 : 0.19, topic_221 : 0.14, topic_349 : 0.13, topic_259 : 0.05\n",
      "============================\n",
      "============================\n",
      "fun = 0.707110364885, optimized = True\n",
      "topic_145 | topic_57 : 0.56, topic_399 : 0.12, topic_498 : 0.12, topic_295 : 0.08, topic_67 : 0.05\n",
      "============================\n",
      "============================\n",
      "fun = 0.758430989831, optimized = True\n",
      "topic_140 | topic_464 : 0.20, topic_471 : 0.13, topic_77 : 0.12, topic_265 : 0.12, topic_266 : 0.08\n",
      "============================\n",
      "============================\n",
      "fun = 0.746066693353, optimized = True\n",
      "topic_92 | topic_428 : 0.57, topic_348 : 0.10, topic_424 : 0.05, topic_86 : 0.03, topic_299 : 0.03\n",
      "============================\n",
      "============================\n",
      "fun = 0.73961960599, optimized = True\n",
      "topic_78 | topic_355 : 0.26, topic_66 : 0.12, topic_442 : 0.12, topic_136 : 0.12, topic_401 : 0.11\n",
      "============================\n",
      "============================\n",
      "fun = 0.752146957306, optimized = True\n",
      "topic_75 | topic_74 : 0.29, topic_124 : 0.28, topic_3 : 0.10, topic_1 : 0.06, topic_220 : 0.04\n",
      "============================\n",
      "============================\n",
      "fun = 0.733406839355, optimized = True\n",
      "topic_71 | topic_356 : 0.40, topic_355 : 0.17, topic_364 : 0.14, topic_127 : 0.06, topic_267 : 0.05\n",
      "============================\n",
      "============================\n",
      "fun = 0.754896114867, optimized = True\n",
      "topic_127 | topic_133 : 0.15, topic_210 : 0.14, topic_301 : 0.12, topic_84 : 0.10, topic_71 : 0.10\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "for key, value  in small_dist_opts.iteritems():\n",
    "    print_optimal_solution(_sol=value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.900343446224, optimized = True\n",
      "topic_30 | topic_463 : 0.14, topic_361 : 0.13, topic_487 : 0.10, topic_116 : 0.09, topic_299 : 0.08\n",
      "============================\n",
      "============================\n",
      "fun = 0.910405840239, optimized = True\n",
      "topic_307 | topic_62 : 0.22, topic_492 : 0.11, topic_293 : 0.09, topic_244 : 0.09, topic_161 : 0.08\n",
      "============================\n",
      "============================\n",
      "fun = 0.923415845239, optimized = True\n",
      "topic_309 | topic_36 : 0.50, topic_374 : 0.16, topic_67 : 0.12, topic_81 : 0.10, topic_164 : 0.05\n",
      "============================\n",
      "============================\n",
      "fun = 0.890908207754, optimized = True\n",
      "topic_388 | topic_269 : 0.23, topic_116 : 0.17, topic_347 : 0.12, topic_119 : 0.12, topic_464 : 0.06\n",
      "============================\n",
      "============================\n",
      "fun = 0.920427835428, optimized = True\n",
      "topic_391 | topic_467 : 0.37, topic_228 : 0.25, topic_400 : 0.03, topic_222 : 0.03, topic_166 : 0.03\n",
      "============================\n",
      "============================\n",
      "fun = 0.89738875009, optimized = True\n",
      "topic_60 | topic_499 : 0.21, topic_68 : 0.11, topic_380 : 0.10, topic_321 : 0.08, topic_44 : 0.07\n",
      "============================\n",
      "============================\n",
      "fun = 0.916226701177, optimized = True\n",
      "topic_243 | topic_396 : 0.13, topic_344 : 0.12, topic_282 : 0.10, topic_471 : 0.10, topic_149 : 0.09\n",
      "============================\n",
      "============================\n",
      "fun = 0.900289657723, optimized = True\n",
      "topic_410 | topic_470 : 0.53, topic_397 : 0.13, topic_230 : 0.11, topic_132 : 0.08, topic_388 : 0.05\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "for key, value  in large_dist_opts.iteritems():\n",
    "    print_optimal_solution(_sol=value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  opt    small_dist_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.752146957306, optimized = True\n",
      "topic_75 | topic_74 : 0.29 [0.84], topic_124 : 0.28 [0.85], topic_3 : 0.10 [0.90], topic_1 : 0.06 [0.90], topic_220 : 0.04 [0.91]\n",
      "closest by distance to topic_75 | topic_75 : [0.00], topic_74 : [0.84], topic_124 : [0.85], topic_1 : [0.90], topic_118 : [0.90]\n",
      "\n",
      "topic_75:      _   _    _ _ \n",
      "topic_74:  _    _   _ _ _ __   \n",
      "topic_124:   _ _           _\n",
      "topic_3:               \n",
      "topic_1:     _          _\n",
      "topic_220:               \n",
      "\n",
      "============================\n",
      "============================\n",
      "fun = 0.776779207039, optimized = True\n",
      "topic_74 | topic_75 : 0.37 [0.84], topic_118 : 0.25 [0.86], topic_116 : 0.07 [0.89], topic_395 : 0.06 [0.91], topic_124 : 0.05 [0.89]\n",
      "closest by distance to topic_74 | topic_74 : [0.00], topic_75 : [0.84], topic_118 : [0.86], topic_116 : [0.89], topic_1 : [0.89]\n",
      "\n",
      "topic_74:  _    _   _ _ _ __   \n",
      "topic_75:      _   _    _ _ \n",
      "topic_118:    _  _       _  \n",
      "topic_116:    _    _    __   \n",
      "topic_395:         _      _\n",
      "topic_124:   _ _           _\n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "topic_name = u'topic_75'\n",
    "other_topic_name = u'topic_74'\n",
    "print_optimal_solution(ds[topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)\n",
    "print_optimal_solution(ds[other_topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.746066693353, optimized = True\n",
      "topic_92 | topic_428 : 0.57 [0.80], topic_348 : 0.10 [0.90], topic_424 : 0.05 [0.92], topic_86 : 0.03 [0.91], topic_299 : 0.03 [0.92]\n",
      "closest by distance to topic_92 | topic_92 : [0.00], topic_428 : [0.80], topic_226 : [0.90], topic_348 : [0.90], topic_86 : [0.91]\n",
      "\n",
      "topic_92:               \n",
      "topic_428:          _ _    _\n",
      "topic_348:      _        _ \n",
      "topic_424:               \n",
      "topic_86:               \n",
      "topic_299:            _   \n",
      "\n",
      "============================\n",
      "============================\n",
      "fun = 0.740950025382, optimized = True\n",
      "topic_428 | topic_92 : 0.53 [0.80], topic_3 : 0.08 [0.91], topic_416 : 0.06 [0.91], topic_226 : 0.06 [0.85], topic_194 : 0.05 [0.90]\n",
      "closest by distance to topic_428 | topic_428 : [0.00], topic_92 : [0.80], topic_226 : [0.85], topic_194 : [0.90], topic_94 : [0.90]\n",
      "\n",
      "topic_428:          _ _    _\n",
      "topic_92:               \n",
      "topic_3:               \n",
      "topic_416: _       __ __      \n",
      "topic_226: _   _  _   _      \n",
      "topic_194:              _ \n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "topic_name = u'topic_92'\n",
    "other_topic_name = u'topic_428'\n",
    "print_optimal_solution(ds[topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)\n",
    "print_optimal_solution(ds[other_topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.736274434606, optimized = True\n",
      "topic_278 | topic_280 : 0.43 [0.81], topic_95 : 0.22 [0.85], topic_64 : 0.11 [0.88], topic_39 : 0.05 [0.90], topic_162 : 0.05 [0.87]\n",
      "closest by distance to topic_278 | topic_278 : [0.00], topic_280 : [0.81], topic_95 : [0.85], topic_133 : [0.86], topic_162 : [0.87]\n",
      "\n",
      "topic_278:               \n",
      "topic_280:         _      \n",
      "topic_95:     _ _  _       _\n",
      "topic_64:             _  \n",
      "topic_39:  _ _   _  _  _     \n",
      "topic_162: _          _    _\n",
      "\n",
      "============================\n",
      "============================\n",
      "fun = 0.766081324544, optimized = True\n",
      "topic_280 | topic_278 : 0.57 [0.81], topic_117 : 0.14 [0.88], topic_301 : 0.13 [0.87], topic_39 : 0.04 [0.91], topic_64 : 0.04 [0.91]\n",
      "closest by distance to topic_280 | topic_280 : [0.00], topic_278 : [0.81], topic_301 : [0.87], topic_133 : [0.88], topic_117 : [0.88]\n",
      "\n",
      "topic_280:         _      \n",
      "topic_278:               \n",
      "topic_117:             _  \n",
      "topic_301:       _    _    \n",
      "topic_39:  _ _   _  _  _     \n",
      "topic_64:             _  \n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "topic_name = u'topic_278'\n",
    "other_topic_name = u'topic_280'\n",
    "print_optimal_solution(ds[topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)\n",
    "print_optimal_solution(ds[other_topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.900289657723, optimized = True\n",
      "topic_410 | topic_470 : 0.53 [0.92], topic_397 : 0.13 [0.95], topic_230 : 0.11 [0.95], topic_132 : 0.08 [0.96], topic_388 : 0.05 [0.96]\n",
      "closest by distance to topic_410 | topic_410 : [0.00], topic_470 : [0.92], topic_317 : [0.95], topic_397 : [0.95], topic_230 : [0.95]\n",
      "\n",
      "topic_410:   _ _     _      \n",
      "topic_470:      _         \n",
      "topic_397:               \n",
      "topic_230:           _    _\n",
      "topic_132:         _      \n",
      "topic_388:       _   _   _  _\n",
      "\n",
      "============================\n",
      "============================\n",
      "fun = 0.853395674722, optimized = True\n",
      "topic_470 | topic_120 : 0.27 [0.90], topic_3 : 0.25 [0.91], topic_410 : 0.13 [0.92], topic_435 : 0.08 [0.94], topic_491 : 0.06 [0.94]\n",
      "closest by distance to topic_470 | topic_470 : [0.00], topic_120 : [0.90], topic_3 : [0.91], topic_335 : [0.91], topic_410 : [0.92]\n",
      "\n",
      "topic_470:      _         \n",
      "topic_120:     _     _ _    \n",
      "topic_3:               \n",
      "topic_410:   _ _     _      \n",
      "topic_435:               \n",
      "topic_491:      _ _     _   \n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "topic_name = u'topic_410'\n",
    "other_topic_name = u'topic_470'\n",
    "print_optimal_solution(ds[topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)\n",
    "print_optimal_solution(ds[other_topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.754684684987, optimized = True\n",
      "topic_418 | topic_8 : 0.14 [0.87], topic_241 : 0.12 [0.86], topic_240 : 0.12 [0.88], topic_3 : 0.09 [0.89], topic_416 : 0.08 [0.87]\n",
      "closest by distance to topic_418 | topic_418 : [0.00], topic_241 : [0.86], topic_8 : [0.87], topic_416 : [0.87], topic_313 : [0.87]\n",
      "\n",
      "topic_418:           _    \n",
      "topic_8:        _      _ \n",
      "topic_241:       _        _\n",
      "topic_240:  _             \n",
      "topic_3:               \n",
      "topic_416: _       __ __      \n",
      "\n",
      "============================\n",
      "============================\n",
      "fun = 0.818580390386, optimized = True\n",
      "topic_8 | topic_3 : 0.31 [0.88], topic_418 : 0.26 [0.87], topic_483 : 0.09 [0.91], topic_68 : 0.09 [0.92], topic_146 : 0.06 [0.93]\n",
      "closest by distance to topic_8 | topic_8 : [0.00], topic_418 : [0.87], topic_3 : [0.88], topic_483 : [0.91], topic_313 : [0.91]\n",
      "\n",
      "topic_8:        _      _ \n",
      "topic_3:               \n",
      "topic_418:           _    \n",
      "topic_483:               \n",
      "topic_68:   _            \n",
      "topic_146:       _ _       _\n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "topic_name = u'topic_418'\n",
    "other_topic_name = u'topic_8'\n",
    "print_optimal_solution(ds[topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)\n",
    "print_optimal_solution(ds[other_topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#      ,    ,   \n",
    "# ,      ?\n",
    "#  ,    \n",
    "#  opt    small_dist_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.923415845239, optimized = True\n",
      "topic_309 | topic_36 : 0.50 [0.94], topic_374 : 0.16 [0.97], topic_67 : 0.12 [0.96], topic_81 : 0.10 [0.96], topic_164 : 0.05 [0.94]\n",
      "closest by distance to topic_309 | topic_309 : [0.00], topic_164 : [0.94], topic_36 : [0.94], topic_418 : [0.95], topic_323 : [0.95]\n",
      "\n",
      "topic_309:         _ _   _  \n",
      "topic_36:         _    _  \n",
      "topic_374:  _             _\n",
      "topic_67:     _          \n",
      "topic_81:         _      \n",
      "topic_164:       _       _ \n",
      "\n",
      "============================\n",
      "============================\n",
      "fun = 0.788396736373, optimized = True\n",
      "topic_36 | topic_241 : 0.39 [0.85], topic_164 : 0.11 [0.86], topic_277 : 0.10 [0.88], topic_166 : 0.09 [0.88], topic_271 : 0.07 [0.89]\n",
      "closest by distance to topic_36 | topic_36 : [0.00], topic_241 : [0.85], topic_164 : [0.86], topic_277 : [0.88], topic_166 : [0.88]\n",
      "\n",
      "topic_36:         _    _  \n",
      "topic_241:       _        _\n",
      "topic_164:       _       _ \n",
      "topic_277:               \n",
      "topic_166:  _  _       _    _\n",
      "topic_271:     _     _  _  _ _\n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "topic_name = u'topic_309'\n",
    "other_topic_name = u'topic_36'\n",
    "print_optimal_solution(ds[topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)\n",
    "print_optimal_solution(ds[other_topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.916226701177, optimized = True\n",
      "topic_243 | topic_396 : 0.13 [0.95], topic_344 : 0.12 [0.94], topic_282 : 0.10 [0.95], topic_471 : 0.10 [0.95], topic_149 : 0.09 [0.96]\n",
      "closest by distance to topic_243 | topic_243 : [0.00], topic_75 : [0.94], topic_344 : [0.94], topic_172 : [0.95], topic_272 : [0.95]\n",
      "\n",
      "topic_243:               \n",
      "topic_396:         _      \n",
      "topic_344:               \n",
      "topic_282:          _ _ _   _\n",
      "topic_471:        _   _    \n",
      "topic_149:              _ \n",
      "\n",
      "============================\n",
      "============================\n",
      "fun = 0.80260105175, optimized = True\n",
      "topic_396 | topic_3 : 0.28 [0.86], topic_73 : 0.14 [0.88], topic_350 : 0.10 [0.91], topic_258 : 0.08 [0.92], topic_434 : 0.06 [0.90]\n",
      "closest by distance to topic_396 | topic_396 : [0.00], topic_3 : [0.86], topic_73 : [0.88], topic_434 : [0.90], topic_272 : [0.90]\n",
      "\n",
      "topic_396:         _      \n",
      "topic_3:               \n",
      "topic_73:   _ _       _ _  _ \n",
      "topic_350:        _       \n",
      "topic_258:               \n",
      "topic_434:  _ _       _  _   \n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "topic_name = u'topic_243'\n",
    "other_topic_name = u'topic_396'\n",
    "print_optimal_solution(ds[topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)\n",
    "print_optimal_solution(ds[other_topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.900289657723, optimized = True\n",
      "topic_410 | topic_470 : 0.53 [0.92], topic_397 : 0.13 [0.95], topic_230 : 0.11 [0.95], topic_132 : 0.08 [0.96], topic_388 : 0.05 [0.96]\n",
      "closest by distance to topic_410 | topic_410 : [0.00], topic_470 : [0.92], topic_317 : [0.95], topic_397 : [0.95], topic_230 : [0.95]\n",
      "\n",
      "topic_410:   _ _     _      \n",
      "topic_470:      _         \n",
      "topic_397:               \n",
      "topic_230:           _    _\n",
      "topic_132:         _      \n",
      "topic_388:       _   _   _  _\n",
      "\n",
      "============================\n",
      "============================\n",
      "fun = 0.853395674722, optimized = True\n",
      "topic_470 | topic_120 : 0.27 [0.90], topic_3 : 0.25 [0.91], topic_410 : 0.13 [0.92], topic_435 : 0.08 [0.94], topic_491 : 0.06 [0.94]\n",
      "closest by distance to topic_470 | topic_470 : [0.00], topic_120 : [0.90], topic_3 : [0.91], topic_335 : [0.91], topic_410 : [0.92]\n",
      "\n",
      "topic_470:      _         \n",
      "topic_120:     _     _ _    \n",
      "topic_3:               \n",
      "topic_410:   _ _     _      \n",
      "topic_435:               \n",
      "topic_491:      _ _     _   \n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "topic_name = u'topic_410'\n",
    "other_topic_name = u'topic_470'\n",
    "print_optimal_solution(ds[topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)\n",
    "print_optimal_solution(ds[other_topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#    opt ,     \n",
    "#      -   , "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.746066693353, optimized = True\n",
      "topic_92 | topic_428 : 0.57 [0.80], topic_348 : 0.10 [0.90], topic_424 : 0.05 [0.92], topic_86 : 0.03 [0.91], topic_299 : 0.03 [0.92]\n",
      "closest by distance to topic_92 | topic_92 : [0.00], topic_428 : [0.80], topic_226 : [0.90], topic_348 : [0.90], topic_86 : [0.91]\n",
      "\n",
      "topic_92:               \n",
      "topic_428:          _ _    _\n",
      "topic_348:      _        _ \n",
      "topic_424:               \n",
      "topic_86:               \n",
      "topic_299:            _   \n",
      "\n",
      "============================\n",
      "============================\n",
      "fun = 0.740950025382, optimized = True\n",
      "topic_428 | topic_92 : 0.53 [0.80], topic_3 : 0.08 [0.91], topic_416 : 0.06 [0.91], topic_226 : 0.06 [0.85], topic_194 : 0.05 [0.90]\n",
      "closest by distance to topic_428 | topic_428 : [0.00], topic_92 : [0.80], topic_226 : [0.85], topic_194 : [0.90], topic_94 : [0.90]\n",
      "\n",
      "topic_428:          _ _    _\n",
      "topic_92:               \n",
      "topic_3:               \n",
      "topic_416: _       __ __      \n",
      "topic_226: _   _  _   _      \n",
      "topic_194:              _ \n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "#   <<>>\n",
    "topic_name = u'topic_92'\n",
    "other_topic_name = u'topic_428'\n",
    "print_optimal_solution(ds[topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)\n",
    "print_optimal_solution(ds[other_topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0 0.0077551\n",
      " 0.0 0.00116458\n",
      " 0.000428391 3.31266e-05\n",
      " 0.0 0.00524335\n",
      " 0.00409053 0.00319101\n",
      " 0.000433505 0.0\n",
      " 0.00236797 0.0\n",
      " 0.00200578 0.00110529\n",
      " 0.00438831 0.00303694\n",
      " 0.0021662 0.000773385\n",
      " 0.0 0.00358029\n",
      " 0.0 0.00316419\n",
      " 0.0 0.00485475\n",
      "_ 1.76624e-05 0.000321171\n",
      " 0.00238779 0.0041048\n",
      "_ 4.70327e-05 0.0\n",
      " 0.0 0.00014228\n",
      " 0.00108994 0.0\n",
      " 0.0 0.00405267\n",
      " 0.0 0.0001383\n",
      " 0.0 0.00159147\n",
      " 0.003645 0.0\n",
      " 0.000861592 0.0\n",
      " 0.0 0.00197238\n",
      " 0.00144042 0.0\n",
      " 0.000509953 0.0\n",
      " 0.000341337 0.0\n",
      " 0.0 0.00155534\n",
      " 0.0 0.00206616\n",
      "_ 0.0 0.000632442\n",
      " 0.0 0.000574692\n",
      " 0.0 0.000100579\n",
      " 0.0 0.00301114\n",
      " 0.0 0.00509165\n",
      " 0.000697966 0.0\n",
      " 0.0 0.0162911\n",
      " 0.0 0.000808911\n",
      " 0.000478861 0.00214819\n",
      " 0.0 0.00423341\n",
      " 0.00106641 0.0\n",
      " 0.00055194 0.0\n",
      " 0.000472495 0.0\n",
      " 0.00119699 0.0\n",
      " 0.0 0.00411383\n",
      " 0.0 0.000614265\n",
      " 0.000479312 0.00095496\n",
      " 0.0 0.000390473\n",
      " 0.0 0.000581949\n",
      " 0.00082286 0.0\n",
      " 0.0 0.000724224\n",
      "_ 0.0 0.00799703\n",
      " 0.0 0.0072125\n",
      " 0.0 0.000268406\n",
      " 0.0 0.00296704\n",
      " 0.00382149 0.00537767\n",
      " 0.0 0.00147852\n",
      " 0.000936573 0.0\n",
      " 0.0 0.00135056\n",
      " 0.00268457 0.0\n",
      " 0.0 0.000416737\n",
      " 0.00776079 0.0\n",
      " 0.0 0.00194991\n",
      " 0.000516543 0.00384331\n",
      " 0.0 0.000132611\n",
      " 0.0015361 0.0\n",
      " 0.00446629 0.0\n",
      " 0.0 4.1581e-05\n",
      " 0.00366002 0.0\n",
      " 0.000714523 0.0\n",
      " 0.0 0.00049658\n",
      " 0.000499873 0.0\n",
      " 0.0 0.000585726\n",
      " 0.000206247 0.0\n",
      " 0.00183109 0.0\n",
      "_ 0.000337515 0.0\n",
      " 0.0 0.000451304\n",
      " 0.000929516 0.00321028\n",
      " 0.00186818 0.000640841\n",
      " 0.0 0.000369114\n",
      " 0.0 0.000664101\n",
      " 0.0 0.000583534\n",
      " 0.0 0.00067439\n",
      " 0.0 0.00123225\n",
      " 0.0010672 0.00138153\n",
      " 9.24248e-05 0.000101361\n",
      " 0.0 0.000510226\n",
      " 0.0 0.000815917\n",
      " 0.000478203 0.0\n",
      "_ 0.000841155 0.0\n",
      " 0.00056755 0.0\n",
      " 2.61633e-05 2.77317e-05\n",
      " 0.0 0.000494576\n",
      " 0.00149529 0.00245472\n",
      " 0.000539955 0.0\n",
      " 0.0054494 0.0\n",
      " 0.0 0.000535717\n",
      " 0.000347946 0.0\n",
      " 0.000608599 0.0\n",
      " 6.8246e-06 0.0\n",
      " 0.000640537 0.0\n",
      " 0.0 0.000654412\n",
      " 0.0 0.00206382\n",
      " 0.0 0.000421343\n",
      " 0.00405845 0.0\n",
      " 0.000383282 0.00596429\n",
      " 0.00353946 0.0\n",
      " 0.0 0.000353752\n",
      " 0.0 0.00172975\n",
      " 0.00116563 0.00516427\n",
      " 0.0 0.00392687\n",
      " 0.0 0.0012988\n",
      " 0.00551671 0.0\n",
      " 0.00047595 0.0\n",
      " 0.0 0.00106693\n",
      " 0.00133172 0.000263498\n",
      " 0.0 0.000576684\n",
      " 0.0 0.000227677\n",
      " 0.00325354 0.0\n",
      " 0.000848948 0.000817135\n",
      " 0.0 0.000721885\n",
      " 0.00058583 0.0\n",
      " 0.00453185 0.0\n",
      " 0.000524229 0.00360695\n",
      " 0.00202676 0.000999935\n",
      "_ 0.00485988 0.0\n",
      " 0.0 0.00060357\n",
      " 0.0 0.000400025\n",
      " 0.000142631 8.36378e-05\n",
      " 0.0 0.00210502\n",
      " 0.0 0.00666849\n",
      " 0.000333503 0.0\n",
      " 0.000322266 0.0\n",
      " 0.00245435 0.00209887\n",
      " 0.000379641 0.0\n",
      " 0.000375553 0.0\n",
      " 0.000970891 0.0\n",
      " 0.0 0.000378035\n",
      " 0.0 0.00152785\n",
      " 0.0 3.07447e-05\n",
      " 0.00406015 0.0\n",
      " 0.0 0.000306034\n",
      " 0.00116352 0.0\n",
      " 0.0 0.00214002\n",
      " 0.0 0.000453594\n",
      " 0.000429573 0.0\n",
      " 0.000657036 0.000237195\n",
      " 0.0 0.00271732\n",
      " 0.0 9.82044e-06\n",
      " 0.0 5.50481e-05\n",
      " 0.00449858 0.0\n",
      " 0.00235792 1.68092e-05\n",
      " 9.02096e-05 0.0\n",
      " 0.0 0.00342634\n",
      " 0.0 0.00159168\n",
      " 0.0 0.000946298\n",
      " 0.000213111 0.00114239\n",
      " 0.00336699 0.00219582\n",
      " 0.00143078 0.0\n",
      " 0.0 0.00236354\n",
      " 0.0 0.00478506\n",
      " 0.0 0.000263348\n",
      " 0.000863694 0.0\n",
      " 0.0 0.00228185\n",
      " 0.00625354 0.0\n",
      " 0.00267942 3.7752e-05\n",
      " 0.0 0.000332168\n",
      " 0.0 0.00111064\n",
      " 0.0 0.0026534\n",
      " 0.00216284 0.000652066\n",
      " 0.00677246 0.0447701\n",
      " 0.0 0.000602689\n",
      " 0.0 0.000311654\n",
      " 0.00080365 0.00101641\n",
      " 0.0 0.000765322\n",
      " 0.00107381 0.0\n",
      " 0.00655215 0.0\n",
      " 0.000764666 0.0\n",
      " 0.0 0.000545581\n",
      " 0.00126926 8.29062e-05\n",
      " 0.0 0.00024126\n",
      " 0.0044883 0.00120955\n",
      " 0.00101991 0.0\n",
      " 0.0 0.000357156\n",
      " 0.00667349 0.0002473\n",
      " 0.00183521 0.0\n",
      " 0.00250222 0.0\n",
      " 0.000533554 0.000488105\n",
      " 0.0 0.000492634\n",
      "_ 0.0 0.000826091\n",
      " 0.000178902 0.0\n",
      " 0.00159517 0.0\n",
      " 0.00044855 0.0\n",
      " 0.00128394 0.00170549\n",
      " 0.0 7.93327e-05\n",
      " 0.00426623 0.0\n",
      " 0.000708098 0.0\n",
      " 0.0 0.000987156\n",
      " 0.000517232 0.0117972\n",
      " 0.000194733 0.0\n",
      " 0.00102342 0.0\n",
      " 0.000863312 0.0\n",
      " 0.0 0.000164001\n",
      " 0.0 0.00163825\n",
      " 0.0 0.000615665\n",
      " 0.00234414 0.0\n",
      " 0.00345592 0.0\n",
      " 0.0 0.000464822\n",
      " 0.0 0.00156917\n",
      " 0.0 0.000627465\n",
      " 0.000761957 0.0\n",
      " 0.00133902 0.0\n",
      " 0.0 0.000274493\n",
      " 0.000703932 0.000240519\n",
      " 0.000359285 0.00452304\n",
      " 0.000532221 0.0\n",
      " 0.00164299 0.00105678\n",
      " 0.000802988 0.00206627\n",
      " 0.00025311 0.0\n",
      " 0.00072943 0.0\n",
      " 0.0 0.000733981\n",
      " 7.05641e-06 0.0\n",
      " 0.0 0.00168906\n",
      " 0.000449081 0.00209984\n",
      " 0.000771432 0.0\n",
      " 0.000675177 0.0\n",
      " 0.00337988 0.0\n",
      " 0.0 0.00875766\n",
      " 0.0 0.000136398\n",
      "_ 0.00142069 0.00925011\n",
      " 0.000618147 0.0\n",
      " 0.0023695 0.00162571\n",
      " 0.0 0.000214507\n",
      " 0.0 5.13344e-05\n",
      " 0.0 0.000163191\n",
      " 0.00110199 0.004522\n",
      " 0.00320456 0.0\n",
      " 0.00099134 0.0\n",
      " 0.000306637 0.0\n",
      " 0.0 0.00161593\n",
      " 0.000528733 0.0\n",
      "_ 0.000413453 0.0\n",
      " 0.00289696 0.0\n",
      " 0.0 0.000224473\n",
      " 0.0 6.66679e-05\n",
      " 0.0 0.000566865\n",
      "__ 0.000409015 0.0\n",
      " 0.0 0.00134811\n",
      " 0.00102559 0.0\n",
      " 0.000400754 0.000121489\n",
      "_ 0.00102974 0.0\n",
      "_ 0.000415833 0.0\n",
      " 0.00438601 0.0\n",
      " 0.0 0.000509272\n",
      " 0.00155487 0.0\n",
      " 0.00180524 0.00032638\n",
      " 0.0 0.000876431\n",
      " 0.000820597 0.0\n",
      "_ 0.0 0.000397057\n",
      " 9.50155e-05 0.0\n",
      " 0.0 0.00158164\n",
      " 0.0 0.00080408\n",
      " 0.0 0.000882733\n",
      " 0.0 7.41167e-05\n",
      " 0.0038851 0.0\n",
      " 0.0 0.00143742\n",
      " 0.0 1.26079e-05\n",
      " 0.000562294 0.0\n",
      " 0.00476589 3.34478e-05\n",
      " 0.0 0.000286097\n",
      " 0.0 0.00139941\n",
      " 0.0 0.000165192\n",
      " 0.0 0.00125015\n",
      " 0.000191569 0.0\n",
      " 0.0 0.00270555\n",
      " 0.00160141 0.0\n",
      " 0.0 0.000611471\n",
      " 0.000908205 0.0\n",
      " 0.00361032 0.00282904\n",
      "_ 0.0 0.000787911\n",
      " 0.00511302 0.0\n",
      " 0.000836324 0.00160795\n",
      " 0.00654535 0.0\n",
      " 0.00427997 0.0\n",
      " 0.000604739 0.0\n",
      " 0.0 0.000416965\n",
      " 0.0 0.000541869\n",
      " 0.000362201 0.0\n",
      " 0.000566704 0.0\n",
      " 0.000890686 0.0\n",
      "_ 0.00046295 0.0\n",
      " 0.000455522 0.0\n",
      " 0.0 0.0005606\n",
      " 0.00234871 0.0\n",
      "_ 0.0 0.000251138\n",
      " 0.000996861 0.0\n",
      " 0.00135711 0.0\n",
      " 0.000134859 0.0\n",
      " 0.00100788 0.0\n",
      " 0.00181242 0.0\n",
      " 0.00269313 0.00194712\n",
      " 0.0 0.000611063\n",
      " 0.0 5.40302e-05\n",
      " 0.0049545 0.0\n",
      " 0.0 0.000332916\n",
      " 0.00120877 0.00274234\n",
      " 0.0 0.000592823\n",
      "_ 0.0 0.00229348\n",
      "_ 0.000465163 0.0\n",
      " 0.0 0.000995584\n",
      " 0.0 0.00283452\n",
      " 0.0 0.000261109\n",
      " 0.0 0.000228405\n",
      " 0.000925773 6.27717e-05\n",
      " 0.0 0.000747922\n",
      " 0.0 0.000512292\n",
      " 0.0060721 0.0\n",
      " 0.000245349 0.0\n",
      " 0.000455177 0.0\n",
      " 0.000557259 0.0\n",
      " 0.000676503 0.0\n",
      " 0.0 8.56688e-05\n",
      " 0.000832456 0.0\n",
      " 0.00124061 0.0\n",
      " 0.00670623 0.0\n",
      " 0.000541103 0.0\n",
      " 0.000317488 0.0\n",
      " 0.0 0.000969895\n",
      " 0.000453483 0.0\n",
      " 0.0 0.000105661\n",
      " 0.00177773 0.0\n",
      " 0.000138137 0.0\n",
      " 0.0 0.00116322\n",
      "_ 0.00036091 0.0\n",
      " 0.00304231 0.0\n",
      " 0.000403669 0.0\n",
      " 0.0 0.000328543\n",
      " 0.00134758 0.0\n",
      " 0.0 2.54022e-05\n",
      " 0.0 0.000531732\n",
      " 0.0 7.05185e-05\n",
      " 0.0604525 0.0490338\n",
      " 0.000376288 0.0\n",
      " 0.0 0.000768559\n",
      " 0.0 0.000512709\n",
      " 0.0 0.00031923\n",
      " 0.0 0.0220532\n",
      " 0.000447281 0.0\n",
      " 0.0011353 0.0\n",
      " 0.0021086 0.00789362\n",
      " 0.00102762 0.000632938\n",
      " 0.00140558 0.0\n",
      " 0.0 0.000100068\n",
      " 0.00159925 0.0\n",
      " 0.0919983 0.181007\n",
      " 0.00276041 0.0\n",
      " 0.00264648 0.0\n",
      " 0.00170459 0.00262917\n",
      " 0.000986571 0.00190649\n",
      " 0.00267351 0.0\n",
      " 0.00111219 0.00103508\n",
      " 0.00227444 0.0\n",
      " 0.0 0.00300858\n",
      " 0.000443117 0.0\n",
      " 0.00403368 0.0\n",
      " 0.0 0.00138985\n",
      " 0.000474135 0.0\n",
      " 0.0 0.00126635\n",
      " 0.0 0.00114524\n",
      " 0.0 0.000276\n",
      " 0.000299085 0.0\n",
      " 0.000946682 0.0\n",
      " 0.00102975 0.0\n",
      " 0.0 0.000717711\n",
      " 0.000274944 0.0\n",
      " 0.000190731 0.0\n",
      " 0.000396778 0.000479386\n",
      " 0.014908 0.000641348\n",
      "_ 0.0 0.000716384\n",
      " 0.00209303 0.0\n",
      " 0.0 0.00528265\n",
      " 0.0 0.000286323\n",
      " 0.000230253 0.0\n",
      " 0.000986242 0.0\n",
      " 0.0 0.00245253\n",
      " 0.000989741 0.0\n",
      " 0.000590532 0.00141369\n",
      "_ 0.0 0.00158117\n",
      " 0.000842938 0.0\n",
      " 0.000667688 0.0\n",
      " 0.0 0.000651218\n",
      " 0.00296695 0.0\n",
      " 0.0 0.000491474\n",
      " 0.0 0.00236338\n",
      "_ 0.000443137 0.0\n",
      " 0.00386945 0.0\n",
      " 0.000429384 0.0\n",
      " 3.47865e-05 0.0\n",
      " 0.0 0.00131973\n",
      " 0.000378222 0.0\n",
      " 0.0 0.00021174\n",
      " 0.00170562 0.0\n",
      " 0.00128636 0.0\n",
      " 0.0 0.00215279\n",
      " 0.000584287 0.0\n",
      "_ 0.0 0.000228383\n",
      " 0.000561481 0.0\n",
      " 0.0 0.00014476\n",
      "_ 0.000614667 0.0\n",
      " 0.0 0.000321231\n",
      " 0.0119147 0.000544823\n",
      " 0.0 0.00180475\n",
      " 0.00206962 0.00357844\n",
      " 0.0 0.00144442\n",
      " 0.000421666 0.0\n",
      " 0.00033141 0.0\n",
      "_ 0.000458791 0.0\n",
      " 0.00248337 0.00643254\n",
      " 0.00218259 0.0\n",
      " 0.0 0.000526001\n",
      " 0.0 0.000320131\n",
      " 0.000590999 0.0\n",
      " 0.00124283 0.000116299\n",
      " 0.0 0.00428448\n",
      " 0.000470214 0.0\n",
      " 0.0 0.000677085\n",
      " 0.000669114 0.0\n",
      " 0.0 0.000605224\n",
      " 0.00272503 0.0\n",
      " 0.00390814 0.0\n",
      " 0.0 0.000363607\n",
      " 0.00124578 0.0\n",
      " 0.00432979 0.0\n",
      " 0.00043735 0.0\n",
      " 0.000396446 0.00330642\n",
      "_ 0.00239131 0.0\n",
      " 0.000470356 0.0\n",
      " 0.0 0.0024166\n",
      " 0.00104314 0.0\n",
      " 0.0 0.00314599\n",
      " 0.0574003 0.00845762\n",
      " 0.00343002 0.0\n",
      " 0.0112707 0.0\n",
      "_ 0.000599449 0.0\n",
      " 0.00134964 0.0\n",
      " 0.0228734 0.0\n",
      " 0.00373294 0.000679807\n",
      "_ 0.000525488 0.0\n",
      " 0.000879363 0.0\n",
      " 0.000934153 0.0\n",
      "__ 0.000543621 0.0\n",
      " 0.0152761 0.0\n",
      " 0.000644845 0.0\n",
      " 0.000460338 0.0\n",
      "_ 0.00106997 0.00774295\n",
      " 0.000732848 0.0\n",
      " 0.00574531 0.0\n",
      " 0.0 0.0240915\n",
      " 0.000397334 0.0\n",
      " 0.00165641 0.0\n",
      " 0.000308345 0.0\n",
      " 0.000455538 0.0\n",
      " 0.00706514 0.0\n",
      " 0.000346098 0.0\n",
      " 0.0 0.000486461\n",
      " 0.0 0.000639256\n",
      " 0.0 0.000484764\n",
      " 0.00179197 0.0\n",
      " 0.00665353 1.80044e-05\n",
      " 0.0 0.000339589\n",
      " 0.00244455 0.0\n",
      " 0.0013783 0.000641326\n",
      " 0.00198968 0.0\n",
      "_ 0.000582904 0.0\n",
      " 0.0 0.000591375\n",
      " 0.000477458 0.0\n",
      " 0.0 0.000165135\n",
      " 0.0 6.72881e-05\n",
      " 0.00036443 0.0\n",
      " 0.0 0.000293602\n",
      " 0.0026136 0.000597464\n",
      " 0.000555392 0.0\n",
      " 0.000528682 0.0\n",
      " 0.0 0.000299532\n",
      " 0.0 0.000260423\n",
      " 0.000847834 0.0\n",
      " 0.0 0.00315046\n",
      " 0.000708138 0.0\n",
      " 0.00421754 0.0\n",
      " 0.000449524 0.0\n",
      " 0.0 0.000159583\n",
      " 0.000451026 0.0\n",
      " 0.0 0.00148243\n",
      "_ 0.00203941 0.0\n",
      " 0.0 0.00075977\n",
      " 0.00034681 0.0\n",
      " 0.000302528 0.0\n",
      " 0.00052941 0.0\n",
      " 0.000187372 0.0\n",
      " 0.00150402 0.0\n",
      " 0.0 0.000126355\n",
      " 0.0 0.000392814\n",
      " 0.00588492 0.0\n",
      " 0.00115523 0.0\n",
      " 0.0 0.000872915\n",
      " 0.0 0.000355158\n",
      " 0.00160506 0.00854816\n",
      " 0.0 7.93827e-05\n",
      " 0.00129263 0.0\n",
      " 0.0 0.000212984\n",
      " 0.0 0.000850042\n",
      " 0.000372912 0.0\n",
      " 0.0 0.000913532\n",
      " 0.00252238 0.0\n",
      " 0.0 0.000532274\n",
      " 0.0 0.00131836\n",
      " 0.000313447 0.0\n",
      "_ 0.0 0.000503836\n",
      "_xx_ 0.000243587 0.0\n",
      "_ 0.0 0.000671634\n",
      " 0.00101591 0.0\n",
      " 0.000449394 0.0\n",
      " 0.000409367 0.0\n",
      " 0.000474453 0.0\n",
      " 0.0 0.000390746\n",
      " 0.000586118 0.000594449\n",
      " 0.0 8.17507e-05\n",
      " 0.000422548 0.0\n",
      " 0.0065235 0.00504379\n",
      " 0.0 0.000227895\n",
      " 0.000292423 0.000224818\n",
      " 0.0 0.000303746\n",
      " 0.00258929 0.0\n",
      " 0.0 0.000334024\n",
      "_ 0.000461075 0.0\n",
      " 0.0 0.0011042\n",
      " 0.00136055 0.0\n",
      " 0.0 1.35499e-05\n",
      " 0.000870259 0.0\n",
      " 0.0 0.000400245\n",
      " 0.00105742 0.0\n",
      " 0.0132536 0.0\n",
      " 0.000708665 0.0\n",
      " 0.000766259 0.000901702\n",
      " 0.0 0.0011865\n",
      " 0.000378575 0.0\n",
      " 0.0010797 0.0\n",
      " 0.0 0.000139265\n",
      "_ 0.000686259 0.0\n",
      " 0.0 0.000283397\n",
      " 0.0 0.0001434\n",
      " 0.00047267 0.0\n",
      " 0.0 0.000155029\n",
      " 0.0 0.00172455\n",
      " 0.000473365 0.0\n",
      " 0.000451528 0.0\n",
      " 0.000703694 0.0304193\n",
      " 0.0 0.00476182\n",
      " 0.0 0.000364384\n",
      " 0.00111076 0.000628048\n",
      " 0.0033271 0.0\n",
      " 0.0 7.47068e-05\n",
      " 0.0 0.00237362\n",
      "_ 0.000464258 0.0\n",
      " 0.000952793 0.0\n",
      " 0.0 0.00130777\n",
      " 0.000292114 0.0\n",
      "_ 0.00041834 0.0\n",
      "_ 0.0 0.000461064\n",
      " 0.000446739 0.0\n",
      " 0.0 0.000216722\n",
      " 0.00034857 0.0\n",
      " 0.000678511 0.0\n",
      " 0.0 0.000186555\n",
      " 0.00133082 0.0\n",
      " 0.0 0.000218732\n",
      " 0.0 0.00256861\n",
      " 0.000454126 0.0\n",
      " 0.0 0.000658723\n",
      " 0.000840179 0.0\n",
      " 0.00100074 0.0\n",
      " 0.000532454 0.0\n",
      " 0.0 0.000913831\n",
      "__ 0.000395853 0.0\n",
      " 0.000434634 0.0\n",
      " 0.000433835 0.0\n",
      "_ 0.000302605 0.0\n",
      "_ 0.0 0.000440491\n",
      " 0.00120373 0.0\n",
      " 0.000426553 0.0\n",
      " 0.000414944 0.0\n",
      " 0.00149358 0.0\n",
      " 0.00183625 0.0\n",
      " 0.00223339 0.000103673\n",
      " 0.000473436 0.0\n",
      " 0.0 0.00105315\n",
      " 0.0 0.000771491\n",
      " 0.000562671 0.0\n",
      " 0.00035858 0.0\n",
      " 0.000554233 0.0\n",
      " 0.00128134 0.0\n",
      " 0.0 0.000812717\n",
      " 0.000467712 0.0\n",
      " 0.0 0.00120987\n",
      " 0.0 0.000323217\n",
      "_ 0.0 0.000247922\n",
      " 0.0 0.000692049\n",
      " 0.00253599 0.0\n",
      " 0.000114596 0.00136421\n",
      "_ 0.0 0.00817109\n",
      "_ 0.0 0.000629716\n",
      " 0.000461549 0.0\n",
      " 0.0 0.000229079\n",
      " 0.0 0.000320638\n",
      " 0.000945736 0.0\n",
      " 0.000911819 0.0\n",
      " 0.000435456 0.0\n",
      " 0.000457351 0.0\n",
      " 0.00163533 0.0\n",
      " 0.00309268 0.0\n",
      " 0.00177643 0.0\n",
      " 0.0 0.000923733\n",
      " 0.00128011 0.0\n",
      " 0.0 0.000863358\n",
      " 0.0 0.000341067\n",
      " 0.00213281 0.0\n",
      " 0.0 0.00178627\n",
      " 0.00122379 0.0\n",
      " 0.00268306 0.0\n",
      " 0.0 0.000202009\n",
      " 0.000447927 0.0\n",
      " 0.0004148 0.0\n",
      " 0.0 0.000590232\n",
      " 0.000348542 0.0\n",
      " 0.0 0.00108224\n",
      "_ 0.0 0.000688803\n",
      " 0.00147046 0.0\n",
      "_ 0.000428007 0.0\n",
      "_ 0.000816944 0.0\n",
      " 0.00202373 0.0\n",
      "_ 0.0 0.000346666\n",
      " 0.0 7.76821e-05\n",
      " 0.0 0.00156435\n",
      " 0.00364509 0.0\n",
      " 0.0 0.00125888\n",
      " 0.000476152 0.0\n",
      " 0.000223656 0.0\n",
      "_ 0.000586159 0.0\n",
      " 0.0 0.00388754\n",
      " 0.000498983 0.0\n",
      "_ 0.000527444 0.0\n",
      " 0.0 0.000519615\n",
      " 0.000950601 0.0\n",
      " 0.0 0.000797373\n",
      " 0.000394637 0.0\n",
      "_xv_ 0.0 0.00223279\n",
      " 0.0 0.000616578\n",
      " 0.0 0.00028053\n",
      " 0.000270749 0.0\n",
      " 0.000491532 0.0\n",
      " 0.0 0.00200345\n",
      " 0.0 0.000754268\n",
      " 0.0 0.000299918\n",
      "_ 0.0 0.00238409\n",
      " 0.000461516 0.0\n",
      " 0.0 0.00017663\n",
      "_ 0.000574952 0.0\n",
      " 0.0 0.00159355\n",
      "_ 0.0 0.000945698\n",
      " 0.0 0.00672011\n",
      "_ 0.0 0.00519438\n",
      " 0.0 0.00273908\n",
      " 0.0 0.0207662\n",
      " 0.0 0.00170442\n",
      " 0.00239131 0.0\n",
      " 0.0026381 0.000186607\n",
      " 0.000598045 0.0\n",
      " 0.000803773 0.0\n",
      "_ 0.0 0.000572469\n",
      " 0.000420986 0.0\n",
      " 0.000432417 0.0\n",
      " 0.0 0.000306158\n",
      " 0.000788963 0.00757398\n",
      " 0.000353686 0.0\n",
      " 0.000973889 0.0\n",
      " 0.0 2.95665e-05\n",
      " 0.0 0.00028929\n",
      " 0.0032476 0.0\n",
      " 0.00110191 0.0\n",
      " 1.80187e-05 0.0\n",
      " 0.0 0.000295877\n",
      "_ 0.000401338 0.0\n",
      " 0.000325558 0.0\n",
      " 0.00305028 0.0\n",
      " 0.000363613 0.000137688\n",
      " 0.000388227 0.0\n",
      " 6.71766e-05 0.0\n",
      " 0.0 0.000557053\n",
      " 0.000217037 0.0\n",
      " 0.00152942 0.0\n",
      " 0.00135216 0.0\n",
      " 0.0 0.00121955\n",
      " 0.0 0.000301841\n",
      " 0.0 0.00250328\n",
      " 0.0189628 0.0\n",
      " 0.0 0.00811212\n",
      " 0.0 0.000994358\n",
      " 0.0 0.0043856\n",
      "_ 0.0 0.00266921\n",
      " 0.0 0.00410323\n",
      " 0.00381776 0.0\n",
      "_ 0.0 0.0094306\n",
      " 0.0 0.00344791\n",
      " 0.0 0.000282396\n",
      " 0.000124854 0.0\n",
      "_ 0.000511027 0.0\n",
      " 0.00136355 0.0\n",
      " 0.00072634 0.0\n",
      "_ 0.0 0.000311116\n",
      " 0.00541492 0.0\n",
      " 0.0 0.00345153\n",
      " 0.0 8.20115e-05\n",
      " 0.0025136 0.0\n",
      " 0.0 0.00456086\n",
      " 0.0 0.000237003\n",
      "_xx_ 0.000134969 0.0\n",
      " 0.000206324 0.0\n",
      " 0.0 0.000546716\n",
      " 0.0 0.00258463\n",
      " 0.0 0.000457772\n",
      " 0.000462336 0.0\n",
      " 0.0 0.00111968\n",
      " 0.0 0.00699653\n",
      " 0.000473683 0.0\n",
      " 0.0 0.000193371\n",
      " 0.000477895 0.0\n",
      " 0.00150332 0.0\n",
      " 0.000631822 0.0\n",
      " 0.0 0.000998494\n",
      "_ 0.0 0.000613238\n",
      "_xix 0.000487798 0.0\n",
      "_ 0.000447797 0.0\n",
      " 6.53385e-05 0.000631898\n",
      " 0.000555326 0.0\n",
      " 0.000158622 0.0\n",
      " 0.016133 0.0\n",
      " 0.0 0.000285754\n",
      "_ 0.0 0.00159805\n",
      " 0.000945451 0.0\n",
      "_ 0.0 0.00115009\n",
      " 0.00034962 0.0\n",
      " 0.000952031 0.0\n",
      " 0.0 0.00078657\n",
      " 0.0 0.000936223\n",
      " 0.0 0.00126328\n",
      " 0.0 0.000308944\n",
      " 0.0 0.000318175\n",
      " 0.000322132 0.0\n",
      " 0.00155993 0.0\n",
      " 0.000466878 0.0\n",
      " 0.000392089 0.0\n",
      " 0.0 0.000949883\n",
      "_ 0.000509148 0.0\n",
      "_ 0.000412768 0.0\n",
      "_ 0.0 0.00109235\n",
      " 0.000312361 0.000528225\n",
      " 0.000157495 0.0\n",
      " 0.000483743 0.0\n",
      "_ 0.000433105 0.0\n",
      " 0.0 7.02449e-05\n",
      "_ 0.00230392 0.0\n",
      " 0.000471071 0.0\n",
      "_ 0.0033575 0.0\n",
      " 0.00113695 0.0\n",
      " 0.00438882 0.0\n",
      "_ 0.000566909 0.0\n",
      "_ 0.000939779 0.0\n",
      " 0.000492544 0.0\n",
      " 0.0075644 0.0\n",
      " 0.000997228 0.0\n",
      "_ 0.0 0.00281816\n",
      " 0.00818843 0.0\n",
      " 0.00107489 0.0\n",
      "_ 0.000280581 0.0\n",
      " 0.0 0.000656561\n",
      "_ 0.000297329 0.0\n",
      " 0.0 0.000304475\n",
      " 0.0 0.000312228\n",
      " 0.0125504 0.0\n",
      "_ 0.0 0.00074439\n",
      " 0.0 0.000495376\n",
      " 0.0 0.00274065\n",
      " 0.000512529 0.0\n",
      " 0.00107655 0.00146395\n",
      " 0.0 0.000204024\n",
      "_ 0.00239131 0.0\n",
      " 0.0 0.000320079\n",
      " 0.0 0.00284779\n",
      " 0.0 0.00253449\n",
      " 0.0 0.000579064\n",
      " 0.00321171 0.0\n",
      " 0.000501023 0.0\n",
      " 0.000406116 0.0\n",
      " 0.000469627 0.0\n",
      " 0.000463415 0.0\n",
      " 0.0 0.000259511\n",
      " 0.000105735 0.00302526\n",
      " 0.0 0.000959605\n",
      "_ 0.00384059 0.0\n",
      "_ 0.00384059 0.0\n",
      "_ 0.000506725 0.0\n",
      " 0.00386575 0.0\n",
      " 0.0 0.00155865\n",
      " 0.00384059 0.0\n",
      " 0.0 0.00232551\n",
      "_ 0.0 0.00281816\n"
     ]
    }
   ],
   "source": [
    "for idx in phi.index:\n",
    "    val = phi[topic_name][idx]\n",
    "    val_other = phi[other_topic_name][idx]\n",
    "    if val != 0 or val_other != 0:\n",
    "        print idx, val, val_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#   small dist  ,      \n",
    "# 2 :  th,       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_topics_to_remove_by_threshold(small_dist_opts, distances):\n",
    "    dist_threshold = 0.88\n",
    "    sorted_by_fun = sorted(small_dist_opts.values(), key = lambda x: x.fun)\n",
    "    topics_to_remove = []\n",
    "    for opt_res in sorted_by_fun:\n",
    "        topic_name = opt_res.optimized_column\n",
    "        # check not close to current topics to remove\n",
    "        dists_to_topics_to_remove = [distances[topic_name][t] for t in topics_to_remove]\n",
    "        is_far = np.all(np.array(dists_to_topics_to_remove) > dist_threshold)\n",
    "        if is_far:\n",
    "            topics_to_remove.append(topic_name)\n",
    "    return topics_to_remove\n",
    "def get_topics_to_remove_by_closest_dist(small_dist_opts, distances):\n",
    "    n_closest = 10\n",
    "    sorted_by_fun = sorted(small_dist_opts.values(), key = lambda x: x.fun)\n",
    "    topics_to_remove = []\n",
    "    for opt_res in sorted_by_fun:\n",
    "        topic_name = opt_res.optimized_column\n",
    "        # check not close to current topics to remove\n",
    "        is_closest = lambda topic, other_topic: np.any(distances[topic].sort_values().head(n_closest).index.values == other_topic)\n",
    "        dists_to_topics_to_remove = [not is_closest(topic_name, t) for t in topics_to_remove]\n",
    "        is_far = np.all(np.array(dists_to_topics_to_remove))\n",
    "        if is_far:\n",
    "            topics_to_remove.append(topic_name)\n",
    "    return topics_to_remove\n",
    "def remove_topics_from_phi(phi, topics_to_remove):\n",
    "    return phi.drop(topics_to_remove, axis=1)\n",
    "def remove_topics_from_distances(distances, topics_to_remove):\n",
    "    distances_convex_hull = distances.drop(topics_to_remove, axis=1)\n",
    "    distances_convex_hull = distances_convex_hull.drop(topics_to_remove, axis=0)\n",
    "    return distances_convex_hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_145:           \n",
      "topic_356: _          \n",
      "topic_327:   _   _     \n",
      "topic_184:          _ \n",
      "topic_117:           \n",
      "topic_38: _        _  \n",
      "topic_428:          _ _\n",
      "topic_373:       _    \n",
      "topic_230:           _\n",
      "topic_419:           \n",
      "topic_75:      _   _  \n",
      "topic_418:           _\n",
      "topic_272:   _ _       \n",
      "topic_127:         _  \n",
      "topic_140:           _\n"
     ]
    }
   ],
   "source": [
    "topics_to_remove_by_closest_dist = get_topics_to_remove_by_closest_dist(small_dist_opts, distances)\n",
    "print '\\n'.join([unicode_list_to_str(topic_name, saved_top_tokens[topic_name][0:11]) for topic_name in topics_to_remove_by_closest_dist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_145:           \n",
      "topic_356: _          \n",
      "topic_327:   _   _     \n",
      "topic_184:          _ \n",
      "topic_117:           \n",
      "topic_278:           \n",
      "topic_38: _        _  \n",
      "topic_78:    _ _     _ \n",
      "topic_428:          _ _\n",
      "topic_373:       _    \n",
      "topic_230:           _\n",
      "topic_419:           \n",
      "topic_83:        _ _  \n",
      "topic_75:      _   _  \n",
      "topic_418:           _\n",
      "topic_272:   _ _       \n",
      "topic_127:         _  \n",
      "topic_140:           _\n",
      "topic_3:           \n"
     ]
    }
   ],
   "source": [
    "topics_to_remove_by_threshold = get_topics_to_remove_by_threshold(small_dist_opts, distances)\n",
    "print '\\n'.join([unicode_list_to_str(topic_name, saved_top_tokens[topic_name][0:11]) for topic_name in topics_to_remove_by_threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_topics_to_remove(_opt_res, _phi_convex_hull, _distances_convex_hull, low_th, high_th):     \n",
    "    small_dist_opts = {col: _opt_res[col] for col in _phi_convex_hull.columns if _opt_res[col].fun < low_th}\n",
    "    large_dist_opts = {col: _opt_res[col] for col in _phi_convex_hull.columns if _opt_res[col].fun > high_th}\n",
    "    print len(small_dist_opts), len(large_dist_opts)\n",
    "    topics_to_remove_by_closest_dist = get_topics_to_remove_by_closest_dist(small_dist_opts, _distances_convex_hull)\n",
    "    print 'topics to remove = ', len(topics_to_remove_by_closest_dist)\n",
    "    print '\\n'.join([unicode_list_to_str(topic_name, saved_top_tokens[topic_name][0:11]) for topic_name in topics_to_remove_by_closest_dist])\n",
    "    return topics_to_remove_by_closest_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iteration = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016-12-11 00:49:22.214000] get_optimization_result for column 0\n",
      "[2016-12-11 00:49:22.624000] get_optimization_result for column 1\n",
      "[2016-12-11 00:49:23.036000] get_optimization_result for column 2\n",
      "[2016-12-11 00:49:23.277000] get_optimization_result for column 3\n",
      "[2016-12-11 00:49:23.828000] get_optimization_result for column 4\n",
      "[2016-12-11 00:49:24.208000] get_optimization_result for column 5\n",
      "[2016-12-11 00:49:24.961000] get_optimization_result for column 6\n",
      "[2016-12-11 00:49:25.269000] get_optimization_result for column 7\n",
      "[2016-12-11 00:49:25.655000] get_optimization_result for column 8\n",
      "[2016-12-11 00:49:26.290000] get_optimization_result for column 9\n",
      "[2016-12-11 00:49:27.021000] get_optimization_result for column 10\n",
      "[2016-12-11 00:49:27.272000] get_optimization_result for column 11\n",
      "[2016-12-11 00:49:27.590000] get_optimization_result for column 12\n",
      "[2016-12-11 00:49:28.038000] get_optimization_result for column 13\n",
      "[2016-12-11 00:49:28.771000] get_optimization_result for column 14\n",
      "[2016-12-11 00:49:29.057000] get_optimization_result for column 15\n",
      "[2016-12-11 00:49:29.396000] get_optimization_result for column 16\n",
      "[2016-12-11 00:49:29.698000] get_optimization_result for column 17\n",
      "[2016-12-11 00:49:29.969000] get_optimization_result for column 18\n",
      "[2016-12-11 00:49:31] get_optimization_result for column 19\n",
      "[2016-12-11 00:49:31.249000] get_optimization_result for column 20\n",
      "[2016-12-11 00:49:31.654000] get_optimization_result for column 21\n",
      "[2016-12-11 00:49:32.369000] get_optimization_result for column 22\n",
      "[2016-12-11 00:49:32.676000] get_optimization_result for column 23\n",
      "[2016-12-11 00:49:33.044000] get_optimization_result for column 24\n",
      "[2016-12-11 00:49:33.272000] get_optimization_result for column 25\n",
      "[2016-12-11 00:49:33.735000] get_optimization_result for column 26\n",
      "[2016-12-11 00:49:34.296000] get_optimization_result for column 27\n",
      "[2016-12-11 00:49:34.754000] get_optimization_result for column 28\n",
      "[2016-12-11 00:49:35.048000] get_optimization_result for column 29\n",
      "[2016-12-11 00:49:35.229000] get_optimization_result for column 30\n",
      "[2016-12-11 00:49:35.465000] get_optimization_result for column 31\n",
      "[2016-12-11 00:49:35.941000] get_optimization_result for column 32\n",
      "[2016-12-11 00:49:36.355000] get_optimization_result for column 33\n",
      "[2016-12-11 00:49:37.194000] get_optimization_result for column 34\n",
      "[2016-12-11 00:49:37.344000] get_optimization_result for column 35\n",
      "[2016-12-11 00:49:37.575000] get_optimization_result for column 36\n",
      "[2016-12-11 00:49:38.294000] get_optimization_result for column 37\n",
      "[2016-12-11 00:49:38.408000] get_optimization_result for column 38\n",
      "[2016-12-11 00:49:38.836000] get_optimization_result for column 39\n",
      "[2016-12-11 00:49:39.278000] get_optimization_result for column 40\n",
      "[2016-12-11 00:49:39.568000] get_optimization_result for column 41\n",
      "[2016-12-11 00:49:39.919000] get_optimization_result for column 42\n",
      "[2016-12-11 00:49:40.079000] get_optimization_result for column 43\n",
      "[2016-12-11 00:49:40.412000] get_optimization_result for column 44\n",
      "[2016-12-11 00:49:40.575000] get_optimization_result for column 45\n",
      "[2016-12-11 00:49:41.589000] get_optimization_result for column 46\n",
      "[2016-12-11 00:49:41.895000] get_optimization_result for column 47\n",
      "[2016-12-11 00:49:42.252000] get_optimization_result for column 48\n",
      "[2016-12-11 00:49:42.852000] get_optimization_result for column 49\n",
      "[2016-12-11 00:49:42.941000] get_optimization_result for column 50\n",
      "[2016-12-11 00:49:43.349000] get_optimization_result for column 51\n",
      "[2016-12-11 00:49:43.657000] get_optimization_result for column 52\n",
      "[2016-12-11 00:49:43.818000] get_optimization_result for column 53\n",
      "[2016-12-11 00:49:43.968000] get_optimization_result for column 54\n",
      "[2016-12-11 00:49:44.720000] get_optimization_result for column 55\n",
      "[2016-12-11 00:49:44.926000] get_optimization_result for column 56\n",
      "[2016-12-11 00:49:45.668000] get_optimization_result for column 57\n",
      "[2016-12-11 00:49:45.760000] get_optimization_result for column 58\n",
      "[2016-12-11 00:49:46.031000] get_optimization_result for column 59\n",
      "[2016-12-11 00:49:46.350000] get_optimization_result for column 60\n",
      "[2016-12-11 00:49:46.847000] get_optimization_result for column 61\n",
      "[2016-12-11 00:49:47.172000] get_optimization_result for column 62\n",
      "[2016-12-11 00:49:47.465000] get_optimization_result for column 63\n",
      "[2016-12-11 00:49:48.047000] get_optimization_result for column 64\n",
      "[2016-12-11 00:49:48.352000] get_optimization_result for column 65\n",
      "[2016-12-11 00:49:48.678000] get_optimization_result for column 66\n",
      "[2016-12-11 00:49:49.192000] get_optimization_result for column 67\n",
      "[2016-12-11 00:49:49.526000] get_optimization_result for column 68\n",
      "[2016-12-11 00:49:49.894000] get_optimization_result for column 69\n",
      "[2016-12-11 00:49:50.165000] get_optimization_result for column 70\n",
      "[2016-12-11 00:49:50.790000] get_optimization_result for column 71\n",
      "[2016-12-11 00:49:51.193000] get_optimization_result for column 72\n",
      "[2016-12-11 00:49:51.917000] get_optimization_result for column 73\n",
      "[2016-12-11 00:49:52.511000] get_optimization_result for column 74\n",
      "[2016-12-11 00:49:52.962000] get_optimization_result for column 75\n",
      "[2016-12-11 00:49:53.282000] get_optimization_result for column 76\n",
      "[2016-12-11 00:49:54.587000] get_optimization_result for column 77\n",
      "[2016-12-11 00:49:54.999000] get_optimization_result for column 78\n",
      "[2016-12-11 00:49:55.867000] get_optimization_result for column 79\n",
      "[2016-12-11 00:49:56.133000] get_optimization_result for column 80\n",
      "[2016-12-11 00:49:57.173000] get_optimization_result for column 81\n",
      "[2016-12-11 00:49:57.629000] get_optimization_result for column 82\n",
      "[2016-12-11 00:49:58.044000] get_optimization_result for column 83\n",
      "[2016-12-11 00:49:58.363000] get_optimization_result for column 84\n",
      "[2016-12-11 00:49:58.646000] get_optimization_result for column 85\n",
      "[2016-12-11 00:49:59.034000] get_optimization_result for column 86\n",
      "[2016-12-11 00:49:59.530000] get_optimization_result for column 87\n",
      "[2016-12-11 00:49:59.907000] get_optimization_result for column 88\n",
      "[2016-12-11 00:50:00.370000] get_optimization_result for column 89\n",
      "[2016-12-11 00:50:00.630000] get_optimization_result for column 90\n",
      "[2016-12-11 00:50:00.998000] get_optimization_result for column 91\n",
      "[2016-12-11 00:50:01.334000] get_optimization_result for column 92\n",
      "[2016-12-11 00:50:01.869000] get_optimization_result for column 93\n",
      "[2016-12-11 00:50:02.490000] get_optimization_result for column 94\n",
      "[2016-12-11 00:50:03.479000] get_optimization_result for column 95\n",
      "[2016-12-11 00:50:04.171000] get_optimization_result for column 96\n",
      "[2016-12-11 00:50:04.603000] get_optimization_result for column 97\n",
      "[2016-12-11 00:50:04.945000] get_optimization_result for column 98\n",
      "[2016-12-11 00:50:05.337000] get_optimization_result for column 99\n",
      "[2016-12-11 00:50:05.850000] get_optimization_result for column 100\n",
      "[2016-12-11 00:50:06.154000] get_optimization_result for column 101\n",
      "[2016-12-11 00:50:06.328000] get_optimization_result for column 102\n",
      "[2016-12-11 00:50:06.807000] get_optimization_result for column 103\n",
      "[2016-12-11 00:50:07.680000] get_optimization_result for column 104\n",
      "[2016-12-11 00:50:07.978000] get_optimization_result for column 105\n",
      "[2016-12-11 00:50:08.249000] get_optimization_result for column 106\n",
      "[2016-12-11 00:50:08.978000] get_optimization_result for column 107\n",
      "[2016-12-11 00:50:09.265000] get_optimization_result for column 108\n",
      "[2016-12-11 00:50:09.330000] get_optimization_result for column 109\n",
      "[2016-12-11 00:50:09.693000] get_optimization_result for column 110\n",
      "[2016-12-11 00:50:09.933000] get_optimization_result for column 111\n",
      "[2016-12-11 00:50:10.612000] get_optimization_result for column 112\n",
      "[2016-12-11 00:50:11.472000] get_optimization_result for column 113\n",
      "[2016-12-11 00:50:12.084000] get_optimization_result for column 114\n",
      "[2016-12-11 00:50:12.389000] get_optimization_result for column 115\n",
      "[2016-12-11 00:50:13.243000] get_optimization_result for column 116\n",
      "[2016-12-11 00:50:14.017000] get_optimization_result for column 117\n",
      "[2016-12-11 00:50:14.615000] get_optimization_result for column 118\n",
      "[2016-12-11 00:50:15.088000] get_optimization_result for column 119\n",
      "[2016-12-11 00:50:15.376000] get_optimization_result for column 120\n",
      "[2016-12-11 00:50:15.860000] get_optimization_result for column 121\n",
      "[2016-12-11 00:50:16.587000] get_optimization_result for column 122\n",
      "[2016-12-11 00:50:16.858000] get_optimization_result for column 123\n",
      "[2016-12-11 00:50:17.396000] get_optimization_result for column 124\n",
      "[2016-12-11 00:50:19.057000] get_optimization_result for column 125\n",
      "[2016-12-11 00:50:19.369000] get_optimization_result for column 126\n",
      "[2016-12-11 00:50:19.723000] get_optimization_result for column 127\n",
      "[2016-12-11 00:50:20.124000] get_optimization_result for column 128\n",
      "[2016-12-11 00:50:20.517000] get_optimization_result for column 129\n",
      "[2016-12-11 00:50:21.212000] get_optimization_result for column 130\n",
      "[2016-12-11 00:50:22.149000] get_optimization_result for column 131\n",
      "[2016-12-11 00:50:22.782000] get_optimization_result for column 132\n",
      "[2016-12-11 00:50:23.678000] get_optimization_result for column 133\n",
      "[2016-12-11 00:50:24.136000] get_optimization_result for column 134\n",
      "[2016-12-11 00:50:24.818000] get_optimization_result for column 135\n",
      "[2016-12-11 00:50:25.152000] get_optimization_result for column 136\n",
      "[2016-12-11 00:50:25.610000] get_optimization_result for column 137\n",
      "[2016-12-11 00:50:25.896000] get_optimization_result for column 138\n",
      "[2016-12-11 00:50:26.147000] get_optimization_result for column 139\n",
      "[2016-12-11 00:50:26.362000] get_optimization_result for column 140\n",
      "[2016-12-11 00:50:27.140000] get_optimization_result for column 141\n",
      "[2016-12-11 00:50:27.611000] get_optimization_result for column 142\n",
      "[2016-12-11 00:50:27.854000] get_optimization_result for column 143\n",
      "[2016-12-11 00:50:27.958000] get_optimization_result for column 144\n",
      "[2016-12-11 00:50:28.293000] get_optimization_result for column 145\n",
      "[2016-12-11 00:50:28.511000] get_optimization_result for column 146\n",
      "[2016-12-11 00:50:28.875000] get_optimization_result for column 147\n",
      "[2016-12-11 00:50:29.379000] get_optimization_result for column 148\n",
      "[2016-12-11 00:50:29.777000] get_optimization_result for column 149\n",
      "[2016-12-11 00:50:30.295000] get_optimization_result for column 150\n",
      "[2016-12-11 00:50:30.538000] get_optimization_result for column 151\n",
      "[2016-12-11 00:50:30.831000] get_optimization_result for column 152\n",
      "[2016-12-11 00:50:31.468000] get_optimization_result for column 153\n",
      "[2016-12-11 00:50:31.756000] get_optimization_result for column 154\n",
      "[2016-12-11 00:50:32.157000] get_optimization_result for column 155\n",
      "[2016-12-11 00:50:32.963000] get_optimization_result for column 156\n",
      "[2016-12-11 00:50:33.319000] get_optimization_result for column 157\n",
      "[2016-12-11 00:50:33.910000] get_optimization_result for column 158\n",
      "[2016-12-11 00:50:34.454000] get_optimization_result for column 159\n",
      "[2016-12-11 00:50:34.809000] get_optimization_result for column 160\n",
      "[2016-12-11 00:50:35.250000] get_optimization_result for column 161\n",
      "[2016-12-11 00:50:36.054000] get_optimization_result for column 162\n",
      "[2016-12-11 00:50:36.391000] get_optimization_result for column 163\n",
      "[2016-12-11 00:50:36.571000] get_optimization_result for column 164\n",
      "[2016-12-11 00:50:36.860000] get_optimization_result for column 165\n",
      "[2016-12-11 00:50:36.998000] get_optimization_result for column 166\n",
      "[2016-12-11 00:50:37.436000] get_optimization_result for column 167\n",
      "[2016-12-11 00:50:37.749000] get_optimization_result for column 168\n",
      "[2016-12-11 00:50:38.039000] get_optimization_result for column 169\n",
      "[2016-12-11 00:50:38.337000] get_optimization_result for column 170\n",
      "[2016-12-11 00:50:38.692000] get_optimization_result for column 171\n",
      "[2016-12-11 00:50:38.869000] get_optimization_result for column 172\n",
      "[2016-12-11 00:50:39.164000] get_optimization_result for column 173\n",
      "[2016-12-11 00:50:39.526000] get_optimization_result for column 174\n",
      "[2016-12-11 00:50:39.894000] get_optimization_result for column 175\n",
      "[2016-12-11 00:50:40.132000] get_optimization_result for column 176\n",
      "[2016-12-11 00:50:40.385000] get_optimization_result for column 177\n",
      "[2016-12-11 00:50:40.835000] get_optimization_result for column 178\n",
      "[2016-12-11 00:50:41.482000] get_optimization_result for column 179\n",
      "[2016-12-11 00:50:41.802000] get_optimization_result for column 180\n",
      "[2016-12-11 00:50:42.688000] get_optimization_result for column 181\n",
      "[2016-12-11 00:50:43.084000] get_optimization_result for column 182\n",
      "[2016-12-11 00:50:43.361000] get_optimization_result for column 183\n",
      "[2016-12-11 00:50:43.933000] get_optimization_result for column 184\n",
      "[2016-12-11 00:50:44.485000] get_optimization_result for column 185\n",
      "[2016-12-11 00:50:44.735000] get_optimization_result for column 186\n",
      "[2016-12-11 00:50:44.857000] get_optimization_result for column 187\n",
      "[2016-12-11 00:50:45.092000] get_optimization_result for column 188\n",
      "[2016-12-11 00:50:45.553000] get_optimization_result for column 189\n",
      "[2016-12-11 00:50:45.999000] get_optimization_result for column 190\n",
      "[2016-12-11 00:50:46.266000] get_optimization_result for column 191\n",
      "[2016-12-11 00:50:46.503000] get_optimization_result for column 192\n",
      "[2016-12-11 00:50:46.579000] get_optimization_result for column 193\n",
      "[2016-12-11 00:50:46.669000] get_optimization_result for column 194\n",
      "[2016-12-11 00:50:47.082000] get_optimization_result for column 195\n",
      "[2016-12-11 00:50:47.493000] get_optimization_result for column 196\n",
      "[2016-12-11 00:50:47.779000] get_optimization_result for column 197\n",
      "[2016-12-11 00:50:48.112000] get_optimization_result for column 198\n",
      "[2016-12-11 00:50:48.490000] get_optimization_result for column 199\n",
      "[2016-12-11 00:50:48.782000] get_optimization_result for column 200\n",
      "[2016-12-11 00:50:49.071000] get_optimization_result for column 201\n",
      "[2016-12-11 00:50:49.369000] get_optimization_result for column 202\n",
      "[2016-12-11 00:50:49.564000] get_optimization_result for column 203\n",
      "[2016-12-11 00:50:50.509000] get_optimization_result for column 204\n",
      "[2016-12-11 00:50:50.632000] get_optimization_result for column 205\n",
      "[2016-12-11 00:50:50.912000] get_optimization_result for column 206\n",
      "[2016-12-11 00:50:52.369000] get_optimization_result for column 207\n",
      "[2016-12-11 00:50:53.196000] get_optimization_result for column 208\n",
      "[2016-12-11 00:50:53.257000] get_optimization_result for column 209\n",
      "[2016-12-11 00:50:53.744000] get_optimization_result for column 210\n",
      "[2016-12-11 00:50:54.155000] get_optimization_result for column 211\n",
      "[2016-12-11 00:50:54.496000] get_optimization_result for column 212\n",
      "[2016-12-11 00:50:54.841000] get_optimization_result for column 213\n",
      "[2016-12-11 00:50:55.172000] get_optimization_result for column 214\n",
      "[2016-12-11 00:50:55.859000] get_optimization_result for column 215\n",
      "[2016-12-11 00:50:56.282000] get_optimization_result for column 216\n",
      "[2016-12-11 00:50:56.509000] get_optimization_result for column 217\n",
      "[2016-12-11 00:50:56.978000] get_optimization_result for column 218\n",
      "[2016-12-11 00:50:57.462000] get_optimization_result for column 219\n",
      "[2016-12-11 00:50:57.644000] get_optimization_result for column 220\n",
      "[2016-12-11 00:50:58.005000] get_optimization_result for column 221\n",
      "[2016-12-11 00:50:58.650000] get_optimization_result for column 222\n",
      "[2016-12-11 00:50:59.199000] get_optimization_result for column 223\n",
      "[2016-12-11 00:50:59.610000] get_optimization_result for column 224\n",
      "[2016-12-11 00:50:59.938000] get_optimization_result for column 225\n",
      "[2016-12-11 00:51:00.544000] get_optimization_result for column 226\n",
      "[2016-12-11 00:51:01.040000] get_optimization_result for column 227\n",
      "[2016-12-11 00:51:01.525000] get_optimization_result for column 228\n",
      "[2016-12-11 00:51:01.791000] get_optimization_result for column 229\n",
      "[2016-12-11 00:51:02.052000] get_optimization_result for column 230\n",
      "[2016-12-11 00:51:02.845000] get_optimization_result for column 231\n",
      "[2016-12-11 00:51:03.253000] get_optimization_result for column 232\n",
      "[2016-12-11 00:51:03.726000] get_optimization_result for column 233\n",
      "[2016-12-11 00:51:04.565000] get_optimization_result for column 234\n",
      "[2016-12-11 00:51:04.874000] get_optimization_result for column 235\n",
      "[2016-12-11 00:51:05.696000] get_optimization_result for column 236\n",
      "[2016-12-11 00:51:06.177000] get_optimization_result for column 237\n",
      "[2016-12-11 00:51:06.512000] get_optimization_result for column 238\n",
      "[2016-12-11 00:51:06.897000] get_optimization_result for column 239\n",
      "[2016-12-11 00:51:07.396000] get_optimization_result for column 240\n",
      "[2016-12-11 00:51:07.875000] get_optimization_result for column 241\n",
      "[2016-12-11 00:51:08.226000] get_optimization_result for column 242\n",
      "[2016-12-11 00:51:09.152000] get_optimization_result for column 243\n",
      "[2016-12-11 00:51:09.768000] get_optimization_result for column 244\n",
      "[2016-12-11 00:51:10.202000] get_optimization_result for column 245\n",
      "[2016-12-11 00:51:10.363000] get_optimization_result for column 246\n",
      "[2016-12-11 00:51:10.568000] get_optimization_result for column 247\n",
      "[2016-12-11 00:51:11.063000] get_optimization_result for column 248\n",
      "[2016-12-11 00:51:11.472000] get_optimization_result for column 249\n",
      "[2016-12-11 00:51:11.926000] get_optimization_result for column 250\n",
      "[2016-12-11 00:51:12.451000] get_optimization_result for column 251\n",
      "[2016-12-11 00:51:12.778000] get_optimization_result for column 252\n",
      "[2016-12-11 00:51:13.095000] get_optimization_result for column 253\n",
      "[2016-12-11 00:51:13.564000] get_optimization_result for column 254\n",
      "[2016-12-11 00:51:14.481000] get_optimization_result for column 255\n",
      "[2016-12-11 00:51:14.680000] get_optimization_result for column 256\n",
      "[2016-12-11 00:51:14.811000] get_optimization_result for column 257\n",
      "[2016-12-11 00:51:15.458000] get_optimization_result for column 258\n",
      "[2016-12-11 00:51:15.935000] get_optimization_result for column 259\n",
      "[2016-12-11 00:51:16.028000] get_optimization_result for column 260\n",
      "[2016-12-11 00:51:16.399000] get_optimization_result for column 261\n",
      "[2016-12-11 00:51:16.604000] get_optimization_result for column 262\n",
      "[2016-12-11 00:51:16.921000] get_optimization_result for column 263\n",
      "[2016-12-11 00:51:17.443000] get_optimization_result for column 264\n",
      "[2016-12-11 00:51:17.813000] get_optimization_result for column 265\n",
      "[2016-12-11 00:51:18.042000] get_optimization_result for column 266\n",
      "[2016-12-11 00:51:18.454000] get_optimization_result for column 267\n",
      "[2016-12-11 00:51:18.790000] get_optimization_result for column 268\n",
      "[2016-12-11 00:51:19.306000] get_optimization_result for column 269\n",
      "[2016-12-11 00:51:20.173000] get_optimization_result for column 270\n",
      "[2016-12-11 00:51:20.800000] get_optimization_result for column 271\n",
      "[2016-12-11 00:51:22.221000] get_optimization_result for column 272\n",
      "[2016-12-11 00:51:22.525000] get_optimization_result for column 273\n",
      "[2016-12-11 00:51:22.968000] get_optimization_result for column 274\n",
      "[2016-12-11 00:51:23.241000] get_optimization_result for column 275\n",
      "[2016-12-11 00:51:23.606000] get_optimization_result for column 276\n",
      "[2016-12-11 00:51:23.795000] get_optimization_result for column 277\n",
      "[2016-12-11 00:51:24.294000] get_optimization_result for column 278\n",
      "[2016-12-11 00:51:25.054000] get_optimization_result for column 279\n",
      "[2016-12-11 00:51:25.561000] get_optimization_result for column 280\n",
      "[2016-12-11 00:51:26.024000] get_optimization_result for column 281\n",
      "[2016-12-11 00:51:26.641000] get_optimization_result for column 282\n",
      "[2016-12-11 00:51:27.030000] get_optimization_result for column 283\n",
      "[2016-12-11 00:51:27.533000] get_optimization_result for column 284\n",
      "[2016-12-11 00:51:27.817000] get_optimization_result for column 285\n",
      "[2016-12-11 00:51:28.121000] get_optimization_result for column 286\n",
      "[2016-12-11 00:51:28.484000] get_optimization_result for column 287\n",
      "[2016-12-11 00:51:28.733000] get_optimization_result for column 288\n",
      "[2016-12-11 00:51:29.063000] get_optimization_result for column 289\n",
      "[2016-12-11 00:51:29.501000] get_optimization_result for column 290\n",
      "[2016-12-11 00:51:30.013000] get_optimization_result for column 291\n",
      "[2016-12-11 00:51:30.493000] get_optimization_result for column 292\n",
      "[2016-12-11 00:51:31.136000] get_optimization_result for column 293\n",
      "[2016-12-11 00:51:31.448000] get_optimization_result for column 294\n",
      "[2016-12-11 00:51:31.997000] get_optimization_result for column 295\n",
      "[2016-12-11 00:51:32.378000] get_optimization_result for column 296\n",
      "[2016-12-11 00:51:32.835000] get_optimization_result for column 297\n",
      "[2016-12-11 00:51:33.276000] get_optimization_result for column 298\n",
      "[2016-12-11 00:51:33.707000] get_optimization_result for column 299\n",
      "[2016-12-11 00:51:34.050000] get_optimization_result for column 300\n",
      "[2016-12-11 00:51:34.666000] get_optimization_result for column 301\n",
      "[2016-12-11 00:51:35.032000] get_optimization_result for column 302\n",
      "[2016-12-11 00:51:35.275000] get_optimization_result for column 303\n",
      "[2016-12-11 00:51:35.461000] get_optimization_result for column 304\n",
      "[2016-12-11 00:51:35.777000] get_optimization_result for column 305\n",
      "[2016-12-11 00:51:36.194000] get_optimization_result for column 306\n",
      "[2016-12-11 00:51:36.606000] get_optimization_result for column 307\n",
      "[2016-12-11 00:51:36.901000] get_optimization_result for column 308\n",
      "[2016-12-11 00:51:37.459000] get_optimization_result for column 309\n",
      "[2016-12-11 00:51:37.836000] get_optimization_result for column 310\n",
      "[2016-12-11 00:51:38.251000] get_optimization_result for column 311\n",
      "[2016-12-11 00:51:38.480000] get_optimization_result for column 312\n",
      "[2016-12-11 00:51:38.563000] get_optimization_result for column 313\n",
      "[2016-12-11 00:51:38.981000] get_optimization_result for column 314\n",
      "[2016-12-11 00:51:39.338000] get_optimization_result for column 315\n",
      "[2016-12-11 00:51:39.995000] get_optimization_result for column 316\n",
      "[2016-12-11 00:51:40.334000] get_optimization_result for column 317\n",
      "[2016-12-11 00:51:40.466000] get_optimization_result for column 318\n",
      "[2016-12-11 00:51:40.847000] get_optimization_result for column 319\n",
      "[2016-12-11 00:51:41.249000] get_optimization_result for column 320\n",
      "[2016-12-11 00:51:41.896000] get_optimization_result for column 321\n",
      "[2016-12-11 00:51:43.031000] get_optimization_result for column 322\n",
      "[2016-12-11 00:51:43.930000] get_optimization_result for column 323\n",
      "[2016-12-11 00:51:44.397000] get_optimization_result for column 324\n",
      "[2016-12-11 00:51:44.844000] get_optimization_result for column 325\n",
      "[2016-12-11 00:51:45.109000] get_optimization_result for column 326\n",
      "[2016-12-11 00:51:45.371000] get_optimization_result for column 327\n",
      "[2016-12-11 00:51:45.710000] get_optimization_result for column 328\n",
      "[2016-12-11 00:51:46.278000] get_optimization_result for column 329\n",
      "[2016-12-11 00:51:46.599000] get_optimization_result for column 330\n",
      "[2016-12-11 00:51:46.851000] get_optimization_result for column 331\n",
      "[2016-12-11 00:51:47.507000] get_optimization_result for column 332\n",
      "[2016-12-11 00:51:47.981000] get_optimization_result for column 333\n",
      "[2016-12-11 00:51:48.255000] get_optimization_result for column 334\n",
      "[2016-12-11 00:51:48.669000] get_optimization_result for column 335\n",
      "[2016-12-11 00:51:49.115000] get_optimization_result for column 336\n",
      "[2016-12-11 00:51:49.600000] get_optimization_result for column 337\n",
      "[2016-12-11 00:51:50.023000] get_optimization_result for column 338\n",
      "[2016-12-11 00:51:50.662000] get_optimization_result for column 339\n",
      "[2016-12-11 00:51:50.981000] get_optimization_result for column 340\n",
      "[2016-12-11 00:51:51.616000] get_optimization_result for column 341\n",
      "[2016-12-11 00:51:51.927000] get_optimization_result for column 342\n",
      "[2016-12-11 00:51:52.159000] get_optimization_result for column 343\n",
      "[2016-12-11 00:51:52.521000] get_optimization_result for column 344\n",
      "[2016-12-11 00:51:53.084000] get_optimization_result for column 345\n",
      "[2016-12-11 00:51:53.503000] get_optimization_result for column 346\n",
      "[2016-12-11 00:51:53.892000] get_optimization_result for column 347\n",
      "[2016-12-11 00:51:54.393000] get_optimization_result for column 348\n",
      "[2016-12-11 00:51:54.749000] get_optimization_result for column 349\n",
      "[2016-12-11 00:51:56.459000] get_optimization_result for column 350\n",
      "[2016-12-11 00:51:56.746000] get_optimization_result for column 351\n",
      "[2016-12-11 00:51:57.014000] get_optimization_result for column 352\n",
      "[2016-12-11 00:51:57.965000] get_optimization_result for column 353\n",
      "[2016-12-11 00:51:58.423000] get_optimization_result for column 354\n",
      "[2016-12-11 00:51:58.689000] get_optimization_result for column 355\n",
      "[2016-12-11 00:51:58.969000] get_optimization_result for column 356\n",
      "[2016-12-11 00:51:59.109000] get_optimization_result for column 357\n",
      "[2016-12-11 00:51:59.554000] get_optimization_result for column 358\n",
      "[2016-12-11 00:51:59.879000] get_optimization_result for column 359\n",
      "[2016-12-11 00:52:00.206000] get_optimization_result for column 360\n",
      "[2016-12-11 00:52:00.437000] get_optimization_result for column 361\n",
      "[2016-12-11 00:52:01.079000] get_optimization_result for column 362\n",
      "[2016-12-11 00:52:01.625000] get_optimization_result for column 363\n",
      "[2016-12-11 00:52:02.509000] get_optimization_result for column 364\n",
      "[2016-12-11 00:52:02.944000] get_optimization_result for column 365\n",
      "[2016-12-11 00:52:03.309000] get_optimization_result for column 366\n",
      "[2016-12-11 00:52:03.825000] get_optimization_result for column 367\n",
      "[2016-12-11 00:52:04.231000] get_optimization_result for column 368\n",
      "[2016-12-11 00:52:04.526000] get_optimization_result for column 369\n",
      "[2016-12-11 00:52:04.702000] get_optimization_result for column 370\n",
      "[2016-12-11 00:52:04.987000] get_optimization_result for column 371\n",
      "[2016-12-11 00:52:05.233000] get_optimization_result for column 372\n",
      "[2016-12-11 00:52:05.479000] get_optimization_result for column 373\n",
      "[2016-12-11 00:52:06.063000] get_optimization_result for column 374\n",
      "[2016-12-11 00:52:06.795000] get_optimization_result for column 375\n",
      "[2016-12-11 00:52:07.074000] get_optimization_result for column 376\n",
      "[2016-12-11 00:52:07.515000] get_optimization_result for column 377\n",
      "[2016-12-11 00:52:07.881000] get_optimization_result for column 378\n",
      "[2016-12-11 00:52:08.648000] get_optimization_result for column 379\n",
      "[2016-12-11 00:52:09.289000] get_optimization_result for column 380\n",
      "[2016-12-11 00:52:09.694000] get_optimization_result for column 381\n",
      "[2016-12-11 00:52:09.971000] get_optimization_result for column 382\n",
      "[2016-12-11 00:52:10.465000] get_optimization_result for column 383\n",
      "[2016-12-11 00:52:10.791000] get_optimization_result for column 384\n",
      "[2016-12-11 00:52:11.345000] get_optimization_result for column 385\n",
      "[2016-12-11 00:52:11.745000] get_optimization_result for column 386\n",
      "[2016-12-11 00:52:12.231000] get_optimization_result for column 387\n",
      "[2016-12-11 00:52:12.767000] get_optimization_result for column 388\n",
      "[2016-12-11 00:52:12.988000] get_optimization_result for column 389\n",
      "[2016-12-11 00:52:13.825000] get_optimization_result for column 390\n",
      "[2016-12-11 00:52:14.234000] get_optimization_result for column 391\n",
      "[2016-12-11 00:52:14.742000] get_optimization_result for column 392\n",
      "[2016-12-11 00:52:15.173000] get_optimization_result for column 393\n",
      "[2016-12-11 00:52:15.559000] get_optimization_result for column 394\n",
      "[2016-12-11 00:52:15.852000] get_optimization_result for column 395\n",
      "[2016-12-11 00:52:16.229000] get_optimization_result for column 396\n",
      "[2016-12-11 00:52:16.354000] get_optimization_result for column 397\n",
      "[2016-12-11 00:52:16.587000] get_optimization_result for column 398\n",
      "[2016-12-11 00:52:17.178000] get_optimization_result for column 399\n",
      "[2016-12-11 00:52:17.670000] get_optimization_result for column 400\n",
      "[2016-12-11 00:52:18.500000] get_optimization_result for column 401\n",
      "[2016-12-11 00:52:18.890000] get_optimization_result for column 402\n",
      "[2016-12-11 00:52:19.304000] get_optimization_result for column 403\n",
      "[2016-12-11 00:52:19.778000] get_optimization_result for column 404\n",
      "[2016-12-11 00:52:20.506000] get_optimization_result for column 405\n",
      "[2016-12-11 00:52:20.784000] get_optimization_result for column 406\n",
      "[2016-12-11 00:52:21.142000] get_optimization_result for column 407\n",
      "[2016-12-11 00:52:21.503000] get_optimization_result for column 408\n",
      "[2016-12-11 00:52:21.927000] get_optimization_result for column 409\n",
      "[2016-12-11 00:52:22.185000] get_optimization_result for column 410\n",
      "[2016-12-11 00:52:22.763000] get_optimization_result for column 411\n",
      "[2016-12-11 00:52:22.931000] get_optimization_result for column 412\n",
      "[2016-12-11 00:52:23.162000] get_optimization_result for column 413\n",
      "[2016-12-11 00:52:23.536000] get_optimization_result for column 414\n",
      "[2016-12-11 00:52:23.899000] get_optimization_result for column 415\n",
      "[2016-12-11 00:52:24.179000] get_optimization_result for column 416\n",
      "[2016-12-11 00:52:24.713000] get_optimization_result for column 417\n",
      "[2016-12-11 00:52:24.963000] get_optimization_result for column 418\n",
      "[2016-12-11 00:52:25.137000] get_optimization_result for column 419\n",
      "[2016-12-11 00:52:25.493000] get_optimization_result for column 420\n",
      "[2016-12-11 00:52:25.948000] get_optimization_result for column 421\n",
      "[2016-12-11 00:52:26.383000] get_optimization_result for column 422\n",
      "[2016-12-11 00:52:26.566000] get_optimization_result for column 423\n",
      "[2016-12-11 00:52:27.048000] get_optimization_result for column 424\n",
      "[2016-12-11 00:52:27.775000] get_optimization_result for column 425\n",
      "[2016-12-11 00:52:28.228000] get_optimization_result for column 426\n",
      "[2016-12-11 00:52:28.635000] get_optimization_result for column 427\n",
      "[2016-12-11 00:52:29.040000] get_optimization_result for column 428\n",
      "[2016-12-11 00:52:29.485000] get_optimization_result for column 429\n",
      "[2016-12-11 00:52:30.080000] get_optimization_result for column 430\n",
      "[2016-12-11 00:52:30.281000] get_optimization_result for column 431\n",
      "[2016-12-11 00:52:30.772000] get_optimization_result for column 432\n",
      "[2016-12-11 00:52:31.095000] get_optimization_result for column 433\n",
      "[2016-12-11 00:52:31.541000] get_optimization_result for column 434\n",
      "[2016-12-11 00:52:31.873000] get_optimization_result for column 435\n",
      "[2016-12-11 00:52:32.217000] get_optimization_result for column 436\n",
      "[2016-12-11 00:52:32.382000] get_optimization_result for column 437\n",
      "[2016-12-11 00:52:32.581000] get_optimization_result for column 438\n",
      "[2016-12-11 00:52:32.997000] get_optimization_result for column 439\n",
      "[2016-12-11 00:52:33.316000] get_optimization_result for column 440\n",
      "[2016-12-11 00:52:34.150000] get_optimization_result for column 441\n",
      "[2016-12-11 00:52:34.536000] get_optimization_result for column 442\n",
      "[2016-12-11 00:52:34.774000] get_optimization_result for column 443\n",
      "[2016-12-11 00:52:35.019000] get_optimization_result for column 444\n",
      "[2016-12-11 00:52:35.530000] get_optimization_result for column 445\n",
      "[2016-12-11 00:52:35.838000] get_optimization_result for column 446\n",
      "[2016-12-11 00:52:36.371000] get_optimization_result for column 447\n",
      "[2016-12-11 00:52:36.744000] get_optimization_result for column 448\n",
      "[2016-12-11 00:52:37.070000] get_optimization_result for column 449\n",
      "[2016-12-11 00:52:37.408000] get_optimization_result for column 450\n",
      "[2016-12-11 00:52:38.283000] get_optimization_result for column 451\n",
      "[2016-12-11 00:52:38.471000] get_optimization_result for column 452\n",
      "[2016-12-11 00:52:38.895000] get_optimization_result for column 453\n",
      "[2016-12-11 00:52:39.152000] get_optimization_result for column 454\n",
      "[2016-12-11 00:52:39.637000] get_optimization_result for column 455\n",
      "[2016-12-11 00:52:40.204000] get_optimization_result for column 456\n",
      "[2016-12-11 00:52:40.559000] get_optimization_result for column 457\n",
      "[2016-12-11 00:52:40.816000] get_optimization_result for column 458\n",
      "[2016-12-11 00:52:40.982000] get_optimization_result for column 459\n",
      "[2016-12-11 00:52:41.207000] get_optimization_result for column 460\n",
      "[2016-12-11 00:52:41.419000] get_optimization_result for column 461\n",
      "[2016-12-11 00:52:41.718000] get_optimization_result for column 462\n",
      "[2016-12-11 00:52:42.061000] get_optimization_result for column 463\n",
      "[2016-12-11 00:52:42.350000] get_optimization_result for column 464\n",
      "[2016-12-11 00:52:42.729000] get_optimization_result for column 465\n",
      "[2016-12-11 00:52:43.538000] get_optimization_result for column 466\n",
      "[2016-12-11 00:52:44.240000] get_optimization_result for column 467\n",
      "[2016-12-11 00:52:44.585000] get_optimization_result for column 468\n",
      "[2016-12-11 00:52:45.409000] get_optimization_result for column 469\n",
      "[2016-12-11 00:52:46.071000] get_optimization_result for column 470\n",
      "[2016-12-11 00:52:46.511000] get_optimization_result for column 471\n",
      "[2016-12-11 00:52:46.811000] get_optimization_result for column 472\n",
      "[2016-12-11 00:52:47.139000] get_optimization_result for column 473\n",
      "[2016-12-11 00:52:47.514000] get_optimization_result for column 474\n",
      "[2016-12-11 00:52:47.905000] get_optimization_result for column 475\n",
      "[2016-12-11 00:52:48.672000] get_optimization_result for column 476\n",
      "[2016-12-11 00:52:49.294000] get_optimization_result for column 477\n",
      "[2016-12-11 00:52:49.724000] get_optimization_result for column 478\n",
      "[2016-12-11 00:52:50.161000] get_optimization_result for column 479\n",
      "[2016-12-11 00:52:50.564000] get_optimization_result for column 480\n",
      "[2016-12-11 00:52:50.784000] get_optimization_result for column 481\n",
      "[2016-12-11 00:52:51.310000] get_optimization_result for column 482\n",
      "[2016-12-11 00:52:51.563000] get_optimization_result for column 483\n",
      "[2016-12-11 00:52:52.211000] get_optimization_result for column 484\n"
     ]
    }
   ],
   "source": [
    "ds2 = get_optimization_result(hellinger_dist, None, phi_convex_hull, distances_convex_hull)\n",
    "ds = ds2\n",
    "save_pickle_file(ds, 'dists_h_none2.p')\n",
    "fs = [ds[col].fun for col in phi_convex_hull.columns]\n",
    "sns.distplot(fs, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 8\n",
      "topics to remove =  9\n",
      "topic_57:   _       _ \n",
      "topic_355:     _      \n",
      "topic_278:           \n",
      "topic_439:  _   _      \n",
      "topic_92:           \n",
      "topic_358:         _  \n",
      "topic_83:        _ _  \n",
      "topic_475:   _      _  \n",
      "topic_3:           \n"
     ]
    }
   ],
   "source": [
    "low_th, high_th = 0.76, 0.89\n",
    "topics_to_remove_by_closest_dist = find_topics_to_remove(ds,  phi_convex_hull, distances_convex_hull, low_th, high_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phi_convex_hull = remove_topics_from_phi(phi_convex_hull, topics_to_remove_by_closest_dist)\n",
    "distances_convex_hull = remove_topics_from_distances(distances_convex_hull, topics_to_remove_by_closest_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iteration = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016-12-11 00:57:49.218000] get_optimization_result for column 0\n",
      "[2016-12-11 00:57:49.840000] get_optimization_result for column 1\n",
      "[2016-12-11 00:57:50.233000] get_optimization_result for column 2\n",
      "[2016-12-11 00:57:50.500000] get_optimization_result for column 3\n",
      "[2016-12-11 00:57:50.969000] get_optimization_result for column 4\n",
      "[2016-12-11 00:57:51.263000] get_optimization_result for column 5\n",
      "[2016-12-11 00:57:51.586000] get_optimization_result for column 6\n",
      "[2016-12-11 00:57:51.941000] get_optimization_result for column 7\n",
      "[2016-12-11 00:57:52.421000] get_optimization_result for column 8\n",
      "[2016-12-11 00:57:52.799000] get_optimization_result for column 9\n",
      "[2016-12-11 00:57:53.323000] get_optimization_result for column 10\n",
      "[2016-12-11 00:57:53.519000] get_optimization_result for column 11\n",
      "[2016-12-11 00:57:54.463000] get_optimization_result for column 12\n",
      "[2016-12-11 00:57:55.475000] get_optimization_result for column 13\n",
      "[2016-12-11 00:57:55.799000] get_optimization_result for column 14\n",
      "[2016-12-11 00:57:56.122000] get_optimization_result for column 15\n",
      "[2016-12-11 00:57:56.306000] get_optimization_result for column 16\n",
      "[2016-12-11 00:57:56.572000] get_optimization_result for column 17\n",
      "[2016-12-11 00:57:57.173000] get_optimization_result for column 18\n",
      "[2016-12-11 00:57:57.481000] get_optimization_result for column 19\n",
      "[2016-12-11 00:57:57.626000] get_optimization_result for column 20\n",
      "[2016-12-11 00:57:58.674000] get_optimization_result for column 21\n",
      "[2016-12-11 00:57:59.010000] get_optimization_result for column 22\n",
      "[2016-12-11 00:57:59.484000] get_optimization_result for column 23\n",
      "[2016-12-11 00:57:59.800000] get_optimization_result for column 24\n",
      "[2016-12-11 00:58:00.235000] get_optimization_result for column 25\n",
      "[2016-12-11 00:58:00.863000] get_optimization_result for column 26\n",
      "[2016-12-11 00:58:01.433000] get_optimization_result for column 27\n",
      "[2016-12-11 00:58:01.833000] get_optimization_result for column 28\n",
      "[2016-12-11 00:58:02.210000] get_optimization_result for column 29\n",
      "[2016-12-11 00:58:02.609000] get_optimization_result for column 30\n",
      "[2016-12-11 00:58:02.819000] get_optimization_result for column 31\n",
      "[2016-12-11 00:58:03.176000] get_optimization_result for column 32\n",
      "[2016-12-11 00:58:04.015000] get_optimization_result for column 33\n",
      "[2016-12-11 00:58:04.561000] get_optimization_result for column 34\n",
      "[2016-12-11 00:58:04.919000] get_optimization_result for column 35\n",
      "[2016-12-11 00:58:05.721000] get_optimization_result for column 36\n",
      "[2016-12-11 00:58:06.352000] get_optimization_result for column 37\n",
      "[2016-12-11 00:58:06.680000] get_optimization_result for column 38\n",
      "[2016-12-11 00:58:07.102000] get_optimization_result for column 39\n",
      "[2016-12-11 00:58:07.330000] get_optimization_result for column 40\n",
      "[2016-12-11 00:58:07.538000] get_optimization_result for column 41\n",
      "[2016-12-11 00:58:08.228000] get_optimization_result for column 42\n",
      "[2016-12-11 00:58:08.458000] get_optimization_result for column 43\n",
      "[2016-12-11 00:58:08.740000] get_optimization_result for column 44\n",
      "[2016-12-11 00:58:09.124000] get_optimization_result for column 45\n",
      "[2016-12-11 00:58:09.427000] get_optimization_result for column 46\n",
      "[2016-12-11 00:58:09.492000] get_optimization_result for column 47\n",
      "[2016-12-11 00:58:09.973000] get_optimization_result for column 48\n",
      "[2016-12-11 00:58:10.369000] get_optimization_result for column 49\n",
      "[2016-12-11 00:58:11.006000] get_optimization_result for column 50\n",
      "[2016-12-11 00:58:11.366000] get_optimization_result for column 51\n",
      "[2016-12-11 00:58:11.553000] get_optimization_result for column 52\n",
      "[2016-12-11 00:58:11.857000] get_optimization_result for column 53\n",
      "[2016-12-11 00:58:12.722000] get_optimization_result for column 54\n",
      "[2016-12-11 00:58:12.882000] get_optimization_result for column 55\n",
      "[2016-12-11 00:58:13.630000] get_optimization_result for column 56\n",
      "[2016-12-11 00:58:13.973000] get_optimization_result for column 57\n",
      "[2016-12-11 00:58:14.291000] get_optimization_result for column 58\n",
      "[2016-12-11 00:58:14.706000] get_optimization_result for column 59\n",
      "[2016-12-11 00:58:14.972000] get_optimization_result for column 60\n",
      "[2016-12-11 00:58:15.268000] get_optimization_result for column 61\n",
      "[2016-12-11 00:58:15.882000] get_optimization_result for column 62\n",
      "[2016-12-11 00:58:16.293000] get_optimization_result for column 63\n",
      "[2016-12-11 00:58:16.732000] get_optimization_result for column 64\n",
      "[2016-12-11 00:58:17.302000] get_optimization_result for column 65\n",
      "[2016-12-11 00:58:17.635000] get_optimization_result for column 66\n",
      "[2016-12-11 00:58:17.988000] get_optimization_result for column 67\n",
      "[2016-12-11 00:58:18.289000] get_optimization_result for column 68\n",
      "[2016-12-11 00:58:18.854000] get_optimization_result for column 69\n",
      "[2016-12-11 00:58:19.377000] get_optimization_result for column 70\n",
      "[2016-12-11 00:58:20.415000] get_optimization_result for column 71\n",
      "[2016-12-11 00:58:20.669000] get_optimization_result for column 72\n",
      "[2016-12-11 00:58:21.307000] get_optimization_result for column 73\n",
      "[2016-12-11 00:58:21.519000] get_optimization_result for column 74\n",
      "[2016-12-11 00:58:21.999000] get_optimization_result for column 75\n",
      "[2016-12-11 00:58:22.318000] get_optimization_result for column 76\n",
      "[2016-12-11 00:58:22.995000] get_optimization_result for column 77\n",
      "[2016-12-11 00:58:23.387000] get_optimization_result for column 78\n",
      "[2016-12-11 00:58:24.079000] get_optimization_result for column 79\n",
      "[2016-12-11 00:58:25.076000] get_optimization_result for column 80\n",
      "[2016-12-11 00:58:25.564000] get_optimization_result for column 81\n",
      "[2016-12-11 00:58:25.902000] get_optimization_result for column 82\n",
      "[2016-12-11 00:58:26.037000] get_optimization_result for column 83\n",
      "[2016-12-11 00:58:26.198000] get_optimization_result for column 84\n",
      "[2016-12-11 00:58:26.598000] get_optimization_result for column 85\n",
      "[2016-12-11 00:58:27.104000] get_optimization_result for column 86\n",
      "[2016-12-11 00:58:27.410000] get_optimization_result for column 87\n",
      "[2016-12-11 00:58:27.597000] get_optimization_result for column 88\n",
      "[2016-12-11 00:58:28.275000] get_optimization_result for column 89\n",
      "[2016-12-11 00:58:29.469000] get_optimization_result for column 90\n",
      "[2016-12-11 00:58:30.208000] get_optimization_result for column 91\n",
      "[2016-12-11 00:58:30.493000] get_optimization_result for column 92\n",
      "[2016-12-11 00:58:31.110000] get_optimization_result for column 93\n",
      "[2016-12-11 00:58:31.452000] get_optimization_result for column 94\n",
      "[2016-12-11 00:58:31.741000] get_optimization_result for column 95\n",
      "[2016-12-11 00:58:32.778000] get_optimization_result for column 96\n",
      "[2016-12-11 00:58:33.063000] get_optimization_result for column 97\n",
      "[2016-12-11 00:58:33.687000] get_optimization_result for column 98\n",
      "[2016-12-11 00:58:34.159000] get_optimization_result for column 99\n",
      "[2016-12-11 00:58:34.624000] get_optimization_result for column 100\n",
      "[2016-12-11 00:58:34.786000] get_optimization_result for column 101\n",
      "[2016-12-11 00:58:35.065000] get_optimization_result for column 102\n",
      "[2016-12-11 00:58:35.465000] get_optimization_result for column 103\n",
      "[2016-12-11 00:58:35.823000] get_optimization_result for column 104\n",
      "[2016-12-11 00:58:36.045000] get_optimization_result for column 105\n",
      "[2016-12-11 00:58:36.518000] get_optimization_result for column 106\n",
      "[2016-12-11 00:58:36.730000] get_optimization_result for column 107\n",
      "[2016-12-11 00:58:37.095000] get_optimization_result for column 108\n",
      "[2016-12-11 00:58:37.442000] get_optimization_result for column 109\n",
      "[2016-12-11 00:58:37.901000] get_optimization_result for column 110\n",
      "[2016-12-11 00:58:38.105000] get_optimization_result for column 111\n",
      "[2016-12-11 00:58:38.721000] get_optimization_result for column 112\n",
      "[2016-12-11 00:58:39.464000] get_optimization_result for column 113\n",
      "[2016-12-11 00:58:39.969000] get_optimization_result for column 114\n",
      "[2016-12-11 00:58:40.414000] get_optimization_result for column 115\n",
      "[2016-12-11 00:58:40.778000] get_optimization_result for column 116\n",
      "[2016-12-11 00:58:41.114000] get_optimization_result for column 117\n",
      "[2016-12-11 00:58:41.294000] get_optimization_result for column 118\n",
      "[2016-12-11 00:58:41.601000] get_optimization_result for column 119\n",
      "[2016-12-11 00:58:41.962000] get_optimization_result for column 120\n",
      "[2016-12-11 00:58:42.711000] get_optimization_result for column 121\n",
      "[2016-12-11 00:58:43.081000] get_optimization_result for column 122\n",
      "[2016-12-11 00:58:43.351000] get_optimization_result for column 123\n",
      "[2016-12-11 00:58:44.052000] get_optimization_result for column 124\n",
      "[2016-12-11 00:58:44.475000] get_optimization_result for column 125\n",
      "[2016-12-11 00:58:45.178000] get_optimization_result for column 126\n",
      "[2016-12-11 00:58:45.801000] get_optimization_result for column 127\n",
      "[2016-12-11 00:58:46.121000] get_optimization_result for column 128\n",
      "[2016-12-11 00:58:47.273000] get_optimization_result for column 129\n",
      "[2016-12-11 00:58:48.184000] get_optimization_result for column 130\n",
      "[2016-12-11 00:58:48.493000] get_optimization_result for column 131\n",
      "[2016-12-11 00:58:48.812000] get_optimization_result for column 132\n",
      "[2016-12-11 00:58:48.904000] get_optimization_result for column 133\n",
      "[2016-12-11 00:58:49.444000] get_optimization_result for column 134\n",
      "[2016-12-11 00:58:49.680000] get_optimization_result for column 135\n",
      "[2016-12-11 00:58:49.907000] get_optimization_result for column 136\n",
      "[2016-12-11 00:58:50.577000] get_optimization_result for column 137\n",
      "[2016-12-11 00:58:50.996000] get_optimization_result for column 138\n",
      "[2016-12-11 00:58:51.304000] get_optimization_result for column 139\n",
      "[2016-12-11 00:58:51.736000] get_optimization_result for column 140\n",
      "[2016-12-11 00:58:52.014000] get_optimization_result for column 141\n",
      "[2016-12-11 00:58:52.296000] get_optimization_result for column 142\n",
      "[2016-12-11 00:58:52.684000] get_optimization_result for column 143\n",
      "[2016-12-11 00:58:53.502000] get_optimization_result for column 144\n",
      "[2016-12-11 00:58:53.716000] get_optimization_result for column 145\n",
      "[2016-12-11 00:58:54.243000] get_optimization_result for column 146\n",
      "[2016-12-11 00:58:54.523000] get_optimization_result for column 147\n",
      "[2016-12-11 00:58:54.787000] get_optimization_result for column 148\n",
      "[2016-12-11 00:58:55.261000] get_optimization_result for column 149\n",
      "[2016-12-11 00:58:55.625000] get_optimization_result for column 150\n",
      "[2016-12-11 00:58:56.157000] get_optimization_result for column 151\n",
      "[2016-12-11 00:58:56.579000] get_optimization_result for column 152\n",
      "[2016-12-11 00:58:57.088000] get_optimization_result for column 153\n",
      "[2016-12-11 00:58:57.532000] get_optimization_result for column 154\n",
      "[2016-12-11 00:58:58.088000] get_optimization_result for column 155\n",
      "[2016-12-11 00:58:58.234000] get_optimization_result for column 156\n",
      "[2016-12-11 00:58:58.541000] get_optimization_result for column 157\n",
      "[2016-12-11 00:58:59.275000] get_optimization_result for column 158\n",
      "[2016-12-11 00:58:59.517000] get_optimization_result for column 159\n",
      "[2016-12-11 00:58:59.936000] get_optimization_result for column 160\n",
      "[2016-12-11 00:59:00.257000] get_optimization_result for column 161\n",
      "[2016-12-11 00:59:00.565000] get_optimization_result for column 162\n",
      "[2016-12-11 00:59:01.363000] get_optimization_result for column 163\n",
      "[2016-12-11 00:59:01.705000] get_optimization_result for column 164\n",
      "[2016-12-11 00:59:02.024000] get_optimization_result for column 165\n",
      "[2016-12-11 00:59:02.200000] get_optimization_result for column 166\n",
      "[2016-12-11 00:59:02.420000] get_optimization_result for column 167\n",
      "[2016-12-11 00:59:02.751000] get_optimization_result for column 168\n",
      "[2016-12-11 00:59:03.068000] get_optimization_result for column 169\n",
      "[2016-12-11 00:59:03.452000] get_optimization_result for column 170\n",
      "[2016-12-11 00:59:03.862000] get_optimization_result for column 171\n",
      "[2016-12-11 00:59:04.237000] get_optimization_result for column 172\n",
      "[2016-12-11 00:59:04.501000] get_optimization_result for column 173\n",
      "[2016-12-11 00:59:05.123000] get_optimization_result for column 174\n",
      "[2016-12-11 00:59:05.594000] get_optimization_result for column 175\n",
      "[2016-12-11 00:59:06.026000] get_optimization_result for column 176\n",
      "[2016-12-11 00:59:06.511000] get_optimization_result for column 177\n",
      "[2016-12-11 00:59:06.870000] get_optimization_result for column 178\n",
      "[2016-12-11 00:59:07.290000] get_optimization_result for column 179\n",
      "[2016-12-11 00:59:07.682000] get_optimization_result for column 180\n",
      "[2016-12-11 00:59:08.019000] get_optimization_result for column 181\n",
      "[2016-12-11 00:59:08.304000] get_optimization_result for column 182\n",
      "[2016-12-11 00:59:08.753000] get_optimization_result for column 183\n",
      "[2016-12-11 00:59:09.026000] get_optimization_result for column 184\n",
      "[2016-12-11 00:59:09.539000] get_optimization_result for column 185\n",
      "[2016-12-11 00:59:09.859000] get_optimization_result for column 186\n",
      "[2016-12-11 00:59:10.167000] get_optimization_result for column 187\n",
      "[2016-12-11 00:59:10.457000] get_optimization_result for column 188\n",
      "[2016-12-11 00:59:10.844000] get_optimization_result for column 189\n",
      "[2016-12-11 00:59:11.226000] get_optimization_result for column 190\n",
      "[2016-12-11 00:59:11.619000] get_optimization_result for column 191\n",
      "[2016-12-11 00:59:12.234000] get_optimization_result for column 192\n",
      "[2016-12-11 00:59:12.497000] get_optimization_result for column 193\n",
      "[2016-12-11 00:59:12.908000] get_optimization_result for column 194\n",
      "[2016-12-11 00:59:13.183000] get_optimization_result for column 195\n",
      "[2016-12-11 00:59:13.375000] get_optimization_result for column 196\n",
      "[2016-12-11 00:59:13.576000] get_optimization_result for column 197\n",
      "[2016-12-11 00:59:14.146000] get_optimization_result for column 198\n",
      "[2016-12-11 00:59:14.419000] get_optimization_result for column 199\n",
      "[2016-12-11 00:59:14.830000] get_optimization_result for column 200\n",
      "[2016-12-11 00:59:14.965000] get_optimization_result for column 201\n",
      "[2016-12-11 00:59:15.226000] get_optimization_result for column 202\n",
      "[2016-12-11 00:59:15.747000] get_optimization_result for column 203\n",
      "[2016-12-11 00:59:16.534000] get_optimization_result for column 204\n",
      "[2016-12-11 00:59:16.895000] get_optimization_result for column 205\n",
      "[2016-12-11 00:59:17.243000] get_optimization_result for column 206\n",
      "[2016-12-11 00:59:17.772000] get_optimization_result for column 207\n",
      "[2016-12-11 00:59:18.384000] get_optimization_result for column 208\n",
      "[2016-12-11 00:59:19.035000] get_optimization_result for column 209\n",
      "[2016-12-11 00:59:19.383000] get_optimization_result for column 210\n",
      "[2016-12-11 00:59:19.840000] get_optimization_result for column 211\n",
      "[2016-12-11 00:59:20.164000] get_optimization_result for column 212\n",
      "[2016-12-11 00:59:20.545000] get_optimization_result for column 213\n",
      "[2016-12-11 00:59:20.974000] get_optimization_result for column 214\n",
      "[2016-12-11 00:59:21.472000] get_optimization_result for column 215\n",
      "[2016-12-11 00:59:21.772000] get_optimization_result for column 216\n",
      "[2016-12-11 00:59:22.290000] get_optimization_result for column 217\n",
      "[2016-12-11 00:59:22.722000] get_optimization_result for column 218\n",
      "[2016-12-11 00:59:22.788000] get_optimization_result for column 219\n",
      "[2016-12-11 00:59:22.900000] get_optimization_result for column 220\n",
      "[2016-12-11 00:59:22.975000] get_optimization_result for column 221\n",
      "[2016-12-11 00:59:23.485000] get_optimization_result for column 222\n",
      "[2016-12-11 00:59:23.895000] get_optimization_result for column 223\n",
      "[2016-12-11 00:59:24.358000] get_optimization_result for column 224\n",
      "[2016-12-11 00:59:24.573000] get_optimization_result for column 225\n",
      "[2016-12-11 00:59:24.934000] get_optimization_result for column 226\n",
      "[2016-12-11 00:59:25.483000] get_optimization_result for column 227\n",
      "[2016-12-11 00:59:26.033000] get_optimization_result for column 228\n",
      "[2016-12-11 00:59:26.415000] get_optimization_result for column 229\n",
      "[2016-12-11 00:59:26.912000] get_optimization_result for column 230\n",
      "[2016-12-11 00:59:27.227000] get_optimization_result for column 231\n",
      "[2016-12-11 00:59:27.357000] get_optimization_result for column 232\n",
      "[2016-12-11 00:59:27.895000] get_optimization_result for column 233\n",
      "[2016-12-11 00:59:28.169000] get_optimization_result for column 234\n",
      "[2016-12-11 00:59:28.528000] get_optimization_result for column 235\n",
      "[2016-12-11 00:59:28.689000] get_optimization_result for column 236\n",
      "[2016-12-11 00:59:29.037000] get_optimization_result for column 237\n",
      "[2016-12-11 00:59:29.737000] get_optimization_result for column 238\n",
      "[2016-12-11 00:59:30.265000] get_optimization_result for column 239\n",
      "[2016-12-11 00:59:30.583000] get_optimization_result for column 240\n",
      "[2016-12-11 00:59:31.073000] get_optimization_result for column 241\n",
      "[2016-12-11 00:59:31.301000] get_optimization_result for column 242\n",
      "[2016-12-11 00:59:31.941000] get_optimization_result for column 243\n",
      "[2016-12-11 00:59:32.571000] get_optimization_result for column 244\n",
      "[2016-12-11 00:59:33.163000] get_optimization_result for column 245\n",
      "[2016-12-11 00:59:33.360000] get_optimization_result for column 246\n",
      "[2016-12-11 00:59:33.889000] get_optimization_result for column 247\n",
      "[2016-12-11 00:59:34.347000] get_optimization_result for column 248\n",
      "[2016-12-11 00:59:34.543000] get_optimization_result for column 249\n",
      "[2016-12-11 00:59:35.312000] get_optimization_result for column 250\n",
      "[2016-12-11 00:59:35.708000] get_optimization_result for column 251\n",
      "[2016-12-11 00:59:36.450000] get_optimization_result for column 252\n",
      "[2016-12-11 00:59:36.998000] get_optimization_result for column 253\n",
      "[2016-12-11 00:59:37.282000] get_optimization_result for column 254\n",
      "[2016-12-11 00:59:38.100000] get_optimization_result for column 255\n",
      "[2016-12-11 00:59:38.657000] get_optimization_result for column 256\n",
      "[2016-12-11 00:59:39.046000] get_optimization_result for column 257\n",
      "[2016-12-11 00:59:39.422000] get_optimization_result for column 258\n",
      "[2016-12-11 00:59:39.996000] get_optimization_result for column 259\n",
      "[2016-12-11 00:59:40.642000] get_optimization_result for column 260\n",
      "[2016-12-11 00:59:40.853000] get_optimization_result for column 261\n",
      "[2016-12-11 00:59:41.131000] get_optimization_result for column 262\n",
      "[2016-12-11 00:59:41.460000] get_optimization_result for column 263\n",
      "[2016-12-11 00:59:41.729000] get_optimization_result for column 264\n",
      "[2016-12-11 00:59:42.275000] get_optimization_result for column 265\n",
      "[2016-12-11 00:59:42.539000] get_optimization_result for column 266\n",
      "[2016-12-11 00:59:43.033000] get_optimization_result for column 267\n",
      "[2016-12-11 00:59:43.293000] get_optimization_result for column 268\n",
      "[2016-12-11 00:59:43.667000] get_optimization_result for column 269\n",
      "[2016-12-11 00:59:43.904000] get_optimization_result for column 270\n",
      "[2016-12-11 00:59:44.244000] get_optimization_result for column 271\n",
      "[2016-12-11 00:59:44.876000] get_optimization_result for column 272\n",
      "[2016-12-11 00:59:45.390000] get_optimization_result for column 273\n",
      "[2016-12-11 00:59:45.698000] get_optimization_result for column 274\n",
      "[2016-12-11 00:59:46.310000] get_optimization_result for column 275\n",
      "[2016-12-11 00:59:46.784000] get_optimization_result for column 276\n",
      "[2016-12-11 00:59:47.219000] get_optimization_result for column 277\n",
      "[2016-12-11 00:59:47.572000] get_optimization_result for column 278\n",
      "[2016-12-11 00:59:48.090000] get_optimization_result for column 279\n",
      "[2016-12-11 00:59:48.542000] get_optimization_result for column 280\n",
      "[2016-12-11 00:59:48.891000] get_optimization_result for column 281\n",
      "[2016-12-11 00:59:49.321000] get_optimization_result for column 282\n",
      "[2016-12-11 00:59:49.584000] get_optimization_result for column 283\n",
      "[2016-12-11 00:59:49.812000] get_optimization_result for column 284\n",
      "[2016-12-11 00:59:50.269000] get_optimization_result for column 285\n",
      "[2016-12-11 00:59:50.425000] get_optimization_result for column 286\n",
      "[2016-12-11 00:59:50.880000] get_optimization_result for column 287\n",
      "[2016-12-11 00:59:51.231000] get_optimization_result for column 288\n",
      "[2016-12-11 00:59:51.524000] get_optimization_result for column 289\n",
      "[2016-12-11 00:59:52.004000] get_optimization_result for column 290\n",
      "[2016-12-11 00:59:52.333000] get_optimization_result for column 291\n",
      "[2016-12-11 00:59:52.848000] get_optimization_result for column 292\n",
      "[2016-12-11 00:59:53.353000] get_optimization_result for column 293\n",
      "[2016-12-11 00:59:53.754000] get_optimization_result for column 294\n",
      "[2016-12-11 00:59:54.133000] get_optimization_result for column 295\n",
      "[2016-12-11 00:59:54.934000] get_optimization_result for column 296\n",
      "[2016-12-11 00:59:55.322000] get_optimization_result for column 297\n",
      "[2016-12-11 00:59:55.430000] get_optimization_result for column 298\n",
      "[2016-12-11 00:59:55.909000] get_optimization_result for column 299\n",
      "[2016-12-11 00:59:56.216000] get_optimization_result for column 300\n",
      "[2016-12-11 00:59:56.799000] get_optimization_result for column 301\n",
      "[2016-12-11 00:59:56.930000] get_optimization_result for column 302\n",
      "[2016-12-11 00:59:57.003000] get_optimization_result for column 303\n",
      "[2016-12-11 00:59:57.371000] get_optimization_result for column 304\n",
      "[2016-12-11 00:59:58.158000] get_optimization_result for column 305\n",
      "[2016-12-11 00:59:58.601000] get_optimization_result for column 306\n",
      "[2016-12-11 00:59:58.827000] get_optimization_result for column 307\n",
      "[2016-12-11 00:59:59.107000] get_optimization_result for column 308\n",
      "[2016-12-11 00:59:59.511000] get_optimization_result for column 309\n",
      "[2016-12-11 00:59:59.827000] get_optimization_result for column 310\n",
      "[2016-12-11 01:00:00.337000] get_optimization_result for column 311\n",
      "[2016-12-11 01:00:00.709000] get_optimization_result for column 312\n",
      "[2016-12-11 01:00:00.927000] get_optimization_result for column 313\n",
      "[2016-12-11 01:00:01.423000] get_optimization_result for column 314\n",
      "[2016-12-11 01:00:01.756000] get_optimization_result for column 315\n",
      "[2016-12-11 01:00:02.435000] get_optimization_result for column 316\n",
      "[2016-12-11 01:00:03.455000] get_optimization_result for column 317\n",
      "[2016-12-11 01:00:03.756000] get_optimization_result for column 318\n",
      "[2016-12-11 01:00:04.432000] get_optimization_result for column 319\n",
      "[2016-12-11 01:00:04.869000] get_optimization_result for column 320\n",
      "[2016-12-11 01:00:05.120000] get_optimization_result for column 321\n",
      "[2016-12-11 01:00:05.374000] get_optimization_result for column 322\n",
      "[2016-12-11 01:00:05.724000] get_optimization_result for column 323\n",
      "[2016-12-11 01:00:06.172000] get_optimization_result for column 324\n",
      "[2016-12-11 01:00:06.485000] get_optimization_result for column 325\n",
      "[2016-12-11 01:00:06.900000] get_optimization_result for column 326\n",
      "[2016-12-11 01:00:07.253000] get_optimization_result for column 327\n",
      "[2016-12-11 01:00:07.503000] get_optimization_result for column 328\n",
      "[2016-12-11 01:00:07.788000] get_optimization_result for column 329\n",
      "[2016-12-11 01:00:07.974000] get_optimization_result for column 330\n",
      "[2016-12-11 01:00:08.623000] get_optimization_result for column 331\n",
      "[2016-12-11 01:00:09.259000] get_optimization_result for column 332\n",
      "[2016-12-11 01:00:09.667000] get_optimization_result for column 333\n",
      "[2016-12-11 01:00:10.024000] get_optimization_result for column 334\n",
      "[2016-12-11 01:00:10.389000] get_optimization_result for column 335\n",
      "[2016-12-11 01:00:11.206000] get_optimization_result for column 336\n",
      "[2016-12-11 01:00:11.782000] get_optimization_result for column 337\n",
      "[2016-12-11 01:00:11.975000] get_optimization_result for column 338\n",
      "[2016-12-11 01:00:12.213000] get_optimization_result for column 339\n",
      "[2016-12-11 01:00:12.734000] get_optimization_result for column 340\n",
      "[2016-12-11 01:00:12.885000] get_optimization_result for column 341\n",
      "[2016-12-11 01:00:13.269000] get_optimization_result for column 342\n",
      "[2016-12-11 01:00:13.789000] get_optimization_result for column 343\n",
      "[2016-12-11 01:00:14.104000] get_optimization_result for column 344\n",
      "[2016-12-11 01:00:14.262000] get_optimization_result for column 345\n",
      "[2016-12-11 01:00:15.495000] get_optimization_result for column 346\n",
      "[2016-12-11 01:00:15.944000] get_optimization_result for column 347\n",
      "[2016-12-11 01:00:16.306000] get_optimization_result for column 348\n",
      "[2016-12-11 01:00:16.569000] get_optimization_result for column 349\n",
      "[2016-12-11 01:00:16.969000] get_optimization_result for column 350\n",
      "[2016-12-11 01:00:17.348000] get_optimization_result for column 351\n",
      "[2016-12-11 01:00:17.496000] get_optimization_result for column 352\n",
      "[2016-12-11 01:00:17.826000] get_optimization_result for column 353\n",
      "[2016-12-11 01:00:18.025000] get_optimization_result for column 354\n",
      "[2016-12-11 01:00:18.558000] get_optimization_result for column 355\n",
      "[2016-12-11 01:00:18.803000] get_optimization_result for column 356\n",
      "[2016-12-11 01:00:19.695000] get_optimization_result for column 357\n",
      "[2016-12-11 01:00:20.119000] get_optimization_result for column 358\n",
      "[2016-12-11 01:00:20.437000] get_optimization_result for column 359\n",
      "[2016-12-11 01:00:20.836000] get_optimization_result for column 360\n",
      "[2016-12-11 01:00:21.356000] get_optimization_result for column 361\n",
      "[2016-12-11 01:00:21.892000] get_optimization_result for column 362\n",
      "[2016-12-11 01:00:22.216000] get_optimization_result for column 363\n",
      "[2016-12-11 01:00:22.583000] get_optimization_result for column 364\n",
      "[2016-12-11 01:00:24.159000] get_optimization_result for column 365\n",
      "[2016-12-11 01:00:24.820000] get_optimization_result for column 366\n",
      "[2016-12-11 01:00:25.602000] get_optimization_result for column 367\n",
      "[2016-12-11 01:00:26.113000] get_optimization_result for column 368\n",
      "[2016-12-11 01:00:26.313000] get_optimization_result for column 369\n",
      "[2016-12-11 01:00:26.930000] get_optimization_result for column 370\n",
      "[2016-12-11 01:00:27.539000] get_optimization_result for column 371\n",
      "[2016-12-11 01:00:28.016000] get_optimization_result for column 372\n",
      "[2016-12-11 01:00:28.214000] get_optimization_result for column 373\n",
      "[2016-12-11 01:00:28.692000] get_optimization_result for column 374\n",
      "[2016-12-11 01:00:28.940000] get_optimization_result for column 375\n",
      "[2016-12-11 01:00:29.728000] get_optimization_result for column 376\n",
      "[2016-12-11 01:00:30.041000] get_optimization_result for column 377\n",
      "[2016-12-11 01:00:30.459000] get_optimization_result for column 378\n",
      "[2016-12-11 01:00:30.966000] get_optimization_result for column 379\n",
      "[2016-12-11 01:00:31.383000] get_optimization_result for column 380\n",
      "[2016-12-11 01:00:31.595000] get_optimization_result for column 381\n",
      "[2016-12-11 01:00:31.795000] get_optimization_result for column 382\n",
      "[2016-12-11 01:00:31.964000] get_optimization_result for column 383\n",
      "[2016-12-11 01:00:32.418000] get_optimization_result for column 384\n",
      "[2016-12-11 01:00:32.941000] get_optimization_result for column 385\n",
      "[2016-12-11 01:00:33.394000] get_optimization_result for column 386\n",
      "[2016-12-11 01:00:33.879000] get_optimization_result for column 387\n",
      "[2016-12-11 01:00:34.191000] get_optimization_result for column 388\n",
      "[2016-12-11 01:00:34.474000] get_optimization_result for column 389\n",
      "[2016-12-11 01:00:34.683000] get_optimization_result for column 390\n",
      "[2016-12-11 01:00:35.175000] get_optimization_result for column 391\n",
      "[2016-12-11 01:00:35.806000] get_optimization_result for column 392\n",
      "[2016-12-11 01:00:36.343000] get_optimization_result for column 393\n",
      "[2016-12-11 01:00:37.526000] get_optimization_result for column 394\n",
      "[2016-12-11 01:00:38.116000] get_optimization_result for column 395\n",
      "[2016-12-11 01:00:38.467000] get_optimization_result for column 396\n",
      "[2016-12-11 01:00:39.039000] get_optimization_result for column 397\n",
      "[2016-12-11 01:00:39.588000] get_optimization_result for column 398\n",
      "[2016-12-11 01:00:39.999000] get_optimization_result for column 399\n",
      "[2016-12-11 01:00:40.794000] get_optimization_result for column 400\n",
      "[2016-12-11 01:00:41.167000] get_optimization_result for column 401\n",
      "[2016-12-11 01:00:41.567000] get_optimization_result for column 402\n",
      "[2016-12-11 01:00:41.879000] get_optimization_result for column 403\n",
      "[2016-12-11 01:00:42.455000] get_optimization_result for column 404\n",
      "[2016-12-11 01:00:42.836000] get_optimization_result for column 405\n",
      "[2016-12-11 01:00:43.165000] get_optimization_result for column 406\n",
      "[2016-12-11 01:00:43.556000] get_optimization_result for column 407\n",
      "[2016-12-11 01:00:43.620000] get_optimization_result for column 408\n",
      "[2016-12-11 01:00:43.861000] get_optimization_result for column 409\n",
      "[2016-12-11 01:00:44.235000] get_optimization_result for column 410\n",
      "[2016-12-11 01:00:44.565000] get_optimization_result for column 411\n",
      "[2016-12-11 01:00:44.985000] get_optimization_result for column 412\n",
      "[2016-12-11 01:00:45.352000] get_optimization_result for column 413\n",
      "[2016-12-11 01:00:46.039000] get_optimization_result for column 414\n",
      "[2016-12-11 01:00:46.540000] get_optimization_result for column 415\n",
      "[2016-12-11 01:00:46.948000] get_optimization_result for column 416\n",
      "[2016-12-11 01:00:47.282000] get_optimization_result for column 417\n",
      "[2016-12-11 01:00:47.744000] get_optimization_result for column 418\n",
      "[2016-12-11 01:00:48.448000] get_optimization_result for column 419\n",
      "[2016-12-11 01:00:48.662000] get_optimization_result for column 420\n",
      "[2016-12-11 01:00:49.244000] get_optimization_result for column 421\n",
      "[2016-12-11 01:00:50.027000] get_optimization_result for column 422\n",
      "[2016-12-11 01:00:50.269000] get_optimization_result for column 423\n",
      "[2016-12-11 01:00:50.864000] get_optimization_result for column 424\n",
      "[2016-12-11 01:00:51.189000] get_optimization_result for column 425\n",
      "[2016-12-11 01:00:51.284000] get_optimization_result for column 426\n",
      "[2016-12-11 01:00:51.611000] get_optimization_result for column 427\n",
      "[2016-12-11 01:00:51.967000] get_optimization_result for column 428\n",
      "[2016-12-11 01:00:52.176000] get_optimization_result for column 429\n",
      "[2016-12-11 01:00:52.631000] get_optimization_result for column 430\n",
      "[2016-12-11 01:00:53.303000] get_optimization_result for column 431\n",
      "[2016-12-11 01:00:53.796000] get_optimization_result for column 432\n",
      "[2016-12-11 01:00:54.317000] get_optimization_result for column 433\n",
      "[2016-12-11 01:00:54.726000] get_optimization_result for column 434\n",
      "[2016-12-11 01:00:54.999000] get_optimization_result for column 435\n",
      "[2016-12-11 01:00:55.392000] get_optimization_result for column 436\n",
      "[2016-12-11 01:00:55.910000] get_optimization_result for column 437\n",
      "[2016-12-11 01:00:56.095000] get_optimization_result for column 438\n",
      "[2016-12-11 01:00:56.395000] get_optimization_result for column 439\n",
      "[2016-12-11 01:00:56.797000] get_optimization_result for column 440\n",
      "[2016-12-11 01:00:57.189000] get_optimization_result for column 441\n",
      "[2016-12-11 01:00:57.549000] get_optimization_result for column 442\n",
      "[2016-12-11 01:00:58.491000] get_optimization_result for column 443\n",
      "[2016-12-11 01:00:59] get_optimization_result for column 444\n",
      "[2016-12-11 01:00:59.443000] get_optimization_result for column 445\n",
      "[2016-12-11 01:00:59.824000] get_optimization_result for column 446\n",
      "[2016-12-11 01:01:00.368000] get_optimization_result for column 447\n",
      "[2016-12-11 01:01:00.872000] get_optimization_result for column 448\n",
      "[2016-12-11 01:01:01.240000] get_optimization_result for column 449\n",
      "[2016-12-11 01:01:01.379000] get_optimization_result for column 450\n",
      "[2016-12-11 01:01:01.662000] get_optimization_result for column 451\n",
      "[2016-12-11 01:01:02.710000] get_optimization_result for column 452\n",
      "[2016-12-11 01:01:03.068000] get_optimization_result for column 453\n",
      "[2016-12-11 01:01:03.375000] get_optimization_result for column 454\n",
      "[2016-12-11 01:01:03.723000] get_optimization_result for column 455\n",
      "[2016-12-11 01:01:04.068000] get_optimization_result for column 456\n",
      "[2016-12-11 01:01:04.567000] get_optimization_result for column 457\n",
      "[2016-12-11 01:01:05.033000] get_optimization_result for column 458\n",
      "[2016-12-11 01:01:05.333000] get_optimization_result for column 459\n",
      "[2016-12-11 01:01:05.659000] get_optimization_result for column 460\n",
      "[2016-12-11 01:01:06.038000] get_optimization_result for column 461\n",
      "[2016-12-11 01:01:06.443000] get_optimization_result for column 462\n",
      "[2016-12-11 01:01:06.805000] get_optimization_result for column 463\n",
      "[2016-12-11 01:01:06.986000] get_optimization_result for column 464\n",
      "[2016-12-11 01:01:07.297000] get_optimization_result for column 465\n",
      "[2016-12-11 01:01:07.609000] get_optimization_result for column 466\n",
      "[2016-12-11 01:01:08.118000] get_optimization_result for column 467\n",
      "[2016-12-11 01:01:08.868000] get_optimization_result for column 468\n",
      "[2016-12-11 01:01:09.269000] get_optimization_result for column 469\n",
      "[2016-12-11 01:01:09.741000] get_optimization_result for column 470\n",
      "[2016-12-11 01:01:10.218000] get_optimization_result for column 471\n",
      "[2016-12-11 01:01:10.526000] get_optimization_result for column 472\n",
      "[2016-12-11 01:01:11.169000] get_optimization_result for column 473\n",
      "[2016-12-11 01:01:11.330000] get_optimization_result for column 474\n",
      "[2016-12-11 01:01:11.621000] get_optimization_result for column 475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28628cc0>"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFoCAYAAADZ17inAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf0DCf+MzFYwyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3174cfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds3 = get_optimization_result(hellinger_dist, None, phi_convex_hull, distances_convex_hull)\n",
    "ds = ds3\n",
    "save_pickle_file(ds3, 'dists_h_none3.p')\n",
    "fs = [ds[col].fun for col in phi_convex_hull.columns]\n",
    "sns.distplot(fs, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 8\n",
      "topics to remove =  3\n",
      "topic_399:  _         \n",
      "topic_71:           \n",
      "topic_359: _  _   _    _ \n"
     ]
    }
   ],
   "source": [
    "low_th, high_th = 0.76, 0.89\n",
    "small_dist_opts = {col: ds[col] for col in phi_convex_hull.columns if ds[col].fun < low_th}\n",
    "large_dist_opts = {col: ds[col] for col in phi_convex_hull.columns if ds[col].fun > high_th}\n",
    "print len(small_dist_opts), len(large_dist_opts)\n",
    "topics_to_remove_by_closest_dist = get_topics_to_remove_by_closest_dist(small_dist_opts, distances_convex_hull)\n",
    "print 'topics to remove = ', len(topics_to_remove_by_closest_dist)\n",
    "print '\\n'.join([unicode_list_to_str(topic_name, saved_top_tokens[topic_name][0:11]) for topic_name in topics_to_remove_by_closest_dist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phi_convex_hull = remove_topics_from_phi(phi_convex_hull, topics_to_remove_by_closest_dist)\n",
    "distances_convex_hull = remove_topics_from_distances(distances_convex_hull, topics_to_remove_by_closest_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iteration = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds4 = get_optimization_result(hellinger_dist, None, phi_convex_hull, distances_convex_hull)\n",
    "ds = ds4\n",
    "save_pickle_file(ds, 'dists_h_none4.p')\n",
    "fs = [ds[col].fun for col in phi_convex_hull.columns]\n",
    "sns.distplot(fs, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_th, high_th = 0.76, 0.89\n",
    "small_dist_opts = {col: ds[col] for col in phi_convex_hull.columns if ds[col].fun < low_th}\n",
    "large_dist_opts = {col: ds[col] for col in phi_convex_hull.columns if ds[col].fun > high_th}\n",
    "print len(small_dist_opts), len(large_dist_opts)\n",
    "topics_to_remove_by_closest_dist = get_topics_to_remove_by_closest_dist(small_dist_opts, distances_convex_hull)\n",
    "print 'topics to remove = ', len(topics_to_remove_by_closest_dist)\n",
    "print '\\n'.join([unicode_list_to_str(topic_name, saved_top_tokens[topic_name][0:11]) for topic_name in topics_to_remove_by_closest_dist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phi_convex_hull = remove_topics_from_phi(phi_convex_hull, topics_to_remove_by_closest_dist)\n",
    "distances_convex_hull = remove_topics_from_distances(distances_convex_hull, topics_to_remove_by_closest_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_file.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
