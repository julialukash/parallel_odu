{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PN_choose_model_100.ipynb\n",
    "Зафиксировано число тем = 100. Были поробованы разные модели, отобрано несколько моделей: \n",
    "* без регуляризатора\n",
    " * name = model_100_1, n_topics = 100, n_doc_passes = 5, seed_value = 100, n_iterations = 20, n_top_tokens = 15, p_threshold = 0.25\n",
    " * last_perplexity_score = 1065.4691168\n",
    " * last_sparsity_phi_score = 0.76290761491\n",
    " * last_sparsity_theta_score = 0.00162797446315\n",
    " * last_topic_kernel_avgsize = 155.89\n",
    " * last_topic_kernel_purity = 0.287688379533\n",
    " * last_topic_kernel_contrast = 0.468397835486\n",
    "* с регуляризаторами, хорошие показатели, но avg kernel size = 90\n",
    " * name = model_100_7, n_topics = 100, n_doc_passes = 5, seed_value = 100, n_iterations = 20, n_top_tokens = 15, p_threshold = 0.25, ss_theta_regularizer, tau = -0.5, decorrelator_phi_regularizer, tau = 10, ss_phi_regularizer, tau = -0.5\n",
    " * last_perplexity_score = 886.578272434\n",
    " * last_sparsity_phi_score = 0.979305968443\n",
    " * last_sparsity_theta_score = 0.769207777133\n",
    " * last_topic_kernel_avgsize = 89.23\n",
    " * last_topic_kernel_purity = 0.50039540324\n",
    " * last_topic_kernel_contrast = 0.728560167745\n",
    "* с регуляризаторами, хорошие показатели, примерно одинаковые, avg kernel size = 24\n",
    " * name = model_100_12, n_topics = 100, n_doc_passes = 5, seed_value = 100, n_iterations = 20, n_top_tokens = 15, p_threshold = 0.25, ss_theta_regularizer, tau = -0.5, decorrelator_phi_regularizer, tau = 10, ss_phi_regularizer, tau = -2\n",
    " * last_perplexity_score = 384.451799322\n",
    " * last_sparsity_phi_score = 0.994879373428\n",
    " * last_sparsity_theta_score = 0.74879280325\n",
    " * last_topic_kernel_avgsize = 23.68\n",
    " * last_topic_kernel_purity = 0.629848034538\n",
    " * last_topic_kernel_contrast = 0.776075642\n",
    "\n",
    "## PN_visualize_convex_hull_100_3models.ipynb\n",
    "Для выбранных моделей были посчитаны внутренние расстояния, посчитан функционал opt при выбрасывании одной темы.\n",
    "\n",
    "Выводы: самая отрегуляризованная модель (3) расстояние наибольшее, модель 1 - размазано расстояние.\n",
    "\n",
    "TODO: сравнить метрики расстояния\n",
    "## PN_model_to_ndw.ipynb\n",
    "Для 3х моделей.\n",
    "\n",
    "TODO: сравнить sample model без умножения на длину документа.\n",
    "## PN_ndw_to_batch.ipynb\n",
    "Для 3х моделей.\n",
    "\n",
    "## TODO\n",
    "Для каждого из созданного датасета:\n",
    "* создать несколько моделей, сравнить их (для начала можно выбрать 2 модели - без регуляризаторов и сильно разреженную)\n",
    "* стабильность: запустить много раз, посмотреть сколько новых тем с каждым разом; как определить новая ли тема? (перестановки и т.д) -> строим матрицу попарных расстояний (hemm) и по топ словам, пытаемся соотнести - порог, новая/не новая + почитать статьи\n",
    "* полнота: запускаем один раз, строим попарные расстояния внутренние, запускаем оптимизацию, смотрим расстояния, откидываем зависимые\n",
    "\n",
    "## PN_choose_model_20_sample-model123.ipynb\n",
    "Даже без регуляризаторов модели получаются с норм показателями (кроме ss theta и большой средний размер ядра) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: для каждой получившейся convex hull посчитать внутреннее расстояние и спроектировать на original\n",
    "## PN_build_convex_hull-sample_m3_2\n",
    "Модель 3: \n",
    "* name = model_100_12, n_topics = 100, n_doc_passes = 5, seed_value = 100, n_iterations = 20, n_top_tokens = 15, p_threshold = 0.25, ss_theta_regularizer, tau = -0.5, decorrelator_phi_regularizer, tau = 10, ss_phi_regularizer, tau = -2\n",
    "\n",
    "Сonvex hulls:\n",
    "- create_model_fn_1: n_topics=20, n_doc_passes=5, seed_value=100 + n_iteration, n_top_tokens=15, p_mass_threshold=0.25\n",
    "От порога зависит сколько тем получится в convex hull, для модели из 20 тем 0,6 слишком большой - остаётся 24 темы (2.30h); или 25-30 тем уже на 20 итерации (10m) и потом число тем колеблится +/- в этих рамках, итого 28 тем(1.30h)\n",
    "Порог 0.4: за 40 итераций постоянно растёт convex hull, итого 150 тем\n",
    "Порог 0.5: за 60 итераций дошло до 61\n",
    "Порог 0.45:\n",
    "\n",
    "- create_model_fn_2: n_topics=100, n_doc_passes=5, seed_value=100 + n_iteration, n_top_tokens=15, p_mass_threshold=0.25\n",
    "Delayed Filtering each 10: накапливалось и отфильтровывалось до 100-110, итого 40 итераций 112 тем (2h)\n",
    "Filtering: 100-120 число тем, итого 50 итераций 111 тем (2h)\n",
    "- create_model_fn_3: n_topics=20, n_doc_passes=5, seed_value=100 + n_iteration, n_top_tokens=15, p_mass_threshold=0.25, ['decorrelator_phi_regularizer'].tau = 300, ['ss_theta_regularizer'].tau = -5, ['ss_phi_regularizer'].tau = -20\n",
    "Delayed Filtering: сошлась до 56 тем (3h)\n",
    "Filtering: после 60 итерации (1h) сошлась к 57 темам (3.30h)\n",
    "- create_model_fn_4: n_topics=100, n_doc_passes=5, seed_value=100 + n_iteration, n_top_tokens=15, p_mass_threshold=0.25, ['decorrelator_phi_regularizer'].tau = 10, ['ss_theta_regularizer'].tau = -0.5, ['ss_phi_regularizer'].tau = -2\n",
    "Delayed Filtering each 10: 233, 326, 410, 484\n",
    "Filtering: \n",
    "Порог 0.6: 543 и всё растёт, для такой хорошей модели порог нужно выше задавать\n",
    "Порог 0.7: отфильтровка до 304 \n",
    "Порог 0.8: отфильтровка до 139 / набор до 118\n",
    "\n",
    "По opt res до original convex hull 21, 22, 31 ближе всего -> 1 и 3 модели (+ там меньше тем)\n",
    "То есть модели из 20 тем \n",
    "\n",
    "- порог \n",
    "- оценка качества: \n",
    "* стабильности\n",
    "* полноты \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TODO\n",
    "* сравнить с opt Вовы + \n",
    "* подобрать гранулярность +(\n",
    "* написать complex reg + \n",
    "* попробовать: когда строить convex hull хранить ещё и все отфильтрованные темы, при добавлении новых тем добавлять и убранные до этого и заново запускать фильтр +\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ('phi_original', 59.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model1, different th, 200 iterations, wf:\n",
    " \n",
    "|  th | n_topics |  opt_to_orig  | gran | x_count_mean |\n",
    "|:---:|:--------:|:-------------:|:----:|:------------:|\n",
    "| 0.4 |    175   |  0.2-0.3-0.35 |  131 |     3.36     |\n",
    "| 0.5 |   50-60  |  0.2-0.33-0.4 |  126 |     3.28     |\n",
    "| 0.6 |   26-30  |  0.2-0.28-0.4 |  128 |      3.3     |\n",
    "| 0.7 |   17-22  |  0.2-0.33-0.4 |  132 |     3.76     |\n",
    "| 0.8 |   9-13   |  0.2-0.33-0.4 |  114 |     3.36     |\n",
    "| 0.9 |    3-6   | 0.23-0.3-0.33 |  90  |      2.6     |\n",
    "\n",
    "Model1, different th, 150 iterations, df:\n",
    "* 0.4\n",
    " * n_topics: 190\n",
    " * opt_to_orig: 0.2-0.3-0.4\n",
    " * gran: 131\n",
    " * 3.36\n",
    "* 0.6\n",
    " * 22\n",
    " * 0.22-0.35\n",
    " * 122\n",
    " * 3\n",
    "* 0.8\n",
    " * 12\n",
    " * .23 -0.38\n",
    " * 109\n",
    " * 2.89\n",
    "\n",
    "* wh, df одинаковый результат (200it: 4,30; 2;    150: 3,00; 3,00)\n",
    "* gran, of course, the same\n",
    "* x_count_mean, of course, +- the same\n",
    "* как порог выбрать?\n",
    " \n",
    "20 topics, Different regs, 0.6, 100 iterations:\n",
    "* ('phi_convex_hull_wf_m_reg2_1', (-5,-5,-)\n",
    " * n_topics: 55 (mb not sosh)\n",
    " * opt_to_orig: 0.3-0.45-0.6\n",
    " * gran: 51.754716981132077)\n",
    " * x_count_mean: 2.16\n",
    "* ('phi_convex_hull_wf_m_reg3_1', (-10,-10,-)\n",
    " * 55 (mb not sosh)\n",
    " * 0.4-0.65-0.8\n",
    " * 48.145454545454548)\n",
    " * 0.6\n",
    "* ('phi_convex_hull_wf_m_reg4_1', (-5,-5,-10)\n",
    " * 55 (mb not sosh)\n",
    " * 0.3-0.45-0.6\n",
    " * 54.169811320754718)\n",
    " * 2.32\n",
    "* ох, получается, что модель, которая хорошо выражается через 1-2 темы - самая отдаленная\n",
    "* добавление decor с -10 не сильно меняет что-то\n",
    "\n",
    "10 topics\n",
    "* 0.6\n",
    " * 10 - 16\n",
    " * 0.2-0.35\n",
    " * 215\n",
    " * 7.69\n",
    "* 0.8\n",
    " * 4 - 6\n",
    " * 0.22-0.32\n",
    " * 191\n",
    " * 7\n",
    "* чем больше гран, чем общнее темы - тем ближе проектируется, но выражается чем больше тем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## algo (?)\n",
    "* df\n",
    " * много раз запускается построение модели, запоминаются темы \n",
    " * __запускается фильтрация__:\n",
    " * каждая тема пытается спроектироваться на матрицу всех тем (opt: не на все, а на N_CLOSEST_TOPICS(=15?)) - текущая тема\n",
    " * выбираются все темы, opt_distance < threshold, сортируются по opt_distance = candidates\n",
    " * набираются topics_to_remove: тема из candidates + _не близка_ ни к какой теме, которая уже в topics_to_remove\n",
    " *  _не близка_ t1, t2: \n",
    "   * по порогу\n",
    "   * distances от t1 до каждой другой темы, сортируем, берем N_CLOSEST_TOPICS - если рассматриваемая тема t2 там есть -> близка\n",
    " * __пока |topics_to_remove| = 0__\n",
    "\n",
    "* wf\n",
    " * то же самое, только фильтеринг после каждой новой построенной модели, а не в конце"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### qa\n",
    "* algo адекватный?\n",
    "* что с threshold делать?\n",
    "* чем больше гран, чем общнее темы - тем ближе проектируется, но выражается чем больше тем\n",
    "* близость её как определять\n",
    "* distance - hungarian alg of matching ? \n",
    "* стабильность и полнота; метрика\n",
    "\n",
    "* Разработка графовых методов анализа структурированных финансовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### todo\n",
    "* реализовать поиск коэффициентов с помощью разложения\n",
    "* тесты +\n",
    " * фи, перестановка столбцов +\n",
    " * фи, выпуклая комбинация с рандомными весами +\n",
    "* написать письмо о единственности \n",
    "* формализовать метрики стабильности\n",
    "* формализовать метрики полноты\n",
    "* добиться с помощью регул. x_count_mean = 0 (+1)\n",
    "* переделать gran: mean -> mean + hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 0.4 \n",
    " * n_topics: 175 topics (50 it)\n",
    " * opt_to_orig: 0.2-0.3-0.35\n",
    " * gran: 131\n",
    " * x_count_mean: 3.36 \n",
    "* 0.5 \n",
    " * 50-60 topics (strange down on 75 it)\n",
    " * 0.2-0.33-0.4\n",
    " * 126\n",
    " * 3.28\n",
    "* 0.6 \n",
    " * 26-30 (> 25 it)\n",
    " * 0.2-0.28-0.4\n",
    " * 128\n",
    " * 3.33\n",
    "* 0.7 \n",
    " * 17-22 (> 10 it)\n",
    " * 0.2-0.33-0.4\n",
    " * 132\n",
    " * 3.76\n",
    "* 0.8 \n",
    " * 9-13 (> 10 it)\n",
    " * 0.2-0.33-0.4\n",
    " * 114\n",
    " * 3.36\n",
    "* 0.9 \n",
    " * 3-6 (> 10 it)\n",
    " * 0.23-0.3-0.33\n",
    " * 90\n",
    " * 2.6"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
