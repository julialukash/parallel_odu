{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PN_choose_model_100.ipynb\n",
    "Зафиксировано число тем = 100. Были поробованы разные модели, отобрано несколько моделей: \n",
    "* без регуляризатора\n",
    " * name = model_100_1, n_topics = 100, n_doc_passes = 5, seed_value = 100, n_iterations = 20, n_top_tokens = 15, p_threshold = 0.25\n",
    " * last_perplexity_score = 1065.4691168\n",
    " * last_sparsity_phi_score = 0.76290761491\n",
    " * last_sparsity_theta_score = 0.00162797446315\n",
    " * last_topic_kernel_avgsize = 155.89\n",
    " * last_topic_kernel_purity = 0.287688379533\n",
    " * last_topic_kernel_contrast = 0.468397835486\n",
    "* с регуляризаторами, хорошие показатели, но avg kernel size = 90\n",
    " * name = model_100_7, n_topics = 100, n_doc_passes = 5, seed_value = 100, n_iterations = 20, n_top_tokens = 15, p_threshold = 0.25, ss_theta_regularizer, tau = -0.5, decorrelator_phi_regularizer, tau = 10, ss_phi_regularizer, tau = -0.5\n",
    " * last_perplexity_score = 886.578272434\n",
    " * last_sparsity_phi_score = 0.979305968443\n",
    " * last_sparsity_theta_score = 0.769207777133\n",
    " * last_topic_kernel_avgsize = 89.23\n",
    " * last_topic_kernel_purity = 0.50039540324\n",
    " * last_topic_kernel_contrast = 0.728560167745\n",
    "* с регуляризаторами, хорошие показатели, примерно одинаковые, avg kernel size = 24\n",
    " * name = model_100_12, n_topics = 100, n_doc_passes = 5, seed_value = 100, n_iterations = 20, n_top_tokens = 15, p_threshold = 0.25, ss_theta_regularizer, tau = -0.5, decorrelator_phi_regularizer, tau = 10, ss_phi_regularizer, tau = -2\n",
    " * last_perplexity_score = 384.451799322\n",
    " * last_sparsity_phi_score = 0.994879373428\n",
    " * last_sparsity_theta_score = 0.74879280325\n",
    " * last_topic_kernel_avgsize = 23.68\n",
    " * last_topic_kernel_purity = 0.629848034538\n",
    " * last_topic_kernel_contrast = 0.776075642\n",
    "\n",
    "## PN_visualize_convex_hull_100_3models.ipynb\n",
    "Для выбранных моделей были посчитаны внутренние расстояния, посчитан функционал opt при выбрасывании одной темы.\n",
    "\n",
    "Выводы: самая отрегуляризованная модель (3) расстояние наибольшее, модель 1 - размазано расстояние.\n",
    "\n",
    "TODO: сравнить метрики расстояния\n",
    "## PN_model_to_ndw.ipynb\n",
    "Для 3х моделей.\n",
    "\n",
    "TODO: сравнить sample model без умножения на длину документа.\n",
    "## PN_ndw_to_batch.ipynb\n",
    "Для 3х моделей.\n",
    "\n",
    "## TODO\n",
    "Для каждого из созданного датасета:\n",
    "* создать несколько моделей, сравнить их (для начала можно выбрать 2 модели - без регуляризаторов и сильно разреженную)\n",
    "* стабильность: запустить много раз, посмотреть сколько новых тем с каждым разом; как определить новая ли тема? (перестановки и т.д) -> строим матрицу попарных расстояний (hemm) и по топ словам, пытаемся соотнести - порог, новая/не новая + почитать статьи\n",
    "* полнота: запускаем один раз, строим попарные расстояния внутренние, запускаем оптимизацию, смотрим расстояния, откидываем зависимые\n",
    "\n",
    "## PN_choose_model_20_sample-model123.ipynb\n",
    "Даже без регуляризаторов модели получаются с норм показателями (кроме ss theta и большой средний размер ядра) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: для каждой получившейся convex hull посчитать внутреннее расстояние и спроектировать на original\n",
    "## PN_build_convex_hull-sample_m3_2\n",
    "Модель 3: \n",
    "* name = model_100_12, n_topics = 100, n_doc_passes = 5, seed_value = 100, n_iterations = 20, n_top_tokens = 15, p_threshold = 0.25, ss_theta_regularizer, tau = -0.5, decorrelator_phi_regularizer, tau = 10, ss_phi_regularizer, tau = -2\n",
    "\n",
    "Сonvex hulls:\n",
    "- create_model_fn_1: n_topics=20, n_doc_passes=5, seed_value=100 + n_iteration, n_top_tokens=15, p_mass_threshold=0.25\n",
    "От порога зависит сколько тем получится в convex hull, для модели из 20 тем 0,6 слишком большой - остаётся 24 темы (2.30h); или 25-30 тем уже на 20 итерации (10m) и потом число тем колеблится +/- в этих рамках, итого 28 тем(1.30h)\n",
    "Порог 0.4: за 40 итераций постоянно растёт convex hull, итого 150 тем\n",
    "Порог 0.5: за 60 итераций дошло до 61\n",
    "Порог 0.45:\n",
    "\n",
    "- create_model_fn_2: n_topics=100, n_doc_passes=5, seed_value=100 + n_iteration, n_top_tokens=15, p_mass_threshold=0.25\n",
    "Delayed Filtering each 10: накапливалось и отфильтровывалось до 100-110, итого 40 итераций 112 тем (2h)\n",
    "Filtering: 100-120 число тем, итого 50 итераций 111 тем (2h)\n",
    "- create_model_fn_3: n_topics=20, n_doc_passes=5, seed_value=100 + n_iteration, n_top_tokens=15, p_mass_threshold=0.25, ['decorrelator_phi_regularizer'].tau = 300, ['ss_theta_regularizer'].tau = -5, ['ss_phi_regularizer'].tau = -20\n",
    "Delayed Filtering: сошлась до 56 тем (3h)\n",
    "Filtering: после 60 итерации (1h) сошлась к 57 темам (3.30h)\n",
    "- create_model_fn_4: n_topics=100, n_doc_passes=5, seed_value=100 + n_iteration, n_top_tokens=15, p_mass_threshold=0.25, ['decorrelator_phi_regularizer'].tau = 10, ['ss_theta_regularizer'].tau = -0.5, ['ss_phi_regularizer'].tau = -2\n",
    "Delayed Filtering each 10: 233, 326, 410, 484\n",
    "Filtering: \n",
    "Порог 0.6: 543 и всё растёт, для такой хорошей модели порог нужно выше задавать\n",
    "Порог 0.7: отфильтровка до 304 \n",
    "Порог 0.8: отфильтровка до 139 / набор до 118\n",
    "\n",
    "По opt res до original convex hull 21, 22, 31 ближе всего -> 1 и 3 модели (+ там меньше тем)\n",
    "То есть модели из 20 тем \n",
    "\n",
    "- порог \n",
    "- оценка качества: \n",
    "* стабильности\n",
    "* полноты \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TODO\n",
    "* сравнить с opt Вовы + \n",
    "* подобрать гранулярность +(\n",
    "* написать complex reg + \n",
    "* попробовать: когда строить convex hull хранить ещё и все отфильтрованные темы, при добавлении новых тем добавлять и убранные до этого и заново запускать фильтр +\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ('phi_original', 59.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model1, different th, 200 iterations, wf:\n",
    " \n",
    "|  th | n_topics |  opt_to_orig  | gran | x_count_mean |\n",
    "|:---:|:--------:|:-------------:|:----:|:------------:|\n",
    "| 0.4 |    175   |  0.2-0.3-0.35 |  131 |     3.36     |\n",
    "| 0.5 |   50-60  |  0.2-0.33-0.4 |  126 |     3.28     |\n",
    "| 0.6 |   26-30  |  0.2-0.28-0.4 |  128 |      3.3     |\n",
    "| 0.7 |   17-22  |  0.2-0.33-0.4 |  132 |     3.76     |\n",
    "| 0.8 |   9-13   |  0.2-0.33-0.4 |  114 |     3.36     |\n",
    "| 0.9 |    3-6   | 0.23-0.3-0.33 |  90  |      2.6     |\n",
    "\n",
    "Model1, different th, 150 iterations, df:\n",
    "* 0.4\n",
    " * n_topics: 190\n",
    " * opt_to_orig: 0.2-0.3-0.4\n",
    " * gran: 131\n",
    " * 3.36\n",
    "* 0.6\n",
    " * 22\n",
    " * 0.22-0.35\n",
    " * 122\n",
    " * 3\n",
    "* 0.8\n",
    " * 12\n",
    " * .23 -0.38\n",
    " * 109\n",
    " * 2.89\n",
    "\n",
    "* wh, df одинаковый результат (200it: 4,30; 2;    150: 3,00; 3,00)\n",
    "* gran, of course, the same\n",
    "* x_count_mean, of course, +- the same\n",
    "* как порог выбрать?\n",
    " \n",
    "20 topics, Different regs, 0.6, 100 iterations:\n",
    "* ('phi_convex_hull_wf_m_reg2_1', (-5,-5,-)\n",
    " * n_topics: 55 (mb not sosh)\n",
    " * opt_to_orig: 0.3-0.45-0.6\n",
    " * gran: 51.754716981132077)\n",
    " * x_count_mean: 2.16\n",
    "* ('phi_convex_hull_wf_m_reg3_1', (-10,-10,-)\n",
    " * 55 (mb not sosh)\n",
    " * 0.4-0.65-0.8\n",
    " * 48.145454545454548)\n",
    " * 0.6\n",
    "* ('phi_convex_hull_wf_m_reg4_1', (-5,-5,-10)\n",
    " * 55 (mb not sosh)\n",
    " * 0.3-0.45-0.6\n",
    " * 54.169811320754718)\n",
    " * 2.32\n",
    "* ох, получается, что модель, которая хорошо выражается через 1-2 темы - самая отдаленная\n",
    "* добавление decor с -10 не сильно меняет что-то\n",
    "\n",
    "10 topics\n",
    "* 0.6\n",
    " * 10 - 16\n",
    " * 0.2-0.35\n",
    " * 215\n",
    " * 7.69\n",
    "* 0.8\n",
    " * 4 - 6\n",
    " * 0.22-0.32\n",
    " * 191\n",
    " * 7\n",
    "* чем больше гран, чем общнее темы - тем ближе проектируется, но выражается чем больше тем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## algo (?)\n",
    "* df\n",
    " * много раз запускается построение модели, запоминаются темы \n",
    " * __запускается фильтрация__:\n",
    " * каждая тема пытается спроектироваться на матрицу всех тем (opt: не на все, а на N_CLOSEST_TOPICS(=15?)) - текущая тема\n",
    " * выбираются все темы, opt_distance < threshold, сортируются по opt_distance = candidates\n",
    " * набираются topics_to_remove: тема из candidates + _не близка_ ни к какой теме, которая уже в topics_to_remove\n",
    " *  _не близка_ t1, t2: \n",
    "   * по порогу\n",
    "   * distances от t1 до каждой другой темы, сортируем, берем N_CLOSEST_TOPICS - если рассматриваемая тема t2 там есть -> близка\n",
    " * __пока |topics_to_remove| = 0__\n",
    "\n",
    "* wf\n",
    " * то же самое, только фильтеринг после каждой новой построенной модели, а не в конце"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### qa\n",
    "* algo адекватный?\n",
    "* что с threshold делать?\n",
    "* чем больше гран, чем общнее темы - тем ближе проектируется, но выражается чем больше тем\n",
    "* близость её как определять\n",
    "* distance - hungarian alg of matching ? \n",
    "* стабильность и полнота; метрика\n",
    "\n",
    "* Разработка графовых методов анализа структурированных финансовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### todo\n",
    "* реализовать поиск коэффициентов с помощью разложения\n",
    "* тесты +\n",
    " * фи, перестановка столбцов +\n",
    " * фи, выпуклая комбинация с рандомными весами +\n",
    "* написать письмо о единственности \n",
    "* формализовать метрики стабильности\n",
    "* формализовать метрики полноты\n",
    "* добиться с помощью регул. x_count_mean = 0 (+1)\n",
    "* переделать gran: mean -> mean + hist\n",
    "* расстояние kl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original set немного странные темы? (первое слово топ-топ, остальные слишком маленькие)\n",
    "работа          0.164683\n",
    "статья          0.096539\n",
    "автор           0.078489\n",
    "журнал          0.074716\n",
    "исследование    0.050769\n",
    "публикация      0.039446\n",
    "раздел          0.032632\n",
    "тема            0.032347\n",
    "вопрос          0.022783\n",
    "коллега         0.021196\n",
    "монография      0.019547\n",
    "материал        0.018971\n",
    "постнаука       0.016101\n",
    "редактор        0.014917\n",
    "название        0.014868"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 0.4 \n",
    " * n_topics: 175 topics (50 it)\n",
    " * opt_to_orig: 0.2-0.3-0.35\n",
    " * gran: 131\n",
    " * x_count_mean: 3.36 \n",
    "* 0.5 \n",
    " * 50-60 topics (strange down on 75 it)\n",
    " * 0.2-0.33-0.4\n",
    " * 126\n",
    " * 3.28\n",
    "* 0.6 \n",
    " * 26-30 (> 25 it)\n",
    " * 0.2-0.28-0.4\n",
    " * 128\n",
    " * 3.33\n",
    "* 0.7 \n",
    " * 17-22 (> 10 it)\n",
    " * 0.2-0.33-0.4\n",
    " * 132\n",
    " * 3.76\n",
    "* 0.8 \n",
    " * 9-13 (> 10 it)\n",
    " * 0.2-0.33-0.4\n",
    " * 114\n",
    " * 3.36\n",
    "* 0.9 \n",
    " * 3-6 (> 10 it)\n",
    " * 0.23-0.3-0.33\n",
    " * 90\n",
    " * 2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n_dw_test = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 0.0], [7.0, 8.0, 9.0], [10.0, 0.0, 12.0]])\n",
    "\n",
    "Phi_test_init = np.array([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0], [7.0, 8.0]])\n",
    "Theta_test_init = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]);\n",
    "\n",
    "Phi_test_init = Phi_test_init / np.sum(Phi_test_init, 0)\n",
    "Theta_test_init = Theta_test_init / np.sum(Theta_test_init, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0625,  0.1   ],\n",
       "       [ 0.1875,  0.2   ],\n",
       "       [ 0.3125,  0.3   ],\n",
       "       [ 0.4375,  0.4   ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Phi_test_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2       ,  0.28571429,  0.33333333],\n",
       "       [ 0.8       ,  0.71428571,  0.66666667]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta_test_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0925    ,  0.08928571,  0.0875    ],\n",
       "       [ 0.1975    ,  0.19642857,  0.19583333],\n",
       "       [ 0.3025    ,  0.30357143,  0.30416667],\n",
       "       [ 0.4075    ,  0.41071429,  0.4125    ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Phi_test_init.dot(Theta_test_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   2.,   3.],\n",
       "       [  4.,   5.,   0.],\n",
       "       [  7.,   8.,   9.],\n",
       "       [ 10.,   0.,  12.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dw_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Разобраться в письмах\n",
    "* Написать issue по transform\n",
    "* Написать one to one matching - хотим же найти такие же\n",
    "* написать em + не все колонки\n",
    "* проанализировать notebooks\n",
    "* запустить на ночь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* написать уже метрики\n",
    " * по стабильности\n",
    " * по полноте\n",
    "* проанализировать результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
