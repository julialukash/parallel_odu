{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.1\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import artm\n",
    "print artm.version()\n",
    "\n",
    "from os import path, mkdir\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "sys.path.insert(0, '..\\\\modules\\\\helpers')\n",
    "from plot_helper import PlotMaker\n",
    "from config_helper import ConfigPaths\n",
    "from print_helper import PrintHelper\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from numpy.linalg import norm as euclidean_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = ConfigPaths('config.cfg')\n",
    "plot_maker = PlotMaker()\n",
    "printer = PrintHelper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print config.models_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_file = open(config.models_file_name, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(current_dictionary, n_topics, n_doc_passes, seed_value, n_top_tokens, p_mass_threshold):    \n",
    "    print '[{}] creating model'.format(datetime.now())\n",
    "    model = artm.ARTM(num_topics=n_topics, dictionary=current_dictionary, cache_theta=True, seed=seed_value, \n",
    "                  class_ids={'ngramm': 1.0, 'author_id': 0.0, 'author': 0.0, \n",
    "                             'post_tag': 0.0, 'projects': 0.0, 'category': 0.0,\n",
    "                             'following_users': 0.0})\n",
    "    model.num_document_passes = n_doc_passes\n",
    "    add_scores_to_model(model, n_top_tokens=n_top_tokens, p_mass_threshold=p_mass_threshold)\n",
    "    return model\n",
    "\n",
    "\n",
    "def add_scores_to_model(artm_model, n_top_tokens, p_mass_threshold):\n",
    "    print '[{}] adding scores'.format(datetime.now())\n",
    "    artm_model.scores.add(artm.PerplexityScore(name='perplexity_score',\n",
    "                                      use_unigram_document_model=False,\n",
    "                                      dictionary=dictionary))\n",
    "    artm_model.scores.add(artm.SparsityPhiScore(name='sparsity_phi_score', class_id='ngramm'))\n",
    "    artm_model.scores.add(artm.SparsityThetaScore(name='sparsity_theta_score'))\n",
    "    artm_model.scores.add(artm.TopicKernelScore(name='topic_kernel_score', class_id='ngramm', \n",
    "                                                probability_mass_threshold=p_mass_threshold))\n",
    "    artm_model.scores.add(artm.TopTokensScore(name='top_tokens_score', class_id='ngramm', num_tokens=n_top_tokens))\n",
    "def fit_one_model(model, _n_iterations, _model_name=''): \n",
    "    print '[{}] fitting'.format(datetime.now())\n",
    "    model.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=_n_iterations)\n",
    "    print '[{}] outputting'.format(datetime.now())\n",
    "    printer.print_artm_model(model, _model_name, _n_iterations, output_file=models_file)\n",
    "    model_pics_file_name =  path.join(config.experiment_path, _model_name)\n",
    "    plot_maker.make_tm_plots(model, model_pics_file_name)\n",
    "    model_output_file_name = path.join(config.experiment_path, _model_name + '.txt')\n",
    "    printer.print_scores(model, _model_name, _n_iterations, model_output_file_name)\n",
    "    printer.print_top_tokens(model, model_output_file_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_vectorizer = artm.BatchVectorizer(data_path=config.output_batches_path,\n",
    "                                        data_format='batches')\n",
    "dictionary = artm.Dictionary()\n",
    "dictionary.load(dictionary_path=config.dictionary_path + '.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_model = create_model(current_dictionary=dictionary, n_topics=500, n_doc_passes=5, seed_value=100,\n",
    "                            n_top_tokens=15, p_mass_threshold=0.25)\n",
    "tmp_model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_regularizer', class_ids=['ngramm']))\n",
    "tmp_model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='ss_theta_regularizer'))\n",
    "tmp_model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='ss_phi_regularizer', class_ids=['ngramm']))\n",
    "tmp_model.regularizers['decorrelator_phi_regularizer'].tau = 100\n",
    "tmp_model.regularizers['ss_theta_regularizer'].tau = -0.1\n",
    "tmp_model.regularizers['ss_phi_regularizer'].tau = -0.05\n",
    "tmp_model = fit_one_model(tmp_model, _n_iterations=20, _model_name='model1')\n",
    "model1 = tmp_model; tmp_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euc_dist(p, q):\n",
    "    return euclidean_norm(p - q)\n",
    "def euc_dist_grad(b, A, x):\n",
    "    x = x.reshape(-1, 1)\n",
    "    b = b.reshape(-1, 1)\n",
    "    norm = euc_dist(A.dot(x), b)\n",
    "    res = A.T.dot(A.dot(x) - b)\n",
    "    if norm != 0:\n",
    "        res = res / norm\n",
    "    return res\n",
    "def cos_dist(p, q):\n",
    "    p = p.reshape(-1, 1)\n",
    "    q = q.reshape(-1, 1)\n",
    "    return cosine_distances(p, q)[0][0]\n",
    "def cos_dist_grad(b, A, x):\n",
    "    x = x.reshape(-1, 1)\n",
    "    b = b.reshape(-1, 1)\n",
    "    y = A.dot(x)\n",
    "    u = b.T.dot(y) # number\n",
    "    deriv_u = A.T.dot(b) * x\n",
    "    v = euclidean_norm(y) * euclidean_norm(b)\n",
    "    nom = deriv_u * v - A.T.dot(A).dot(x) * u[0][0] * euclidean_norm(b) / euclidean_norm(y)\n",
    "    denom = v * v\n",
    "    if denom != 0:\n",
    "        res = nom / denom\n",
    "    else:\n",
    "        res = nom\n",
    "    return -res\n",
    "def hellinger_dist(p, q):\n",
    "    return np.sqrt(np.sum((np.sqrt(p) - np.sqrt(q)) ** 2)) / np.sqrt(2) \n",
    "def hellinger_dist_grad(b, A, x):\n",
    "    y = A.dot(x)\n",
    "    nom = np.divide(np.sqrt(y) - np.sqrt(b), np.sqrt(y)).dot(A)\n",
    "    denom = 2 * hellinger_dist(y, b) * np.sqrt(2)\n",
    "    res = nom / denom \n",
    "    return res\n",
    "def hellinger_dist_grad_nan(b, A, x):\n",
    "    y = A.dot(x)\n",
    "    tmp = np.divide(np.sqrt(y) - np.sqrt(b), np.sqrt(y))\n",
    "    tmp[np.isnan(tmp)] = 0\n",
    "    nom = tmp.dot(A)\n",
    "    denom = 2 * hellinger_dist(y, b) * np.sqrt(2)\n",
    "    res = nom / denom \n",
    "    return res\n",
    "def hellinger_dist_grad_eps(b, A, x):\n",
    "    y = A.dot(x)\n",
    "    y[y == 0] = 1e-3\n",
    "    tmp = np.divide(np.sqrt(y) - np.sqrt(b), np.sqrt(y))\n",
    "    nom = tmp.dot(A)\n",
    "    denom = 2 * hellinger_dist(y, b) * np.sqrt(2)\n",
    "    res = nom / denom \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_pickle_file(dists, filename):\n",
    "    pickle_filename = path.join(config.experiment_path, filename)\n",
    "    pickle_file = open(pickle_filename, 'wb')\n",
    "    pickle.dump(dists, pickle_file)\n",
    "    pickle_file.close()\n",
    "def calculate_distances(dist, jac_dist, phi):\n",
    "    distances = {}\n",
    "    col_idx = 0\n",
    "    for col in phi.columns:\n",
    "        print '[{}] caclulating dist for column {}'.format(datetime.now(), col_idx)\n",
    "        distances[col] = calculate_distance(dist, jac_dist, col_idx, phi)\n",
    "        col_idx += 1\n",
    "    return distances\n",
    "def calculate_distance(dist, jac_dist, col_idx, phi):\n",
    "    max_iter = 50\n",
    "    col = phi.iloc[:, col_idx]\n",
    "    phi_cut = phi.drop(phi.columns[col_idx], axis=1)\n",
    "    n_columns = phi_cut.shape[1] \n",
    "    print phi_cut.shape, col.shape\n",
    "    bnds = [(0, 1)] * n_columns\n",
    "    constraints = cons = ({'type': 'eq', 'fun': lambda x:  np.sum(x) - 1, 'jac': lambda x: [1] * n_columns})\n",
    "    fun = lambda x: dist(col, phi_cut.dot(x))\n",
    "    jac = lambda x: jac_dist(col, phi_cut, x)\n",
    "    is_optimized = False\n",
    "    it = 0\n",
    "    while (not is_optimized) and it != 4:\n",
    "        it += 1\n",
    "        init_x = np.random.uniform(0, 1, (1, n_columns))\n",
    "        init_x /= np.sum(init_x)\n",
    "        if jac_dist is not None:\n",
    "            res = minimize(fun, jac=jac, x0=init_x, method='SLSQP', bounds=bnds, constraints=cons, options={'maxiter': max_iter, 'disp': True})\n",
    "        else:\n",
    "            res = minimize(fun, x0=init_x, method='SLSQP', bounds=bnds, constraints=cons, options={'maxiter': max_iter, 'disp': True})\n",
    "        is_optimized = res.success\n",
    "    res['column_names'] = phi_cut.columns\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dists_c1 = calculate_distances(cos_dist, None, phi1)\n",
    "save_pickle_file(dists_c1, 'dists_c_none.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dists_c2 = calculate_distances(cos_dist, cos_dist_grad, phi1)\n",
    "save_pickle_file(dists_c2, 'dists_c.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dists_h1 = calculate_distances(hellinger_dist, None, phi1)\n",
    "save_pickle_file(dists_h1, 'dists_h_none.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dists_h2 = calculate_distances(hellinger_dist, hellinger_dist_grad_nan, phi1)\n",
    "save_pickle_file(dists_h2, 'dists_h_nan.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dists_h3 = calculate_distances(hellinger_dist, hellinger_dist_grad_eps, phi1)\n",
    "save_pickle_file(dists_h3, 'dists_h_eps.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dists_e1 = calculate_distances(euc_dist, None, phi1)\n",
    "save_pickle_file(dists_e1, 'dists_e_none.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dists_e2 = calculate_distances(euc_dist, euc_dist_grad, phi1)\n",
    "save_pickle_file(dists_e2, 'dists_e.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_file.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
