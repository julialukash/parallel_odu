{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import artm\n",
    "print artm.version()\n",
    "\n",
    "from os import path, mkdir\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "sys.path.insert(0, '..\\\\modules\\\\helpers')\n",
    "from plot_helper import PlotMaker\n",
    "from config_helper import ConfigPaths\n",
    "from print_helper import PrintHelper\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import ConvexHull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = ConfigPaths('config.cfg')\n",
    "plot_maker = PlotMaker()\n",
    "printer = PrintHelper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:\\\\topic_modeling\\\\csi_science_collections.git\\experiments\\UCI_filtered_ngramm_trimmed_without_names\\03_12_comp\\models.txt\n"
     ]
    }
   ],
   "source": [
    "print config.models_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_file = open(config.models_file_name, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(current_dictionary, n_topics, n_doc_passes, seed_value, n_top_tokens, p_mass_threshold):    \n",
    "    print '[{}] creating model'.format(datetime.now())\n",
    "    model = artm.ARTM(num_topics=n_topics, dictionary=current_dictionary, cache_theta=True, seed=seed_value, \n",
    "                  class_ids={'ngramm': 1.0, 'author_id': 0.0, 'author': 0.0, \n",
    "                             'post_tag': 0.0, 'projects': 0.0, 'category': 0.0,\n",
    "                             'following_users': 0.0})\n",
    "    model.num_document_passes = n_doc_passes\n",
    "    add_scores_to_model(model, n_top_tokens=n_top_tokens, p_mass_threshold=p_mass_threshold)\n",
    "    return model\n",
    "\n",
    "\n",
    "def add_scores_to_model(artm_model, n_top_tokens, p_mass_threshold):\n",
    "    print '[{}] adding scores'.format(datetime.now())\n",
    "    artm_model.scores.add(artm.PerplexityScore(name='perplexity_score',\n",
    "                                      use_unigram_document_model=False,\n",
    "                                      dictionary=dictionary))\n",
    "    artm_model.scores.add(artm.SparsityPhiScore(name='sparsity_phi_score', class_id='ngramm'))\n",
    "    artm_model.scores.add(artm.SparsityThetaScore(name='sparsity_theta_score'))\n",
    "    artm_model.scores.add(artm.TopicKernelScore(name='topic_kernel_score', class_id='ngramm', \n",
    "                                                probability_mass_threshold=p_mass_threshold))\n",
    "    artm_model.scores.add(artm.TopTokensScore(name='top_tokens_score', class_id='ngramm', num_tokens=n_top_tokens))\n",
    "def fit_one_model(model, _n_iterations, _model_name=''): \n",
    "    print '[{}] fitting'.format(datetime.now())\n",
    "    model.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=_n_iterations)\n",
    "    print '[{}] outputting'.format(datetime.now())\n",
    "    printer.print_artm_model(model, _model_name, _n_iterations, output_file=models_file)\n",
    "    model_pics_file_name =  path.join(config.experiment_path, _model_name)\n",
    "    plot_maker.make_tm_plots(model, model_pics_file_name)\n",
    "    model_output_file_name = path.join(config.experiment_path, _model_name + '.txt')\n",
    "    printer.print_scores(model, _model_name, _n_iterations, model_output_file_name)\n",
    "    printer.print_top_tokens(model, model_output_file_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(_model, _model_name): \n",
    "    print '[{}] saving model'.format(datetime.now())\n",
    "    model_output_file_name = path.join(config.models_archive_path, _model_name)\n",
    "    _model.save(filename=model_output_file_name+'_saved_p_wt', model_name=_model_name+'p_wt')\n",
    "    _model.save(filename=model_output_file_name+'_saved_n_wt', model_name=_model_name+'n_wt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_vectorizer = artm.BatchVectorizer(data_path=config.dataset_path,\n",
    "                                        data_format='bow_uci',\n",
    "                                        collection_name=config.collection_name,\n",
    "                                        target_folder=config.output_batches_path)\n",
    "dictionary = artm.Dictionary()\n",
    "dictionary.gather(data_path=config.output_batches_path,\n",
    "                  vocab_file_path=config.vocabulary_path)\n",
    "dictionary.save(dictionary_path=config.dictionary_path)\n",
    "dictionary.save_text(dictionary_path=config.dictionary_path + '.txt')\n",
    "dictionary.load_text(dictionary_path=config.dictionary_path + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_vectorizer = artm.BatchVectorizer(data_path=config.output_batches_path,\n",
    "                                        data_format='batches')\n",
    "dictionary = artm.Dictionary()\n",
    "dictionary.load(dictionary_path=config.dictionary_path + '.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary.filter(min_tf=5, max_tf=2000, min_df_rate=0.01, max_df_rate=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016-12-03 23:20:02.954000] creating model\n",
      "[2016-12-03 23:20:04.709000] adding scores\n",
      "[2016-12-03 23:20:04.723000] fitting\n",
      "[2016-12-03 23:20:33.626000] outputting\n",
      "name = model_decor_sparse_t_reg_1, n_topics = 100, n_doc_passes = 5, seed_value = 100, n_iterations = 15, n_top_tokens = 15, p_threshold = 0.25\n",
      "ss_theta_regularizer, tau = -0.01\n",
      "decorrelator_phi_regularizer, tau = 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp_model = create_model(current_dictionary=dictionary, n_topics=100, n_doc_passes=5, seed_value=100,\n",
    "                         n_top_tokens=15, p_mass_threshold=0.25)\n",
    "tmp_model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_regularizer', class_ids=['ngramm']))\n",
    "tmp_model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='ss_theta_regularizer'))\n",
    "tmp_model.regularizers['decorrelator_phi_regularizer'].tau = 100\n",
    "tmp_model.regularizers['ss_theta_regularizer'].tau = -0.01\n",
    "tmp_model = fit_one_model(tmp_model, _n_iterations=15, _model_name='model_decor_sparse_t_reg_1')\n",
    "model1 = tmp_model; tmp_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016-12-03 23:20:49.807000] creating model\n",
      "[2016-12-03 23:20:51.193000] adding scores\n",
      "[2016-12-03 23:20:51.201000] fitting\n",
      "[2016-12-03 23:21:08.759000] outputting\n",
      "name = model_decor_sparse_t_reg_2, n_topics = 50, n_doc_passes = 5, seed_value = 100, n_iterations = 15, n_top_tokens = 15, p_threshold = 0.25\n",
      "ss_theta_regularizer, tau = -0.01\n",
      "decorrelator_phi_regularizer, tau = 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp_model = create_model(current_dictionary=dictionary, n_topics=50, n_doc_passes=5, seed_value=100,\n",
    "                         n_top_tokens=15, p_mass_threshold=0.25)\n",
    "tmp_model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_regularizer', class_ids=['ngramm']))\n",
    "tmp_model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='ss_theta_regularizer'))\n",
    "tmp_model.regularizers['decorrelator_phi_regularizer'].tau = 100\n",
    "tmp_model.regularizers['ss_theta_regularizer'].tau = -0.01\n",
    "tmp_model = fit_one_model(tmp_model, _n_iterations=15, _model_name='model_decor_sparse_t_reg_2')\n",
    "model2 = tmp_model; tmp_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phi1 = model1.get_phi()\n",
    "phi1_t = phi1.transpose()\n",
    "phi2 = model2.get_phi()\n",
    "phi2_t = phi2.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_distance(topic, other_topic):\n",
    "    # take elements that are both nonzero\n",
    "    nonzero_indices = np.intersect1d(np.where(topic != 0), np.where(other_topic != 0))\n",
    "    topic_cut = topic[nonzero_indices]\n",
    "    other_topic_cut = other_topic[nonzero_indices]\n",
    "    if len(nonzero_indices) == 0:\n",
    "        dist = float('inf')\n",
    "    else:\n",
    "        dist = np.sum(0.5 * (np.log(topic_cut) - np.log(other_topic_cut)) * (topic_cut - other_topic_cut))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def take_distances(_phi, _phi_other):\n",
    "    print '[{}] take_distances between {} columns and {} columns'.format(datetime.now(), len(_phi.columns), len(_phi_other.columns))\n",
    "    distances = pd.DataFrame(0, index = _phi.columns, columns=_phi_other.columns)\n",
    "    for col_idx in range(len(_phi.columns)):\n",
    "        print '[{}] column num {} of {}'.format(datetime.now(), col_idx, len(_phi.columns))\n",
    "        for other_col_idx in range(len(_phi_other.columns)):\n",
    "            distance = get_distance(_phi.iloc[:, col_idx], _phi_other.iloc[:, other_col_idx])\n",
    "            distances.iloc[col_idx, other_col_idx] = distance\n",
    "    return distances\n",
    "def distances_to_str_by_rows(distances, _n_topics):\n",
    "    str = ''\n",
    "    for n_row in range(len(distances.index)):\n",
    "        values = distances.iloc[n_row, :].sort_values().head(_n_topics)\n",
    "        value = ', '.join(['{} : {}'.format(values.index[ind], values[ind]) for ind in range(len(values))])\n",
    "        str += '{} | {}\\n'.format(distances.index[n_row], value)\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016-12-03 23:21:22.900000] take_distances between 50 columns and 100 columns\n",
      "[2016-12-03 23:21:22.901000] column num 0 of 50\n",
      "[2016-12-03 23:21:23.654000] column num 1 of 50\n",
      "[2016-12-03 23:21:24.299000] column num 2 of 50\n",
      "[2016-12-03 23:21:24.926000] column num 3 of 50\n",
      "[2016-12-03 23:21:25.604000] column num 4 of 50\n",
      "[2016-12-03 23:21:26.273000] column num 5 of 50\n",
      "[2016-12-03 23:21:26.875000] column num 6 of 50\n",
      "[2016-12-03 23:21:27.554000] column num 7 of 50\n",
      "[2016-12-03 23:21:28.218000] column num 8 of 50\n",
      "[2016-12-03 23:21:28.842000] column num 9 of 50\n",
      "[2016-12-03 23:21:29.516000] column num 10 of 50\n",
      "[2016-12-03 23:21:30.214000] column num 11 of 50\n",
      "[2016-12-03 23:21:30.885000] column num 12 of 50\n",
      "[2016-12-03 23:21:31.530000] column num 13 of 50\n",
      "[2016-12-03 23:21:32.179000] column num 14 of 50\n",
      "[2016-12-03 23:21:32.839000] column num 15 of 50\n",
      "[2016-12-03 23:21:33.477000] column num 16 of 50\n",
      "[2016-12-03 23:21:34.142000] column num 17 of 50\n",
      "[2016-12-03 23:21:34.707000] column num 18 of 50\n",
      "[2016-12-03 23:21:35.352000] column num 19 of 50\n",
      "[2016-12-03 23:21:36.063000] column num 20 of 50\n",
      "[2016-12-03 23:21:36.722000] column num 21 of 50\n",
      "[2016-12-03 23:21:37.401000] column num 22 of 50\n",
      "[2016-12-03 23:21:38.058000] column num 23 of 50\n",
      "[2016-12-03 23:21:38.698000] column num 24 of 50\n",
      "[2016-12-03 23:21:39.323000] column num 25 of 50\n",
      "[2016-12-03 23:21:39.947000] column num 26 of 50\n",
      "[2016-12-03 23:21:40.642000] column num 27 of 50\n",
      "[2016-12-03 23:21:41.258000] column num 28 of 50\n",
      "[2016-12-03 23:21:41.916000] column num 29 of 50\n",
      "[2016-12-03 23:21:42.503000] column num 30 of 50\n",
      "[2016-12-03 23:21:43.164000] column num 31 of 50\n",
      "[2016-12-03 23:21:43.799000] column num 32 of 50\n",
      "[2016-12-03 23:21:44.445000] column num 33 of 50\n",
      "[2016-12-03 23:21:45.117000] column num 34 of 50\n",
      "[2016-12-03 23:21:45.775000] column num 35 of 50\n",
      "[2016-12-03 23:21:46.383000] column num 36 of 50\n",
      "[2016-12-03 23:21:47.013000] column num 37 of 50\n",
      "[2016-12-03 23:21:47.656000] column num 38 of 50\n",
      "[2016-12-03 23:21:48.238000] column num 39 of 50\n",
      "[2016-12-03 23:21:48.856000] column num 40 of 50\n",
      "[2016-12-03 23:21:49.518000] column num 41 of 50\n",
      "[2016-12-03 23:21:50.136000] column num 42 of 50\n",
      "[2016-12-03 23:21:50.702000] column num 43 of 50\n",
      "[2016-12-03 23:21:51.346000] column num 44 of 50\n",
      "[2016-12-03 23:21:52.011000] column num 45 of 50\n",
      "[2016-12-03 23:21:52.664000] column num 46 of 50\n",
      "[2016-12-03 23:21:53.336000] column num 47 of 50\n",
      "[2016-12-03 23:21:53.980000] column num 48 of 50\n",
      "[2016-12-03 23:21:54.648000] column num 49 of 50\n"
     ]
    }
   ],
   "source": [
    "distances = take_distances(phi2, phi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0 | topic_0 : 2.05394411087, topic_57 : 3.52333402634, topic_18 : 4.42354679108\n",
      "topic_1 | topic_1 : 0.957847476006, topic_75 : 1.60966968536, topic_15 : 4.0636100769\n",
      "topic_2 | topic_2 : 0.831335067749, topic_64 : 2.59058761597, topic_89 : 3.10039997101\n",
      "topic_3 | topic_98 : 2.35483384132, topic_73 : 2.44401478767, topic_92 : 3.33433294296\n",
      "topic_4 | topic_68 : 2.93214654922, topic_55 : 3.63667440414, topic_78 : 4.349609375\n",
      "topic_5 | topic_5 : 2.64490389824, topic_81 : 3.2126262188, topic_61 : 3.36071968079\n",
      "topic_6 | topic_6 : 2.45645022392, topic_87 : 3.45866441727, topic_68 : 3.65049815178\n",
      "topic_7 | topic_7 : 1.73223555088, topic_8 : 4.45220947266, topic_22 : 4.65224123001\n",
      "topic_8 | topic_8 : 3.6936712265, topic_57 : 3.7868950367, topic_90 : 4.60551548004\n",
      "topic_9 | topic_9 : 3.01174807549, topic_64 : 4.23945713043, topic_86 : 4.43224334717\n",
      "topic_10 | topic_10 : 1.49747776985, topic_69 : 4.73697042465, topic_73 : 4.77277517319\n",
      "topic_11 | topic_11 : 0.871329724789, topic_57 : 3.34069395065, topic_66 : 4.05449676514\n",
      "topic_12 | topic_12 : 1.93703532219, topic_71 : 4.04335308075, topic_84 : 4.14589929581\n",
      "topic_13 | topic_13 : 1.92766547203, topic_89 : 2.94344139099, topic_2 : 3.28733444214\n",
      "topic_14 | topic_14 : 2.03910803795, topic_2 : 3.12854337692, topic_89 : 3.15545606613\n",
      "topic_15 | topic_15 : 1.37129998207, topic_74 : 3.27931880951, topic_1 : 4.01687335968\n",
      "topic_16 | topic_16 : 1.74173736572, topic_79 : 3.07739138603, topic_57 : 3.21499300003\n",
      "topic_17 | topic_78 : 1.17040860653, topic_71 : 2.51810455322, topic_17 : 2.5266726017\n",
      "topic_18 | topic_18 : 1.39223456383, topic_93 : 1.48592162132, topic_7 : 2.58838129044\n",
      "topic_19 | topic_19 : 1.98657989502, topic_27 : 3.88870000839, topic_2 : 4.21719646454\n",
      "topic_20 | topic_20 : 0.684966564178, topic_61 : 4.20126104355, topic_66 : 4.77717399597\n",
      "topic_21 | topic_21 : 2.73127031326, topic_57 : 2.98446941376, topic_89 : 3.39640522003\n",
      "topic_22 | topic_22 : 1.22564411163, topic_57 : 3.91751623154, topic_3 : 3.96280479431\n",
      "topic_23 | topic_23 : 0.469686716795, topic_57 : 4.49801063538, topic_2 : 4.6655626297\n",
      "topic_24 | topic_24 : 1.82816338539, topic_62 : 3.21199440956, topic_65 : 3.44010519981\n",
      "topic_25 | topic_25 : 0.958798289299, topic_66 : 4.00775718689, topic_57 : 4.1862487793\n",
      "topic_26 | topic_26 : 1.11738228798, topic_66 : 3.58082890511, topic_95 : 3.83946442604\n",
      "topic_27 | topic_54 : 1.31305551529, topic_55 : 3.41251778603, topic_74 : 4.36547327042\n",
      "topic_28 | topic_28 : 1.60558402538, topic_57 : 3.46859622002, topic_56 : 3.59210038185\n",
      "topic_29 | topic_29 : 2.10672092438, topic_80 : 3.19025731087, topic_61 : 3.73919057846\n",
      "topic_30 | topic_30 : 2.42576313019, topic_58 : 3.31216478348, topic_57 : 3.52216482162\n",
      "topic_31 | topic_31 : 3.07358407974, topic_51 : 3.49207687378, topic_78 : 4.66382598877\n",
      "topic_32 | topic_32 : 2.08801651001, topic_65 : 2.87838053703, topic_89 : 4.81288576126\n",
      "topic_33 | topic_33 : 2.12100839615, topic_57 : 3.78478860855, topic_72 : 4.48147678375\n",
      "topic_34 | topic_34 : 0.581960856915, topic_2 : 3.85084223747, topic_66 : 4.06426668167\n",
      "topic_35 | topic_35 : 1.25106978416, topic_82 : 2.44746994972, topic_38 : 3.52138233185\n",
      "topic_36 | topic_36 : 0.534565925598, topic_68 : 4.78937911987, topic_6 : 4.92857551575\n",
      "topic_37 | topic_37 : 1.50934159756, topic_57 : 3.36473035812, topic_2 : 3.42968058586\n",
      "topic_38 | topic_38 : 0.450920879841, topic_66 : 3.55507254601, topic_74 : 3.92131257057\n",
      "topic_39 | topic_39 : 0.662586390972, topic_57 : 4.05442142487, topic_81 : 4.43740367889\n",
      "topic_40 | topic_40 : 1.23781609535, topic_70 : 3.44384598732, topic_57 : 3.59266281128\n",
      "topic_41 | topic_41 : 1.29489684105, topic_53 : 3.2206056118, topic_57 : 4.45569896698\n",
      "topic_42 | topic_57 : 0.604071974754, topic_61 : 3.23131966591, topic_65 : 3.36889672279\n",
      "topic_43 | topic_43 : 0.622463822365, topic_57 : 3.36911559105, topic_78 : 4.28624391556\n",
      "topic_44 | topic_44 : 0.422358840704, topic_48 : 3.83531332016, topic_32 : 3.97685432434\n",
      "topic_45 | topic_45 : 1.71170163155, topic_99 : 2.63965702057, topic_95 : 4.34651851654\n",
      "topic_46 | topic_46 : 1.96868979931, topic_57 : 3.95609998703, topic_73 : 4.09108257294\n",
      "topic_47 | topic_47 : 1.01426184177, topic_50 : 3.77371525764, topic_57 : 3.86949706078\n",
      "topic_48 | topic_48 : 0.771019816399, topic_57 : 3.79621076584, topic_2 : 4.29727888107\n",
      "topic_49 | topic_49 : 1.32556700706, topic_76 : 2.97407054901, topic_60 : 3.47175621986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print distances_to_str_by_rows(distances, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_file.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
