{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.1\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import artm\n",
    "import seaborn as sns\n",
    "print artm.version()\n",
    "\n",
    "from os import path, mkdir\n",
    "from datetime import datetime\n",
    "sys.path.insert(0, '..\\\\modules\\\\helpers')\n",
    "from plot_helper import PlotMaker\n",
    "from config_helper import ConfigPaths\n",
    "from print_helper import PrintHelper\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from numpy.linalg import norm as euclidean_norm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = ConfigPaths('config.cfg')\n",
    "plot_maker = PlotMaker()\n",
    "printer = PrintHelper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:\\\\topic_modeling\\\\csi_science_collections.git\\experiments\\UCI_filtered_ngramm_trimmed_without_names\\np_10_12_500_opt_dists\\models.txt\n"
     ]
    }
   ],
   "source": [
    "print config.models_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_file = open(config.models_file_name, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(current_dictionary, n_topics, n_doc_passes, seed_value, n_top_tokens, p_mass_threshold):    \n",
    "    print '[{}] creating model'.format(datetime.now())\n",
    "    model = artm.ARTM(num_topics=n_topics, dictionary=current_dictionary, cache_theta=True, seed=seed_value, \n",
    "                  class_ids={'ngramm': 1.0, 'author_id': 0.0, 'author': 0.0, \n",
    "                             'post_tag': 0.0, 'projects': 0.0, 'category': 0.0,\n",
    "                             'following_users': 0.0})\n",
    "    model.num_document_passes = n_doc_passes\n",
    "    add_scores_to_model(model, n_top_tokens=n_top_tokens, p_mass_threshold=p_mass_threshold)\n",
    "    return model\n",
    "\n",
    "\n",
    "def add_scores_to_model(artm_model, n_top_tokens, p_mass_threshold):\n",
    "    print '[{}] adding scores'.format(datetime.now())\n",
    "    artm_model.scores.add(artm.PerplexityScore(name='perplexity_score',\n",
    "                                      use_unigram_document_model=False,\n",
    "                                      dictionary=dictionary))\n",
    "    artm_model.scores.add(artm.SparsityPhiScore(name='sparsity_phi_score', class_id='ngramm'))\n",
    "    artm_model.scores.add(artm.SparsityThetaScore(name='sparsity_theta_score'))\n",
    "    artm_model.scores.add(artm.TopicKernelScore(name='topic_kernel_score', class_id='ngramm', \n",
    "                                                probability_mass_threshold=p_mass_threshold))\n",
    "    artm_model.scores.add(artm.TopTokensScore(name='top_tokens_score', class_id='ngramm', num_tokens=n_top_tokens))\n",
    "def fit_one_model(model, _n_iterations, _model_name=''): \n",
    "    print '[{}] fitting'.format(datetime.now())\n",
    "    model.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=_n_iterations)\n",
    "    print '[{}] outputting'.format(datetime.now())\n",
    "    printer.print_artm_model(model, _model_name, _n_iterations, output_file=models_file)\n",
    "    model_pics_file_name =  path.join(config.experiment_path, _model_name)\n",
    "    plot_maker.make_tm_plots(model, model_pics_file_name)\n",
    "    model_output_file_name = path.join(config.experiment_path, _model_name + '.txt')\n",
    "    printer.print_scores(model, _model_name, _n_iterations, model_output_file_name)\n",
    "    printer.print_top_tokens(model, model_output_file_name)\n",
    "    return model\n",
    "def save_pickle_file(dists, filename):\n",
    "    pickle_filename = path.join(config.experiment_path, filename)\n",
    "    pickle_file = open(pickle_filename, 'wb')\n",
    "    pickle.dump(dists, pickle_file)\n",
    "    pickle_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_vectorizer = artm.BatchVectorizer(data_path=config.output_batches_path,\n",
    "                                        data_format='batches')\n",
    "dictionary = artm.Dictionary()\n",
    "dictionary.load(dictionary_path=config.dictionary_path + '.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016-12-10 20:33:32.478000] creating model\n",
      "[2016-12-10 20:33:35.009000] adding scores\n",
      "[2016-12-10 20:33:35.036000] fitting\n",
      "[2016-12-10 20:36:52.445000] outputting\n",
      "name = model1, n_topics = 500, n_doc_passes = 5, seed_value = 100, n_iterations = 20, n_top_tokens = 15, p_threshold = 0.25\n",
      "ss_theta_regularizer, tau = -0.1\n",
      "decorrelator_phi_regularizer, tau = 100\n",
      "ss_phi_regularizer, tau = -0.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp_model = create_model(current_dictionary=dictionary, n_topics=500, n_doc_passes=5, seed_value=100,\n",
    "                            n_top_tokens=15, p_mass_threshold=0.25)\n",
    "tmp_model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_regularizer', class_ids=['ngramm']))\n",
    "tmp_model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='ss_theta_regularizer'))\n",
    "tmp_model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='ss_phi_regularizer', class_ids=['ngramm']))\n",
    "tmp_model.regularizers['decorrelator_phi_regularizer'].tau = 100\n",
    "tmp_model.regularizers['ss_theta_regularizer'].tau = -0.1\n",
    "tmp_model.regularizers['ss_phi_regularizer'].tau = -0.05\n",
    "tmp_model = fit_one_model(tmp_model, _n_iterations=20, _model_name='model1')\n",
    "model1 = tmp_model; tmp_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016-12-10 20:37:33.773000] creating model\n",
      "[2016-12-10 20:37:35.541000] adding scores\n",
      "[2016-12-10 20:37:35.552000] fitting\n",
      "[2016-12-10 20:37:54.947000] outputting\n",
      "name = model2, n_topics = 10, n_doc_passes = 5, seed_value = 100, n_iterations = 20, n_top_tokens = 15, p_threshold = 0.25\n",
      "ss_theta_regularizer, tau = -0.1\n",
      "decorrelator_phi_regularizer, tau = 100\n",
      "ss_phi_regularizer, tau = -0.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp_model = create_model(current_dictionary=dictionary, n_topics=10, n_doc_passes=5, seed_value=100,\n",
    "                            n_top_tokens=15, p_mass_threshold=0.25)\n",
    "tmp_model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_regularizer', class_ids=['ngramm']))\n",
    "tmp_model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='ss_theta_regularizer'))\n",
    "tmp_model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='ss_phi_regularizer', class_ids=['ngramm']))\n",
    "tmp_model.regularizers['decorrelator_phi_regularizer'].tau = 100\n",
    "tmp_model.regularizers['ss_theta_regularizer'].tau = -0.1\n",
    "tmp_model.regularizers['ss_phi_regularizer'].tau = -0.05\n",
    "tmp_model = fit_one_model(tmp_model, _n_iterations=20, _model_name='model2')\n",
    "model2 = tmp_model; tmp_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euc_dist(p, q):\n",
    "    return euclidean_norm(p - q)\n",
    "def euc_dist_grad(b, A, x):\n",
    "    x = x.reshape(-1, 1)\n",
    "    b = b.reshape(-1, 1)\n",
    "    norm = euc_dist(A.dot(x), b)\n",
    "    res = A.T.dot(A.dot(x) - b)\n",
    "    if norm != 0:\n",
    "        res = res / norm\n",
    "    return res\n",
    "def cos_dist(p, q):\n",
    "    p = p.reshape(-1, 1)\n",
    "    q = q.reshape(-1, 1)\n",
    "    return cosine_distances(p, q)[0][0]\n",
    "def cos_dist_grad(b, A, x):\n",
    "    x = x.reshape(-1, 1)\n",
    "    b = b.reshape(-1, 1)\n",
    "    y = A.dot(x)\n",
    "    u = b.T.dot(y) # number\n",
    "    deriv_u = A.T.dot(b) * x\n",
    "    v = euclidean_norm(y) * euclidean_norm(b)\n",
    "    nom = deriv_u * v - A.T.dot(A).dot(x) * u[0][0] * euclidean_norm(b) / euclidean_norm(y)\n",
    "    denom = v * v\n",
    "    if denom != 0:\n",
    "        res = nom / denom\n",
    "    else:\n",
    "        res = nom\n",
    "    return -res\n",
    "def hellinger_dist(p, q):\n",
    "    return np.sqrt(np.sum((np.sqrt(p) - np.sqrt(q)) ** 2)) / np.sqrt(2) \n",
    "def hellinger_dist_grad(b, A, x):\n",
    "    y = A.dot(x)\n",
    "    nom = np.divide(np.sqrt(y) - np.sqrt(b), np.sqrt(y)).dot(A)\n",
    "    denom = 2 * hellinger_dist(y, b) * np.sqrt(2)\n",
    "    res = nom / denom \n",
    "    return res\n",
    "def hellinger_dist_grad_nan(b, A, x):\n",
    "    y = A.dot(x)\n",
    "    tmp = np.divide(np.sqrt(y) - np.sqrt(b), np.sqrt(y))\n",
    "    tmp[np.isnan(tmp)] = 0\n",
    "    nom = tmp.dot(A)\n",
    "    denom = 2 * hellinger_dist(y, b) * np.sqrt(2)\n",
    "    res = nom / denom \n",
    "    return res\n",
    "def hellinger_dist_grad_eps(b, A, x):\n",
    "    y = A.dot(x)\n",
    "    y[y == 0] = 1e-3\n",
    "    tmp = np.divide(np.sqrt(y) - np.sqrt(b), np.sqrt(y))\n",
    "    nom = tmp.dot(A)\n",
    "    denom = 2 * hellinger_dist(y, b) * np.sqrt(2)\n",
    "    res = nom / denom \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_optimal_solution_eps(_sol):\n",
    "    _eps = 1e-2\n",
    "    x = _sol.x\n",
    "    c = _sol.column_names\n",
    "    x_mask = x >_eps\n",
    "    x_cut = x[x_mask]\n",
    "    c_cut = c[x_mask]\n",
    "    combination = ', '.join(['{} : {}'.format(c_cut[ind], x_cut[ind]) for ind in range(len(x_cut))])\n",
    "    print 'fun = {}, optimized = {}'.format(_sol.fun, _sol.success)\n",
    "    print '{}: {}'.format(_sol.optimized_column, combination)\n",
    "def print_optimal_solution(_sol, _distances=None, _saved_top_tokens=None):\n",
    "    x = _sol.x\n",
    "    c = _sol.column_names\n",
    "    sorted_x = sorted(zip(x, c), reverse=True)[0 : NUM_INDICES]\n",
    "    if _distances is not None:\n",
    "        combination = ', '.join(['{0} : {1:0.2f} [{2:0.2f}]'.format(item[1], item[0], _distances[_sol.optimized_column][item[1]]) for item in sorted_x])\n",
    "        combination += '\\n' + distances_to_str_row(_distances, _sol.optimized_column, _n_topics=NUM_INDICES)\n",
    "    else:\n",
    "        combination = ', '.join(['{0} : {1:0.2f}'.format(item[1], item[0]) for item in sorted_x])\n",
    "    print '============================'\n",
    "    print 'fun = {}, optimized = {}'.format(_sol.fun, _sol.success)\n",
    "    print '{} | {}'.format(_sol.optimized_column, combination)\n",
    "    if _saved_top_tokens is not None:\n",
    "        topics_str = optimal_solution_topics_to_str(_saved_top_tokens, _sol.optimized_column, sorted_x)\n",
    "        print topics_str\n",
    "    print '============================'\n",
    "def unicode_list_to_str(_name, _list):\n",
    "    return _name + ': ' + ' '.join(_list)\n",
    "def optimal_solution_topics_to_str(_saved_top_tokens, topic_name, sorted_x):\n",
    "    topics = [item[1] for item in sorted_x]\n",
    "    topics.insert(0, topic_name)\n",
    "    str = \"\"\n",
    "    for topic_name in topics:\n",
    "        str += unicode_list_to_str(topic_name, _saved_top_tokens[topic_name]) + '\\n'\n",
    "    return str\n",
    "def calculate_distances(dist_fun, _phi, _phi_other):\n",
    "    print '[{}] take_distances between {} columns and {} columns'.format(datetime.now(), len(_phi.columns), len(_phi_other.columns))\n",
    "    distances = pd.DataFrame(0, index = _phi.columns, columns=_phi_other.columns)\n",
    "    for idx, col in enumerate(_phi.columns):\n",
    "        print '[{}] column num {} of {}'.format(datetime.now(), idx, len(_phi.columns))\n",
    "        for idx_other, col_other in enumerate(_phi_other.columns):\n",
    "            distance = dist_fun(_phi[col], _phi_other[col_other])\n",
    "            distances.iloc[idx, idx_other] = distance\n",
    "    return distances\n",
    "def distances_to_str_row(distances, topic, _n_topics):\n",
    "    values = distances[topic].sort_values().head(_n_topics)\n",
    "    value = ', '.join(['{0} : [{1:0.2f}]'.format(values.index[ind], values[ind]) for ind in range(len(values))])\n",
    "    str = 'closest by distance to {} | {}\\n'.format(topic, value)\n",
    "    return str\n",
    "def calculate_distances_one_col(dist, phi, column): \n",
    "    distances = pd.DataFrame(0, index = range(1), columns=phi.columns)\n",
    "    for idx, col in enumerate(phi.columns):\n",
    "        distance = dist(column, phi[col])\n",
    "        distances.iloc[0, idx] = distance\n",
    "    return distances\n",
    "def get_optimization_result(dist_fn, jac_dist_fn, phi, distances):\n",
    "    opt_results = {}\n",
    "    for col_idx, col in enumerate(phi.columns):\n",
    "        print '[{}] get_optimization_result for column {}'.format(datetime.now(), col_idx)\n",
    "        opt_results[col] = solve_optimization_problem(dist_fn, jac_dist_fn, col_idx, phi, distances)\n",
    "    return opt_results\n",
    "def solve_optimization_problem(dist_fn, jac_dist_fn, col_idx, phi, distances, verbose=False):\n",
    "    max_iter = 50\n",
    "    col_name = phi.columns[col_idx]\n",
    "    col = phi[col_name]\n",
    "    # get n closest topics\n",
    "    closest_indices = distances[col_name].sort_values().head(N_CLOSEST_TOPICS).index.values\n",
    "    phi_closest = phi[closest_indices]\n",
    "    # delete zero rows from matrix\n",
    "    phi_closest_nz = phi_closest[(phi_closest.T != 0).any()]\n",
    "    col_nz = phi_closest_nz[col_name]\n",
    "    # delete col from phi\n",
    "    phi_cut_nz = phi_closest_nz.drop(col_name, axis=1)\n",
    "    \n",
    "    # opt solver\n",
    "    n_columns = phi_cut_nz.shape[1] \n",
    "    bnds = [(0, 1)] * n_columns\n",
    "    constraints = cons = ({'type': 'eq', 'fun': lambda x:  np.sum(x) - 1, 'jac': lambda x: [1] * n_columns})\n",
    "    opt_fun = lambda x: dist_fn(col_nz, phi_cut_nz.dot(x))\n",
    "    jac_fun = lambda x: jac_dist_fn(col_nz, phi_cut_nz, x)\n",
    "    \n",
    "    is_optimized = False\n",
    "    it = 0\n",
    "    while (not is_optimized) and it != 4:\n",
    "        it += 1\n",
    "        init_x = np.random.uniform(0, 1, (1, n_columns))\n",
    "        init_x /= np.sum(init_x)\n",
    "        if jac_dist_fn is not None:\n",
    "            res = minimize(opt_fun, jac=jac_fun, x0=init_x, method='SLSQP', bounds=bnds, constraints=cons, options={'maxiter': max_iter, 'disp': verbose})\n",
    "        else:\n",
    "            res = minimize(opt_fun, x0=init_x, method='SLSQP', bounds=bnds, constraints=cons, options={'maxiter': max_iter, 'disp': verbose})\n",
    "        is_optimized = res.success\n",
    "    res['column_names'] = phi_cut_nz.columns\n",
    "    res['optimized_column'] = col_name\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_CLOSEST_TOPICS = 25\n",
    "phi1 = model1.get_phi()\n",
    "phi1 = phi1[(phi1.T != 0).any()]\n",
    "saved_top_tokens1 = model1.score_tracker['top_tokens_score'].last_tokens\n",
    "phi = phi1\n",
    "saved_top_tokens = saved_top_tokens1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016-12-10 22:03:41.944000] calculating distances\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.860765081112\n",
      "            Iterations: 35\n",
      "            Function evaluations: 953\n",
      "            Gradient evaluations: 35\n"
     ]
    }
   ],
   "source": [
    "ds_zero_col = solve_optimization_problem(hellinger_dist, None, 0, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016-12-10 22:19:02.426000] caclulating dist for column 0\n",
      "[2016-12-10 22:19:04.127000] caclulating dist for column 1\n",
      "[2016-12-10 22:19:05.808000] caclulating dist for column 2\n",
      "[2016-12-10 22:19:07.510000] caclulating dist for column 3\n",
      "[2016-12-10 22:19:09.736000] caclulating dist for column 4\n",
      "[2016-12-10 22:19:11.102000] caclulating dist for column 5\n",
      "[2016-12-10 22:19:12.773000] caclulating dist for column 6\n",
      "[2016-12-10 22:19:14.360000] caclulating dist for column 7\n",
      "[2016-12-10 22:19:16.021000] caclulating dist for column 8\n",
      "[2016-12-10 22:19:17.855000] caclulating dist for column 9\n",
      "[2016-12-10 22:19:19.401000] caclulating dist for column 10\n",
      "[2016-12-10 22:19:21.006000] caclulating dist for column 11\n",
      "[2016-12-10 22:19:22.558000] caclulating dist for column 12\n",
      "[2016-12-10 22:19:24.311000] caclulating dist for column 13\n",
      "[2016-12-10 22:19:25.830000] caclulating dist for column 14\n",
      "[2016-12-10 22:19:27.430000] caclulating dist for column 15\n",
      "[2016-12-10 22:19:29.001000] caclulating dist for column 16\n",
      "[2016-12-10 22:19:30.663000] caclulating dist for column 17\n",
      "[2016-12-10 22:19:32.520000] caclulating dist for column 18\n",
      "[2016-12-10 22:19:34.874000] caclulating dist for column 19\n",
      "[2016-12-10 22:19:37.084000] caclulating dist for column 20\n",
      "[2016-12-10 22:19:39.592000] caclulating dist for column 21\n",
      "[2016-12-10 22:19:41.999000] caclulating dist for column 22\n",
      "[2016-12-10 22:19:43.745000] caclulating dist for column 23\n",
      "[2016-12-10 22:19:45.436000] caclulating dist for column 24\n",
      "[2016-12-10 22:19:46.923000] caclulating dist for column 25\n",
      "[2016-12-10 22:19:48.310000] caclulating dist for column 26\n",
      "[2016-12-10 22:19:49.845000] caclulating dist for column 27\n",
      "[2016-12-10 22:19:51.506000] caclulating dist for column 28\n",
      "[2016-12-10 22:19:53.618000] caclulating dist for column 29\n",
      "[2016-12-10 22:19:55.320000] caclulating dist for column 30\n",
      "[2016-12-10 22:19:56.955000] caclulating dist for column 31\n",
      "[2016-12-10 22:19:58.796000] caclulating dist for column 32\n",
      "[2016-12-10 22:20:00.582000] caclulating dist for column 33\n",
      "[2016-12-10 22:20:02.447000] caclulating dist for column 34\n",
      "[2016-12-10 22:20:03.933000] caclulating dist for column 35\n",
      "[2016-12-10 22:20:05.436000] caclulating dist for column 36\n",
      "[2016-12-10 22:20:07.226000] caclulating dist for column 37\n",
      "[2016-12-10 22:20:08.996000] caclulating dist for column 38\n",
      "[2016-12-10 22:20:11.250000] caclulating dist for column 39\n",
      "[2016-12-10 22:20:13.022000] caclulating dist for column 40\n",
      "[2016-12-10 22:20:14.988000] caclulating dist for column 41\n",
      "[2016-12-10 22:20:16.529000] caclulating dist for column 42\n",
      "[2016-12-10 22:20:18.063000] caclulating dist for column 43\n",
      "[2016-12-10 22:20:19.633000] caclulating dist for column 44\n",
      "[2016-12-10 22:20:21.114000] caclulating dist for column 45\n",
      "[2016-12-10 22:20:22.701000] caclulating dist for column 46\n",
      "[2016-12-10 22:20:24.799000] caclulating dist for column 47\n",
      "[2016-12-10 22:20:26.482000] caclulating dist for column 48\n",
      "[2016-12-10 22:20:28.032000] caclulating dist for column 49\n",
      "[2016-12-10 22:20:29.719000] caclulating dist for column 50\n",
      "[2016-12-10 22:20:31.336000] caclulating dist for column 51\n",
      "[2016-12-10 22:20:33.326000] caclulating dist for column 52\n",
      "[2016-12-10 22:20:34.844000] caclulating dist for column 53\n",
      "[2016-12-10 22:20:36.300000] caclulating dist for column 54\n",
      "[2016-12-10 22:20:37.934000] caclulating dist for column 55\n",
      "[2016-12-10 22:20:39.806000] caclulating dist for column 56\n",
      "[2016-12-10 22:20:41.992000] caclulating dist for column 57\n",
      "[2016-12-10 22:20:43.732000] caclulating dist for column 58\n",
      "[2016-12-10 22:20:45.513000] caclulating dist for column 59\n",
      "[2016-12-10 22:20:47.154000] caclulating dist for column 60\n",
      "[2016-12-10 22:20:48.994000] caclulating dist for column 61\n",
      "[2016-12-10 22:20:50.772000] caclulating dist for column 62\n",
      "[2016-12-10 22:20:53.090000] caclulating dist for column 63\n",
      "[2016-12-10 22:20:54.675000] caclulating dist for column 64\n",
      "[2016-12-10 22:20:56.762000] caclulating dist for column 65\n",
      "[2016-12-10 22:20:58.323000] caclulating dist for column 66\n",
      "[2016-12-10 22:21:00.045000] caclulating dist for column 67\n",
      "[2016-12-10 22:21:01.831000] caclulating dist for column 68\n",
      "[2016-12-10 22:21:03.331000] caclulating dist for column 69\n",
      "[2016-12-10 22:21:04.753000] caclulating dist for column 70\n",
      "[2016-12-10 22:21:06.371000] caclulating dist for column 71\n",
      "[2016-12-10 22:21:08.121000] caclulating dist for column 72\n",
      "[2016-12-10 22:21:09.743000] caclulating dist for column 73\n",
      "[2016-12-10 22:21:11.713000] caclulating dist for column 74\n",
      "[2016-12-10 22:21:13.434000] caclulating dist for column 75\n",
      "[2016-12-10 22:21:15.400000] caclulating dist for column 76\n",
      "[2016-12-10 22:21:16.906000] caclulating dist for column 77\n",
      "[2016-12-10 22:21:18.490000] caclulating dist for column 78\n",
      "[2016-12-10 22:21:20.313000] caclulating dist for column 79\n",
      "[2016-12-10 22:21:21.924000] caclulating dist for column 80\n",
      "[2016-12-10 22:21:23.657000] caclulating dist for column 81\n",
      "[2016-12-10 22:21:25.255000] caclulating dist for column 82\n",
      "[2016-12-10 22:21:27.143000] caclulating dist for column 83\n",
      "[2016-12-10 22:21:28.984000] caclulating dist for column 84\n",
      "[2016-12-10 22:21:30.603000] caclulating dist for column 85\n",
      "[2016-12-10 22:21:32.137000] caclulating dist for column 86\n",
      "[2016-12-10 22:21:33.810000] caclulating dist for column 87\n",
      "[2016-12-10 22:21:35.276000] caclulating dist for column 88\n",
      "[2016-12-10 22:21:36.915000] caclulating dist for column 89\n",
      "[2016-12-10 22:21:38.929000] caclulating dist for column 90\n",
      "[2016-12-10 22:21:40.521000] caclulating dist for column 91\n",
      "[2016-12-10 22:21:42.039000] caclulating dist for column 92\n",
      "[2016-12-10 22:21:43.607000] caclulating dist for column 93\n",
      "[2016-12-10 22:21:45.335000] caclulating dist for column 94\n",
      "[2016-12-10 22:21:46.932000] caclulating dist for column 95\n",
      "[2016-12-10 22:21:48.304000] caclulating dist for column 96\n",
      "[2016-12-10 22:21:49.937000] caclulating dist for column 97\n",
      "[2016-12-10 22:21:51.455000] caclulating dist for column 98\n",
      "[2016-12-10 22:21:53.291000] caclulating dist for column 99\n",
      "[2016-12-10 22:21:54.926000] caclulating dist for column 100\n",
      "[2016-12-10 22:21:56.437000] caclulating dist for column 101\n",
      "[2016-12-10 22:21:58.004000] caclulating dist for column 102\n",
      "[2016-12-10 22:21:59.641000] caclulating dist for column 103\n",
      "[2016-12-10 22:22:01.811000] caclulating dist for column 104\n",
      "[2016-12-10 22:22:03.213000] caclulating dist for column 105\n",
      "[2016-12-10 22:22:05.244000] caclulating dist for column 106\n",
      "[2016-12-10 22:22:07.357000] caclulating dist for column 107\n",
      "[2016-12-10 22:22:09.227000] caclulating dist for column 108\n",
      "[2016-12-10 22:22:11.046000] caclulating dist for column 109\n",
      "[2016-12-10 22:22:12.648000] caclulating dist for column 110\n",
      "[2016-12-10 22:22:14.367000] caclulating dist for column 111\n",
      "[2016-12-10 22:22:16.047000] caclulating dist for column 112\n",
      "[2016-12-10 22:22:17.748000] caclulating dist for column 113\n",
      "[2016-12-10 22:22:19.624000] caclulating dist for column 114\n",
      "[2016-12-10 22:22:22.113000] caclulating dist for column 115\n",
      "[2016-12-10 22:22:24.182000] caclulating dist for column 116\n",
      "[2016-12-10 22:22:25.871000] caclulating dist for column 117\n",
      "[2016-12-10 22:22:27.687000] caclulating dist for column 118\n",
      "[2016-12-10 22:22:29.481000] caclulating dist for column 119\n",
      "[2016-12-10 22:22:31.134000] caclulating dist for column 120\n",
      "[2016-12-10 22:22:32.903000] caclulating dist for column 121\n",
      "[2016-12-10 22:22:34.671000] caclulating dist for column 122\n",
      "[2016-12-10 22:22:36.274000] caclulating dist for column 123\n",
      "[2016-12-10 22:22:38.009000] caclulating dist for column 124\n",
      "[2016-12-10 22:22:39.791000] caclulating dist for column 125\n",
      "[2016-12-10 22:22:41.599000] caclulating dist for column 126\n",
      "[2016-12-10 22:22:43.318000] caclulating dist for column 127\n",
      "[2016-12-10 22:22:45.184000] caclulating dist for column 128\n",
      "[2016-12-10 22:22:47.386000] caclulating dist for column 129\n",
      "[2016-12-10 22:22:48.957000] caclulating dist for column 130\n",
      "[2016-12-10 22:22:50.576000] caclulating dist for column 131\n",
      "[2016-12-10 22:22:52.477000] caclulating dist for column 132\n",
      "[2016-12-10 22:22:54.164000] caclulating dist for column 133\n",
      "[2016-12-10 22:22:55.963000] caclulating dist for column 134\n",
      "[2016-12-10 22:22:57.429000] caclulating dist for column 135\n",
      "[2016-12-10 22:22:59.206000] caclulating dist for column 136\n",
      "[2016-12-10 22:23:01.647000] caclulating dist for column 137\n",
      "[2016-12-10 22:23:03.690000] caclulating dist for column 138\n",
      "[2016-12-10 22:23:05.508000] caclulating dist for column 139\n",
      "[2016-12-10 22:23:07.142000] caclulating dist for column 140\n",
      "[2016-12-10 22:23:09.015000] caclulating dist for column 141\n",
      "[2016-12-10 22:23:10.748000] caclulating dist for column 142\n",
      "[2016-12-10 22:23:12.934000] caclulating dist for column 143\n",
      "[2016-12-10 22:23:14.603000] caclulating dist for column 144\n",
      "[2016-12-10 22:23:16.336000] caclulating dist for column 145\n",
      "[2016-12-10 22:23:18.321000] caclulating dist for column 146\n",
      "[2016-12-10 22:23:20.630000] caclulating dist for column 147\n",
      "[2016-12-10 22:23:22.324000] caclulating dist for column 148\n",
      "[2016-12-10 22:23:23.941000] caclulating dist for column 149\n",
      "[2016-12-10 22:23:25.837000] caclulating dist for column 150\n",
      "[2016-12-10 22:23:27.544000] caclulating dist for column 151\n",
      "[2016-12-10 22:23:29.144000] caclulating dist for column 152\n",
      "[2016-12-10 22:23:30.977000] caclulating dist for column 153\n",
      "[2016-12-10 22:23:33.563000] caclulating dist for column 154\n",
      "[2016-12-10 22:23:35.568000] caclulating dist for column 155\n",
      "[2016-12-10 22:23:37.433000] caclulating dist for column 156\n",
      "[2016-12-10 22:23:39.049000] caclulating dist for column 157\n",
      "[2016-12-10 22:23:41.112000] caclulating dist for column 158\n",
      "[2016-12-10 22:23:42.973000] caclulating dist for column 159\n",
      "[2016-12-10 22:23:44.605000] caclulating dist for column 160\n",
      "[2016-12-10 22:23:46.650000] caclulating dist for column 161\n",
      "[2016-12-10 22:23:48.316000] caclulating dist for column 162\n",
      "[2016-12-10 22:23:49.980000] caclulating dist for column 163\n",
      "[2016-12-10 22:23:51.596000] caclulating dist for column 164\n",
      "[2016-12-10 22:23:53.496000] caclulating dist for column 165\n",
      "[2016-12-10 22:23:55.130000] caclulating dist for column 166\n",
      "[2016-12-10 22:23:56.917000] caclulating dist for column 167\n",
      "[2016-12-10 22:23:58.681000] caclulating dist for column 168\n",
      "[2016-12-10 22:24:00.337000] caclulating dist for column 169\n",
      "[2016-12-10 22:24:02.173000] caclulating dist for column 170\n",
      "[2016-12-10 22:24:03.693000] caclulating dist for column 171\n",
      "[2016-12-10 22:24:05.976000] caclulating dist for column 172\n",
      "[2016-12-10 22:24:07.824000] caclulating dist for column 173\n",
      "[2016-12-10 22:24:09.932000] caclulating dist for column 174\n",
      "[2016-12-10 22:24:11.387000] caclulating dist for column 175\n",
      "[2016-12-10 22:24:13.281000] caclulating dist for column 176\n",
      "[2016-12-10 22:24:15.054000] caclulating dist for column 177\n",
      "[2016-12-10 22:24:17.026000] caclulating dist for column 178\n",
      "[2016-12-10 22:24:18.512000] caclulating dist for column 179\n",
      "[2016-12-10 22:24:20.131000] caclulating dist for column 180\n",
      "[2016-12-10 22:24:21.833000] caclulating dist for column 181\n",
      "[2016-12-10 22:24:23.882000] caclulating dist for column 182\n",
      "[2016-12-10 22:24:25.534000] caclulating dist for column 183\n",
      "[2016-12-10 22:24:27.749000] caclulating dist for column 184\n",
      "[2016-12-10 22:24:29.599000] caclulating dist for column 185\n",
      "[2016-12-10 22:24:31.401000] caclulating dist for column 186\n",
      "[2016-12-10 22:24:32.769000] caclulating dist for column 187\n",
      "[2016-12-10 22:24:34.487000] caclulating dist for column 188\n",
      "[2016-12-10 22:24:36.089000] caclulating dist for column 189\n",
      "[2016-12-10 22:24:37.442000] caclulating dist for column 190\n",
      "[2016-12-10 22:24:39.260000] caclulating dist for column 191\n",
      "[2016-12-10 22:24:40.778000] caclulating dist for column 192\n",
      "[2016-12-10 22:24:42.915000] caclulating dist for column 193\n",
      "[2016-12-10 22:24:45.721000] caclulating dist for column 194\n",
      "[2016-12-10 22:24:47.238000] caclulating dist for column 195\n",
      "[2016-12-10 22:24:49.052000] caclulating dist for column 196\n",
      "[2016-12-10 22:24:50.983000] caclulating dist for column 197\n",
      "[2016-12-10 22:24:53.258000] caclulating dist for column 198\n",
      "[2016-12-10 22:24:55.260000] caclulating dist for column 199\n",
      "[2016-12-10 22:24:56.816000] caclulating dist for column 200\n",
      "[2016-12-10 22:24:58.416000] caclulating dist for column 201\n",
      "[2016-12-10 22:25:00.523000] caclulating dist for column 202\n",
      "[2016-12-10 22:25:02.364000] caclulating dist for column 203\n",
      "[2016-12-10 22:25:04.421000] caclulating dist for column 204\n",
      "[2016-12-10 22:25:06.204000] caclulating dist for column 205\n",
      "[2016-12-10 22:25:08.060000] caclulating dist for column 206\n",
      "[2016-12-10 22:25:10.071000] caclulating dist for column 207\n",
      "[2016-12-10 22:25:11.743000] caclulating dist for column 208\n",
      "[2016-12-10 22:25:14.001000] caclulating dist for column 209\n",
      "[2016-12-10 22:25:15.538000] caclulating dist for column 210\n",
      "[2016-12-10 22:25:17.087000] caclulating dist for column 211\n",
      "[2016-12-10 22:25:18.528000] caclulating dist for column 212\n",
      "[2016-12-10 22:25:20.093000] caclulating dist for column 213\n",
      "[2016-12-10 22:25:22.066000] caclulating dist for column 214\n",
      "[2016-12-10 22:25:24.763000] caclulating dist for column 215\n",
      "[2016-12-10 22:25:26.319000] caclulating dist for column 216\n",
      "[2016-12-10 22:25:27.984000] caclulating dist for column 217\n",
      "[2016-12-10 22:25:30.616000] caclulating dist for column 218\n",
      "[2016-12-10 22:25:32.272000] caclulating dist for column 219\n",
      "[2016-12-10 22:25:33.908000] caclulating dist for column 220\n",
      "[2016-12-10 22:25:35.574000] caclulating dist for column 221\n",
      "[2016-12-10 22:25:37.590000] caclulating dist for column 222\n",
      "[2016-12-10 22:25:39.152000] caclulating dist for column 223\n",
      "[2016-12-10 22:25:40.804000] caclulating dist for column 224\n",
      "[2016-12-10 22:25:42.389000] caclulating dist for column 225\n",
      "[2016-12-10 22:25:44.215000] caclulating dist for column 226\n",
      "[2016-12-10 22:25:46.224000] caclulating dist for column 227\n",
      "[2016-12-10 22:25:47.858000] caclulating dist for column 228\n",
      "[2016-12-10 22:25:49.406000] caclulating dist for column 229\n",
      "[2016-12-10 22:25:51.208000] caclulating dist for column 230\n",
      "[2016-12-10 22:25:52.987000] caclulating dist for column 231\n",
      "[2016-12-10 22:25:54.570000] caclulating dist for column 232\n",
      "[2016-12-10 22:25:56.442000] caclulating dist for column 233\n",
      "[2016-12-10 22:25:58.290000] caclulating dist for column 234\n",
      "[2016-12-10 22:25:59.959000] caclulating dist for column 235\n",
      "[2016-12-10 22:26:01.512000] caclulating dist for column 236\n",
      "[2016-12-10 22:26:03.101000] caclulating dist for column 237\n",
      "[2016-12-10 22:26:04.741000] caclulating dist for column 238\n",
      "[2016-12-10 22:26:06.430000] caclulating dist for column 239\n",
      "[2016-12-10 22:26:08.080000] caclulating dist for column 240\n",
      "[2016-12-10 22:26:09.710000] caclulating dist for column 241\n",
      "[2016-12-10 22:26:11.445000] caclulating dist for column 242\n",
      "[2016-12-10 22:26:12.989000] caclulating dist for column 243\n",
      "[2016-12-10 22:26:14.550000] caclulating dist for column 244\n",
      "[2016-12-10 22:26:16.406000] caclulating dist for column 245\n",
      "[2016-12-10 22:26:18.140000] caclulating dist for column 246\n",
      "[2016-12-10 22:26:19.791000] caclulating dist for column 247\n",
      "[2016-12-10 22:26:21.476000] caclulating dist for column 248\n",
      "[2016-12-10 22:26:23.465000] caclulating dist for column 249\n",
      "[2016-12-10 22:26:25.067000] caclulating dist for column 250\n",
      "[2016-12-10 22:26:26.908000] caclulating dist for column 251\n",
      "[2016-12-10 22:26:28.490000] caclulating dist for column 252\n",
      "[2016-12-10 22:26:30.940000] caclulating dist for column 253\n",
      "[2016-12-10 22:26:32.849000] caclulating dist for column 254\n",
      "[2016-12-10 22:26:34.733000] caclulating dist for column 255\n",
      "[2016-12-10 22:26:37.118000] caclulating dist for column 256\n",
      "[2016-12-10 22:26:39.010000] caclulating dist for column 257\n",
      "[2016-12-10 22:26:40.977000] caclulating dist for column 258\n",
      "[2016-12-10 22:26:42.708000] caclulating dist for column 259\n",
      "[2016-12-10 22:26:44.395000] caclulating dist for column 260\n",
      "[2016-12-10 22:26:46.467000] caclulating dist for column 261\n",
      "[2016-12-10 22:26:48.686000] caclulating dist for column 262\n",
      "[2016-12-10 22:26:51.002000] caclulating dist for column 263\n",
      "[2016-12-10 22:26:52.857000] caclulating dist for column 264\n",
      "[2016-12-10 22:26:54.456000] caclulating dist for column 265\n",
      "[2016-12-10 22:26:56.201000] caclulating dist for column 266\n",
      "[2016-12-10 22:26:58.225000] caclulating dist for column 267\n",
      "[2016-12-10 22:27:00.012000] caclulating dist for column 268\n",
      "[2016-12-10 22:27:01.888000] caclulating dist for column 269\n",
      "[2016-12-10 22:27:03.587000] caclulating dist for column 270\n",
      "[2016-12-10 22:27:05.300000] caclulating dist for column 271\n",
      "[2016-12-10 22:27:07.050000] caclulating dist for column 272\n",
      "[2016-12-10 22:27:08.856000] caclulating dist for column 273\n",
      "[2016-12-10 22:27:10.712000] caclulating dist for column 274\n",
      "[2016-12-10 22:27:12.381000] caclulating dist for column 275\n",
      "[2016-12-10 22:27:13.888000] caclulating dist for column 276\n",
      "[2016-12-10 22:27:15.589000] caclulating dist for column 277\n",
      "[2016-12-10 22:27:17.411000] caclulating dist for column 278\n",
      "[2016-12-10 22:27:19.345000] caclulating dist for column 279\n",
      "[2016-12-10 22:27:21.064000] caclulating dist for column 280\n",
      "[2016-12-10 22:27:23.071000] caclulating dist for column 281\n",
      "[2016-12-10 22:27:24.690000] caclulating dist for column 282\n",
      "[2016-12-10 22:27:26.407000] caclulating dist for column 283\n",
      "[2016-12-10 22:27:28.356000] caclulating dist for column 284\n",
      "[2016-12-10 22:27:30.029000] caclulating dist for column 285\n",
      "[2016-12-10 22:27:31.695000] caclulating dist for column 286\n",
      "[2016-12-10 22:27:33.567000] caclulating dist for column 287\n",
      "[2016-12-10 22:27:34.984000] caclulating dist for column 288\n",
      "[2016-12-10 22:27:36.741000] caclulating dist for column 289\n",
      "[2016-12-10 22:27:38.776000] caclulating dist for column 290\n",
      "[2016-12-10 22:27:40.443000] caclulating dist for column 291\n",
      "[2016-12-10 22:27:42.197000] caclulating dist for column 292\n",
      "[2016-12-10 22:27:43.996000] caclulating dist for column 293\n",
      "[2016-12-10 22:27:45.657000] caclulating dist for column 294\n",
      "[2016-12-10 22:27:47.527000] caclulating dist for column 295\n",
      "[2016-12-10 22:27:49.787000] caclulating dist for column 296\n",
      "[2016-12-10 22:27:51.455000] caclulating dist for column 297\n",
      "[2016-12-10 22:27:52.997000] caclulating dist for column 298\n",
      "[2016-12-10 22:27:54.610000] caclulating dist for column 299\n",
      "[2016-12-10 22:27:56.348000] caclulating dist for column 300\n",
      "[2016-12-10 22:27:58.230000] caclulating dist for column 301\n",
      "[2016-12-10 22:28:00.166000] caclulating dist for column 302\n",
      "[2016-12-10 22:28:01.816000] caclulating dist for column 303\n",
      "[2016-12-10 22:28:03.703000] caclulating dist for column 304\n",
      "[2016-12-10 22:28:05.259000] caclulating dist for column 305\n",
      "[2016-12-10 22:28:06.909000] caclulating dist for column 306\n",
      "[2016-12-10 22:28:08.713000] caclulating dist for column 307\n",
      "[2016-12-10 22:28:10.468000] caclulating dist for column 308\n",
      "[2016-12-10 22:28:12.218000] caclulating dist for column 309\n",
      "[2016-12-10 22:28:14.090000] caclulating dist for column 310\n",
      "[2016-12-10 22:28:15.741000] caclulating dist for column 311\n",
      "[2016-12-10 22:28:17.297000] caclulating dist for column 312\n",
      "[2016-12-10 22:28:18.953000] caclulating dist for column 313\n",
      "[2016-12-10 22:28:20.533000] caclulating dist for column 314\n",
      "[2016-12-10 22:28:22.136000] caclulating dist for column 315\n",
      "[2016-12-10 22:28:23.783000] caclulating dist for column 316\n",
      "[2016-12-10 22:28:25.446000] caclulating dist for column 317\n",
      "[2016-12-10 22:28:26.881000] caclulating dist for column 318\n",
      "[2016-12-10 22:28:28.552000] caclulating dist for column 319\n",
      "[2016-12-10 22:28:30.224000] caclulating dist for column 320\n",
      "[2016-12-10 22:28:31.804000] caclulating dist for column 321\n",
      "[2016-12-10 22:28:33.397000] caclulating dist for column 322\n",
      "[2016-12-10 22:28:35.017000] caclulating dist for column 323\n",
      "[2016-12-10 22:28:36.631000] caclulating dist for column 324\n",
      "[2016-12-10 22:28:38.384000] caclulating dist for column 325\n",
      "[2016-12-10 22:28:40.187000] caclulating dist for column 326\n",
      "[2016-12-10 22:28:41.959000] caclulating dist for column 327\n",
      "[2016-12-10 22:28:44.115000] caclulating dist for column 328\n",
      "[2016-12-10 22:28:45.803000] caclulating dist for column 329\n",
      "[2016-12-10 22:28:47.352000] caclulating dist for column 330\n",
      "[2016-12-10 22:28:49.067000] caclulating dist for column 331\n",
      "[2016-12-10 22:28:50.901000] caclulating dist for column 332\n",
      "[2016-12-10 22:28:52.796000] caclulating dist for column 333\n",
      "[2016-12-10 22:28:54.657000] caclulating dist for column 334\n",
      "[2016-12-10 22:28:56.409000] caclulating dist for column 335\n",
      "[2016-12-10 22:28:58.147000] caclulating dist for column 336\n",
      "[2016-12-10 22:28:59.797000] caclulating dist for column 337\n",
      "[2016-12-10 22:29:01.453000] caclulating dist for column 338\n",
      "[2016-12-10 22:29:03.556000] caclulating dist for column 339\n",
      "[2016-12-10 22:29:05.259000] caclulating dist for column 340\n",
      "[2016-12-10 22:29:06.994000] caclulating dist for column 341\n",
      "[2016-12-10 22:29:08.766000] caclulating dist for column 342\n",
      "[2016-12-10 22:29:10.561000] caclulating dist for column 343\n",
      "[2016-12-10 22:29:12.058000] caclulating dist for column 344\n",
      "[2016-12-10 22:29:13.698000] caclulating dist for column 345\n",
      "[2016-12-10 22:29:15.498000] caclulating dist for column 346\n",
      "[2016-12-10 22:29:17.318000] caclulating dist for column 347\n",
      "[2016-12-10 22:29:18.985000] caclulating dist for column 348\n",
      "[2016-12-10 22:29:21.729000] caclulating dist for column 349\n",
      "[2016-12-10 22:29:23.347000] caclulating dist for column 350\n",
      "[2016-12-10 22:29:25.189000] caclulating dist for column 351\n",
      "[2016-12-10 22:29:26.776000] caclulating dist for column 352\n",
      "[2016-12-10 22:29:28.279000] caclulating dist for column 353\n",
      "[2016-12-10 22:29:29.880000] caclulating dist for column 354\n",
      "[2016-12-10 22:29:31.560000] caclulating dist for column 355\n",
      "[2016-12-10 22:29:33.465000] caclulating dist for column 356\n",
      "[2016-12-10 22:29:35.521000] caclulating dist for column 357\n",
      "[2016-12-10 22:29:37.170000] caclulating dist for column 358\n",
      "[2016-12-10 22:29:39.947000] caclulating dist for column 359\n",
      "[2016-12-10 22:29:42.010000] caclulating dist for column 360\n",
      "[2016-12-10 22:29:43.745000] caclulating dist for column 361\n",
      "[2016-12-10 22:29:45.362000] caclulating dist for column 362\n",
      "[2016-12-10 22:29:47.233000] caclulating dist for column 363\n",
      "[2016-12-10 22:29:49.352000] caclulating dist for column 364\n",
      "[2016-12-10 22:29:50.871000] caclulating dist for column 365\n",
      "[2016-12-10 22:29:53.405000] caclulating dist for column 366\n",
      "[2016-12-10 22:29:54.962000] caclulating dist for column 367\n",
      "[2016-12-10 22:29:56.611000] caclulating dist for column 368\n",
      "[2016-12-10 22:29:58.271000] caclulating dist for column 369\n",
      "[2016-12-10 22:29:59.926000] caclulating dist for column 370\n",
      "[2016-12-10 22:30:01.629000] caclulating dist for column 371\n",
      "[2016-12-10 22:30:03.348000] caclulating dist for column 372\n",
      "[2016-12-10 22:30:05.368000] caclulating dist for column 373\n",
      "[2016-12-10 22:30:07.475000] caclulating dist for column 374\n",
      "[2016-12-10 22:30:09.111000] caclulating dist for column 375\n",
      "[2016-12-10 22:30:10.760000] caclulating dist for column 376\n",
      "[2016-12-10 22:30:12.567000] caclulating dist for column 377\n",
      "[2016-12-10 22:30:14.185000] caclulating dist for column 378\n",
      "[2016-12-10 22:30:15.877000] caclulating dist for column 379\n",
      "[2016-12-10 22:30:17.767000] caclulating dist for column 380\n",
      "[2016-12-10 22:30:19.286000] caclulating dist for column 381\n",
      "[2016-12-10 22:30:21.040000] caclulating dist for column 382\n",
      "[2016-12-10 22:30:22.596000] caclulating dist for column 383\n",
      "[2016-12-10 22:30:24.845000] caclulating dist for column 384\n",
      "[2016-12-10 22:30:26.429000] caclulating dist for column 385\n",
      "[2016-12-10 22:30:28.183000] caclulating dist for column 386\n",
      "[2016-12-10 22:30:29.918000] caclulating dist for column 387\n",
      "[2016-12-10 22:30:31.504000] caclulating dist for column 388\n",
      "[2016-12-10 22:30:33.270000] caclulating dist for column 389\n",
      "[2016-12-10 22:30:35.023000] caclulating dist for column 390\n",
      "[2016-12-10 22:30:36.532000] caclulating dist for column 391\n",
      "[2016-12-10 22:30:37.950000] caclulating dist for column 392\n",
      "[2016-12-10 22:30:39.500000] caclulating dist for column 393\n",
      "[2016-12-10 22:30:41.098000] caclulating dist for column 394\n",
      "[2016-12-10 22:30:42.747000] caclulating dist for column 395\n",
      "[2016-12-10 22:30:44.414000] caclulating dist for column 396\n",
      "[2016-12-10 22:30:46.149000] caclulating dist for column 397\n",
      "[2016-12-10 22:30:47.839000] caclulating dist for column 398\n",
      "[2016-12-10 22:30:49.572000] caclulating dist for column 399\n",
      "[2016-12-10 22:30:51.585000] caclulating dist for column 400\n",
      "[2016-12-10 22:30:53.155000] caclulating dist for column 401\n",
      "[2016-12-10 22:30:55.043000] caclulating dist for column 402\n",
      "[2016-12-10 22:30:56.646000] caclulating dist for column 403\n",
      "[2016-12-10 22:30:58.395000] caclulating dist for column 404\n",
      "[2016-12-10 22:31:00.136000] caclulating dist for column 405\n",
      "[2016-12-10 22:31:01.787000] caclulating dist for column 406\n",
      "[2016-12-10 22:31:03.414000] caclulating dist for column 407\n",
      "[2016-12-10 22:31:05.216000] caclulating dist for column 408\n",
      "[2016-12-10 22:31:06.919000] caclulating dist for column 409\n",
      "[2016-12-10 22:31:08.707000] caclulating dist for column 410\n",
      "[2016-12-10 22:31:10.448000] caclulating dist for column 411\n",
      "[2016-12-10 22:31:11.978000] caclulating dist for column 412\n",
      "[2016-12-10 22:31:13.749000] caclulating dist for column 413\n",
      "[2016-12-10 22:31:15.606000] caclulating dist for column 414\n",
      "[2016-12-10 22:31:17.360000] caclulating dist for column 415\n",
      "[2016-12-10 22:31:19.531000] caclulating dist for column 416\n",
      "[2016-12-10 22:31:21.269000] caclulating dist for column 417\n",
      "[2016-12-10 22:31:22.854000] caclulating dist for column 418\n",
      "[2016-12-10 22:31:24.305000] caclulating dist for column 419\n",
      "[2016-12-10 22:31:26.193000] caclulating dist for column 420\n",
      "[2016-12-10 22:31:27.916000] caclulating dist for column 421\n",
      "[2016-12-10 22:31:29.534000] caclulating dist for column 422\n",
      "[2016-12-10 22:31:30.954000] caclulating dist for column 423\n",
      "[2016-12-10 22:31:32.524000] caclulating dist for column 424\n",
      "[2016-12-10 22:31:34.243000] caclulating dist for column 425\n",
      "[2016-12-10 22:31:36.208000] caclulating dist for column 426\n",
      "[2016-12-10 22:31:37.909000] caclulating dist for column 427\n",
      "[2016-12-10 22:31:39.435000] caclulating dist for column 428\n",
      "[2016-12-10 22:31:41.078000] caclulating dist for column 429\n",
      "[2016-12-10 22:31:42.663000] caclulating dist for column 430\n",
      "[2016-12-10 22:31:44.181000] caclulating dist for column 431\n",
      "[2016-12-10 22:31:45.880000] caclulating dist for column 432\n",
      "[2016-12-10 22:31:47.529000] caclulating dist for column 433\n",
      "[2016-12-10 22:31:49.280000] caclulating dist for column 434\n",
      "[2016-12-10 22:31:50.925000] caclulating dist for column 435\n",
      "[2016-12-10 22:31:52.557000] caclulating dist for column 436\n",
      "[2016-12-10 22:31:54.308000] caclulating dist for column 437\n",
      "[2016-12-10 22:31:55.863000] caclulating dist for column 438\n",
      "[2016-12-10 22:31:57.484000] caclulating dist for column 439\n",
      "[2016-12-10 22:31:59.431000] caclulating dist for column 440\n",
      "[2016-12-10 22:32:01.149000] caclulating dist for column 441\n",
      "[2016-12-10 22:32:02.768000] caclulating dist for column 442\n",
      "[2016-12-10 22:32:04.609000] caclulating dist for column 443\n",
      "[2016-12-10 22:32:06.290000] caclulating dist for column 444\n",
      "[2016-12-10 22:32:09.015000] caclulating dist for column 445\n",
      "[2016-12-10 22:32:10.705000] caclulating dist for column 446\n",
      "[2016-12-10 22:32:12.391000] caclulating dist for column 447\n",
      "[2016-12-10 22:32:14.063000] caclulating dist for column 448\n",
      "[2016-12-10 22:32:15.866000] caclulating dist for column 449\n",
      "[2016-12-10 22:32:17.467000] caclulating dist for column 450\n",
      "[2016-12-10 22:32:19.272000] caclulating dist for column 451\n",
      "[2016-12-10 22:32:20.936000] caclulating dist for column 452\n",
      "[2016-12-10 22:32:22.476000] caclulating dist for column 453\n",
      "[2016-12-10 22:32:24.179000] caclulating dist for column 454\n",
      "[2016-12-10 22:32:26.207000] caclulating dist for column 455\n",
      "[2016-12-10 22:32:27.993000] caclulating dist for column 456\n",
      "[2016-12-10 22:32:29.722000] caclulating dist for column 457\n",
      "[2016-12-10 22:32:31.290000] caclulating dist for column 458\n",
      "[2016-12-10 22:32:33.239000] caclulating dist for column 459\n",
      "[2016-12-10 22:32:34.909000] caclulating dist for column 460\n",
      "[2016-12-10 22:32:36.674000] caclulating dist for column 461\n",
      "[2016-12-10 22:32:38.747000] caclulating dist for column 462\n",
      "[2016-12-10 22:32:40.264000] caclulating dist for column 463\n",
      "[2016-12-10 22:32:42.035000] caclulating dist for column 464\n",
      "[2016-12-10 22:32:44.153000] caclulating dist for column 465\n",
      "[2016-12-10 22:32:45.970000] caclulating dist for column 466\n",
      "[2016-12-10 22:32:47.687000] caclulating dist for column 467\n",
      "[2016-12-10 22:32:49.388000] caclulating dist for column 468\n",
      "[2016-12-10 22:32:51.075000] caclulating dist for column 469\n",
      "[2016-12-10 22:32:52.994000] caclulating dist for column 470\n",
      "[2016-12-10 22:32:55.265000] caclulating dist for column 471\n",
      "[2016-12-10 22:32:56.982000] caclulating dist for column 472\n",
      "[2016-12-10 22:32:59.499000] caclulating dist for column 473\n",
      "[2016-12-10 22:33:01.567000] caclulating dist for column 474\n",
      "[2016-12-10 22:33:03.824000] caclulating dist for column 475\n",
      "[2016-12-10 22:33:05.634000] caclulating dist for column 476\n",
      "[2016-12-10 22:33:07.803000] caclulating dist for column 477\n",
      "[2016-12-10 22:33:09.751000] caclulating dist for column 478\n",
      "[2016-12-10 22:33:11.512000] caclulating dist for column 479\n",
      "[2016-12-10 22:33:13.395000] caclulating dist for column 480\n",
      "[2016-12-10 22:33:15.597000] caclulating dist for column 481\n",
      "[2016-12-10 22:33:17.726000] caclulating dist for column 482\n",
      "[2016-12-10 22:33:20.014000] caclulating dist for column 483\n",
      "[2016-12-10 22:33:21.974000] caclulating dist for column 484\n",
      "[2016-12-10 22:33:23.899000] caclulating dist for column 485\n",
      "[2016-12-10 22:33:26.275000] caclulating dist for column 486\n",
      "[2016-12-10 22:33:28.047000] caclulating dist for column 487\n",
      "[2016-12-10 22:33:29.820000] caclulating dist for column 488\n",
      "[2016-12-10 22:33:31.489000] caclulating dist for column 489\n",
      "[2016-12-10 22:33:33.795000] caclulating dist for column 490\n",
      "[2016-12-10 22:33:36.034000] caclulating dist for column 491\n",
      "[2016-12-10 22:33:38.484000] caclulating dist for column 492\n",
      "[2016-12-10 22:33:40.842000] caclulating dist for column 493\n",
      "[2016-12-10 22:33:42.724000] caclulating dist for column 494\n",
      "[2016-12-10 22:33:44.848000] caclulating dist for column 495\n",
      "[2016-12-10 22:33:46.606000] caclulating dist for column 496\n",
      "[2016-12-10 22:33:48.215000] caclulating dist for column 497\n",
      "[2016-12-10 22:33:49.915000] caclulating dist for column 498\n",
      "[2016-12-10 22:33:51.686000] caclulating dist for column 499\n"
     ]
    }
   ],
   "source": [
    "distances = calculate_distances(hellinger_dist, phi, phi)\n",
    "ds = get_optimization_result(hellinger_dist, None, phi, distances)\n",
    "save_pickle_file(ds, 'dists_h_none.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x31977978>"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFoCAYAAADZ17inAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRESKUlgQERGRohQWREREpKj/H/S+JpOiLxm5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x254e1be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# построим распределение полученных distances\n",
    "vals = distances.values.flatten()\n",
    "sns.distplot(vals[vals != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# построим распределение полученных opt_fun "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27ca92b0>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFoCAYAAADZ17inAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQEksAAAlsQAAlMQCAFASCwBA6Qb24WM1HyIaHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27c30f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fs = [ds[col].fun for col in phi.columns]\n",
    "sns.distplot(fs, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# посмотрим на топики, которые < 0.76 и > 0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 8\n"
     ]
    }
   ],
   "source": [
    "low_th, high_th = 0.76, 0.89\n",
    "small_dist_opts = {col: ds[col] for col in phi.columns if ds[col].fun < low_th}\n",
    "large_dist_opts = {col: ds[col] for col in phi.columns if ds[col].fun > high_th}\n",
    "print len(small_dist_opts), len(large_dist_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.709351444397, optimized = True\n",
      "topic_57 | topic_145 : 0.53, topic_498 : 0.17, topic_177 : 0.08, topic_80 : 0.05, topic_399 : 0.04\n",
      "============================\n",
      "============================\n",
      "fun = 0.738238209879, optimized = True\n",
      "topic_38 | topic_58 : 0.31, topic_359 : 0.26, topic_346 : 0.06, topic_161 : 0.06, topic_379 : 0.05\n",
      "============================\n",
      "============================\n",
      "fun = 0.743417370783, optimized = True\n",
      "topic_373 | topic_67 : 0.10, topic_178 : 0.10, topic_284 : 0.10, topic_136 : 0.10, topic_51 : 0.07\n",
      "============================\n",
      "============================\n",
      "fun = 0.755007645115, optimized = True\n",
      "topic_359 | topic_38 : 0.34, topic_363 : 0.28, topic_439 : 0.10, topic_401 : 0.06, topic_491 : 0.03\n",
      "============================\n",
      "============================\n",
      "fun = 0.749524709385, optimized = True\n",
      "topic_358 | topic_122 : 0.32, topic_117 : 0.26, topic_263 : 0.19, topic_163 : 0.05, topic_413 : 0.04\n",
      "============================\n",
      "============================\n",
      "fun = 0.754684684987, optimized = True\n",
      "topic_418 | topic_8 : 0.14, topic_241 : 0.12, topic_240 : 0.12, topic_3 : 0.09, topic_416 : 0.08\n",
      "============================\n",
      "============================\n",
      "fun = 0.749000183063, optimized = True\n",
      "topic_419 | topic_137 : 0.27, topic_381 : 0.18, topic_255 : 0.15, topic_49 : 0.11, topic_20 : 0.08\n",
      "============================\n",
      "============================\n",
      "fun = 0.727051142601, optimized = True\n",
      "topic_355 | topic_71 : 0.26, topic_78 : 0.22, topic_356 : 0.18, topic_84 : 0.13, topic_401 : 0.08\n",
      "============================\n",
      "============================\n",
      "fun = 0.721139289431, optimized = True\n",
      "topic_356 | topic_71 : 0.35, topic_355 : 0.22, topic_442 : 0.15, topic_440 : 0.12, topic_401 : 0.07\n",
      "============================\n",
      "============================\n",
      "fun = 0.742522040364, optimized = True\n",
      "topic_439 | topic_399 : 0.33, topic_346 : 0.10, topic_38 : 0.10, topic_359 : 0.09, topic_80 : 0.07\n",
      "============================\n",
      "============================\n",
      "fun = 0.750065030465, optimized = True\n",
      "topic_177 | topic_136 : 0.16, topic_498 : 0.16, topic_399 : 0.11, topic_90 : 0.11, topic_407 : 0.09\n",
      "============================\n",
      "============================\n",
      "fun = 0.754730641578, optimized = True\n",
      "topic_475 | topic_163 : 0.21, topic_184 : 0.13, topic_124 : 0.07, topic_403 : 0.06, topic_6 : 0.06\n",
      "============================\n",
      "============================\n",
      "fun = 0.719470714355, optimized = True\n",
      "topic_399 | topic_214 : 0.24, topic_439 : 0.23, topic_145 : 0.13, topic_177 : 0.09, topic_407 : 0.07\n",
      "============================\n",
      "============================\n",
      "fun = 0.736274434606, optimized = True\n",
      "topic_278 | topic_280 : 0.43, topic_95 : 0.22, topic_64 : 0.11, topic_39 : 0.05, topic_162 : 0.05\n",
      "============================\n",
      "============================\n",
      "fun = 0.750153662328, optimized = True\n",
      "topic_83 | topic_18 : 0.19, topic_456 : 0.19, topic_176 : 0.14, topic_7 : 0.11, topic_140 : 0.06\n",
      "============================\n",
      "============================\n",
      "fun = 0.744080905474, optimized = True\n",
      "topic_230 | topic_182 : 0.23, topic_429 : 0.10, topic_110 : 0.09, topic_289 : 0.09, topic_107 : 0.06\n",
      "============================\n",
      "============================\n",
      "fun = 0.735853486773, optimized = True\n",
      "topic_117 | topic_358 : 0.24, topic_39 : 0.15, topic_263 : 0.10, topic_95 : 0.10, topic_181 : 0.07\n",
      "============================\n",
      "============================\n",
      "fun = 0.754858215591, optimized = True\n",
      "topic_272 | topic_276 : 0.13, topic_383 : 0.13, topic_120 : 0.09, topic_106 : 0.08, topic_433 : 0.08\n",
      "============================\n",
      "============================\n",
      "fun = 0.759953366513, optimized = True\n",
      "topic_3 | topic_350 : 0.45, topic_219 : 0.20, topic_396 : 0.17, topic_8 : 0.14, topic_428 : 0.01\n",
      "============================\n",
      "============================\n",
      "fun = 0.740950025382, optimized = True\n",
      "topic_428 | topic_92 : 0.53, topic_3 : 0.08, topic_416 : 0.06, topic_226 : 0.06, topic_194 : 0.05\n",
      "============================\n",
      "============================\n",
      "fun = 0.730630205856, optimized = True\n",
      "topic_184 | topic_208 : 0.53, topic_475 : 0.16, topic_49 : 0.07, topic_122 : 0.07, topic_242 : 0.05\n",
      "============================\n",
      "============================\n",
      "fun = 0.72466505756, optimized = True\n",
      "topic_327 | topic_108 : 0.40, topic_448 : 0.19, topic_221 : 0.14, topic_349 : 0.13, topic_259 : 0.05\n",
      "============================\n",
      "============================\n",
      "fun = 0.707110364885, optimized = True\n",
      "topic_145 | topic_57 : 0.56, topic_399 : 0.12, topic_498 : 0.12, topic_295 : 0.08, topic_67 : 0.05\n",
      "============================\n",
      "============================\n",
      "fun = 0.758430989831, optimized = True\n",
      "topic_140 | topic_464 : 0.20, topic_471 : 0.13, topic_77 : 0.12, topic_265 : 0.12, topic_266 : 0.08\n",
      "============================\n",
      "============================\n",
      "fun = 0.746066693353, optimized = True\n",
      "topic_92 | topic_428 : 0.57, topic_348 : 0.10, topic_424 : 0.05, topic_86 : 0.03, topic_299 : 0.03\n",
      "============================\n",
      "============================\n",
      "fun = 0.73961960599, optimized = True\n",
      "topic_78 | topic_355 : 0.26, topic_66 : 0.12, topic_442 : 0.12, topic_136 : 0.12, topic_401 : 0.11\n",
      "============================\n",
      "============================\n",
      "fun = 0.752146957306, optimized = True\n",
      "topic_75 | topic_74 : 0.29, topic_124 : 0.28, topic_3 : 0.10, topic_1 : 0.06, topic_220 : 0.04\n",
      "============================\n",
      "============================\n",
      "fun = 0.733406839355, optimized = True\n",
      "topic_71 | topic_356 : 0.40, topic_355 : 0.17, topic_364 : 0.14, topic_127 : 0.06, topic_267 : 0.05\n",
      "============================\n",
      "============================\n",
      "fun = 0.754896114867, optimized = True\n",
      "topic_127 | topic_133 : 0.15, topic_210 : 0.14, topic_301 : 0.12, topic_84 : 0.10, topic_71 : 0.10\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "for key, value  in small_dist_opts.iteritems():\n",
    "    print_optimal_solution(_sol=value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.900343446224, optimized = True\n",
      "topic_30 | topic_463 : 0.14, topic_361 : 0.13, topic_487 : 0.10, topic_116 : 0.09, topic_299 : 0.08\n",
      "============================\n",
      "============================\n",
      "fun = 0.910405840239, optimized = True\n",
      "topic_307 | topic_62 : 0.22, topic_492 : 0.11, topic_293 : 0.09, topic_244 : 0.09, topic_161 : 0.08\n",
      "============================\n",
      "============================\n",
      "fun = 0.923415845239, optimized = True\n",
      "topic_309 | topic_36 : 0.50, topic_374 : 0.16, topic_67 : 0.12, topic_81 : 0.10, topic_164 : 0.05\n",
      "============================\n",
      "============================\n",
      "fun = 0.890908207754, optimized = True\n",
      "topic_388 | topic_269 : 0.23, topic_116 : 0.17, topic_347 : 0.12, topic_119 : 0.12, topic_464 : 0.06\n",
      "============================\n",
      "============================\n",
      "fun = 0.920427835428, optimized = True\n",
      "topic_391 | topic_467 : 0.37, topic_228 : 0.25, topic_400 : 0.03, topic_222 : 0.03, topic_166 : 0.03\n",
      "============================\n",
      "============================\n",
      "fun = 0.89738875009, optimized = True\n",
      "topic_60 | topic_499 : 0.21, topic_68 : 0.11, topic_380 : 0.10, topic_321 : 0.08, topic_44 : 0.07\n",
      "============================\n",
      "============================\n",
      "fun = 0.916226701177, optimized = True\n",
      "topic_243 | topic_396 : 0.13, topic_344 : 0.12, topic_282 : 0.10, topic_471 : 0.10, topic_149 : 0.09\n",
      "============================\n",
      "============================\n",
      "fun = 0.900289657723, optimized = True\n",
      "topic_410 | topic_470 : 0.53, topic_397 : 0.13, topic_230 : 0.11, topic_132 : 0.08, topic_388 : 0.05\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "for key, value  in large_dist_opts.iteritems():\n",
    "    print_optimal_solution(_sol=value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# выведем opt для некоторых из small_dist_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.752146957306, optimized = True\n",
      "topic_75 | topic_74 : 0.29 [0.84], topic_124 : 0.28 [0.85], topic_3 : 0.10 [0.90], topic_1 : 0.06 [0.90], topic_220 : 0.04 [0.91]\n",
      "closest by distance to topic_75 | topic_75 : [0.00], topic_74 : [0.84], topic_124 : [0.85], topic_1 : [0.90], topic_118 : [0.90]\n",
      "\n",
      "topic_75: диалект лексика язык словарь карта литературный_язык вариант говор диалектный_язык изучение фонетика материал русский_диалектология национальный_язык норма\n",
      "topic_74: гласный русский_язык говор слово произношение литературный_язык ударение звук австралийский_абориген мягкий_согласный древнерусский_язык носитель_русский_язык часть ять литр\n",
      "topic_124: язык лингвист английский_язык разный_язык название лингвистика носитель вопрос слово факт простой различие помощь понятие родной_язык\n",
      "topic_3: работа автор статья исследование тема монография издание труд изучение материал редактор вопрос книга коллега пора\n",
      "topic_1: глагол существительное грамматика форма русский_язык синтаксис прилагательное категория значение число правило предложение морфология слово множественный_число\n",
      "topic_220: школа учитель школьник ученик предмет егэ проблема страна урок взгляд ребята преподавание уровень опыт физика\n",
      "\n",
      "============================\n",
      "============================\n",
      "fun = 0.776779207039, optimized = True\n",
      "topic_74 | topic_75 : 0.37 [0.84], topic_118 : 0.25 [0.86], topic_116 : 0.07 [0.89], topic_395 : 0.06 [0.91], topic_124 : 0.05 [0.89]\n",
      "closest by distance to topic_74 | topic_74 : [0.00], topic_75 : [0.84], topic_118 : [0.86], topic_116 : [0.89], topic_1 : [0.89]\n",
      "\n",
      "topic_74: гласный русский_язык говор слово произношение литературный_язык ударение звук австралийский_абориген мягкий_согласный древнерусский_язык носитель_русский_язык часть ять литр\n",
      "topic_75: диалект лексика язык словарь карта литературный_язык вариант говор диалектный_язык изучение фонетика материал русский_диалектология национальный_язык норма\n",
      "topic_118: слово словарь значение русский_язык цитата значение_слово вопрос пример язык предмет место название носитель_язык тысяча смысл\n",
      "topic_116: крылов норма употребление русский_язык письмо отношение юмор берестяной_грамота слово плата эпоха доктор_филологический_наука имя явление механизм\n",
      "topic_395: упрощение фонема звук различие область артикуляция резонанс явление голосовой_связка граница дискретность гортань настоящее количество человеческий_язык\n",
      "topic_124: язык лингвист английский_язык разный_язык название лингвистика носитель вопрос слово факт простой различие помощь понятие родной_язык\n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "topic_name = u'topic_75'\n",
    "other_topic_name = u'topic_74'\n",
    "print_optimal_solution(ds[topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)\n",
    "print_optimal_solution(ds[other_topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.746066693353, optimized = True\n",
      "topic_92 | topic_428 : 0.57 [0.80], topic_348 : 0.10 [0.90], topic_424 : 0.05 [0.92], topic_86 : 0.03 [0.91], topic_299 : 0.03 [0.92]\n",
      "closest by distance to topic_92 | topic_92 : [0.00], topic_428 : [0.80], topic_226 : [0.90], topic_348 : [0.90], topic_86 : [0.91]\n",
      "\n",
      "topic_92: фильм кино зритель экран просмотр смех реплика высказывание погружение эйзенштейн участие кадр аттракцион строка голливуд\n",
      "topic_428: фильм кино кинематограф жанр режиссёр картина хоррор тема реж плохой_кино точка_зрение категория ужас зритель популярный_культура\n",
      "topic_348: речь слово ошибка высказывание средство устный_речь собеседник общение тип выражение пауза ситуация новое письменный_текст форма\n",
      "topic_424: мода восприятие знак иллюзия образ предмет воздействие одежда знание сторона постоянство опыт процесс ценность контекст\n",
      "topic_86: цирк трюк номер артист единство стадо театр целое декорация мешок сцена зритель движение оазис теснота\n",
      "topic_299: событие действие смысл случай образ основание контекст наблюдение анализ понимание вопрос иной_слово определение объяснение наблюдатель\n",
      "\n",
      "============================\n",
      "============================\n",
      "fun = 0.740950025382, optimized = True\n",
      "topic_428 | topic_92 : 0.53 [0.80], topic_3 : 0.08 [0.91], topic_416 : 0.06 [0.91], topic_226 : 0.06 [0.85], topic_194 : 0.05 [0.90]\n",
      "closest by distance to topic_428 | topic_428 : [0.00], topic_92 : [0.80], topic_226 : [0.85], topic_194 : [0.90], topic_94 : [0.90]\n",
      "\n",
      "topic_428: фильм кино кинематограф жанр режиссёр картина хоррор тема реж плохой_кино точка_зрение категория ужас зритель популярный_культура\n",
      "topic_92: фильм кино зритель экран просмотр смех реплика высказывание погружение эйзенштейн участие кадр аттракцион строка голливуд\n",
      "topic_3: работа автор статья исследование тема монография издание труд изучение материал редактор вопрос книга коллега пора\n",
      "topic_416: точка_зрение формат мнение эксперт вопрос проблема роль мнение_эксперт_постнаука актуальный_проблема_общество пример средство интерес задача сожаление результат\n",
      "topic_226: массовый_культура зомби сериал критический_теория тема современный_культура проблема культуролог живой_мертвец образ популярность кино исследование идея фильм\n",
      "topic_194: песнь песня жанр былина эпос порнография фольклор бытование правило вид носитель образ эротика устный_текст старина\n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "topic_name = u'topic_92'\n",
    "other_topic_name = u'topic_428'\n",
    "print_optimal_solution(ds[topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)\n",
    "print_optimal_solution(ds[other_topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.736274434606, optimized = True\n",
      "topic_278 | topic_280 : 0.43 [0.81], topic_95 : 0.22 [0.85], topic_64 : 0.11 [0.88], topic_39 : 0.05 [0.90], topic_162 : 0.05 [0.87]\n",
      "closest by distance to topic_278 | topic_278 : [0.00], topic_280 : [0.81], topic_95 : [0.85], topic_133 : [0.86], topic_162 : [0.87]\n",
      "\n",
      "topic_278: белка белок клетка приона цитоплазма домен шаперон агрегат состояние фибрилла дрожжи эукариот структура образ транскрипция\n",
      "topic_280: молекула белок белка аминокислота нуклеотид секвенирование длина процесс нуклеиновый_кислота друг липид рид результат пептид группа\n",
      "topic_95: клетка ткань работа токсин живой_система химический_вещество открытие тип_клетка концентрация функционирование лимфоцит тип зависимость частность живой_клетка\n",
      "topic_64: структура полимер процесс синтез смесь эксперимент задача гидродинамика расчёт область простой динамика структура_белок образ простейшее\n",
      "topic_39: днк молекула_днк генетический_информация крик уотсон двойной_спираль последовательность структура_днк форма последовательность_днк цепочка конец стела хор открытие\n",
      "topic_162: сложный_система чашка помощь зрение реакция образ процесс друг каскад пиксель биологический_система мишень биофизик аптека химический_синтез\n",
      "\n",
      "============================\n",
      "============================\n",
      "fun = 0.766081324544, optimized = True\n",
      "topic_280 | topic_278 : 0.57 [0.81], topic_117 : 0.14 [0.88], topic_301 : 0.13 [0.87], topic_39 : 0.04 [0.91], topic_64 : 0.04 [0.91]\n",
      "closest by distance to topic_280 | topic_280 : [0.00], topic_278 : [0.81], topic_301 : [0.87], topic_133 : [0.88], topic_117 : [0.88]\n",
      "\n",
      "topic_280: молекула белок белка аминокислота нуклеотид секвенирование длина процесс нуклеиновый_кислота друг липид рид результат пептид группа\n",
      "topic_278: белка белок клетка приона цитоплазма домен шаперон агрегат состояние фибрилла дрожжи эукариот структура образ транскрипция\n",
      "topic_117: геном днк участок ген последовательность изменение болезнь клетка подход опечатка помощь образ половый_клетка мутация клон\n",
      "topic_301: химия соединение реакция химик аббревиатура молекула органический_химия синтез катализатор процесс химический_реакция природа связь катализ получение\n",
      "topic_39: днк молекула_днк генетический_информация крик уотсон двойной_спираль последовательность структура_днк форма последовательность_днк цепочка конец стела хор открытие\n",
      "topic_64: структура полимер процесс синтез смесь эксперимент задача гидродинамика расчёт область простой динамика структура_белок образ простейшее\n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "topic_name = u'topic_278'\n",
    "other_topic_name = u'topic_280'\n",
    "print_optimal_solution(ds[topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)\n",
    "print_optimal_solution(ds[other_topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.900289657723, optimized = True\n",
      "topic_410 | topic_470 : 0.53 [0.92], topic_397 : 0.13 [0.95], topic_230 : 0.11 [0.95], topic_132 : 0.08 [0.96], topic_388 : 0.05 [0.96]\n",
      "closest by distance to topic_410 | topic_410 : [0.00], topic_470 : [0.92], topic_317 : [0.95], topic_397 : [0.95], topic_230 : [0.95]\n",
      "\n",
      "topic_410: перспектива будущее научный_сообщество новый_программа дисциплина специфика место профессия ивар_максут освещение проблема постнаука рекомбинация пресс изучение\n",
      "topic_470: учёный постнаука открытие материал исследование фундаментальный_наука идея специалист работа вопрос новое передача способ будущее участие\n",
      "topic_397: преподаватель преподавание дисциплина студент курс принцип ректор гумбольдт работа обществознание обучение рамка выбор задача цель\n",
      "topic_230: страна китай сша индия инвестиция ввп отношение развитие япония торговля экономический_развитие фактор ес азия темп_рост\n",
      "topic_132: англия тысячелетие монт древность период стен археология айсберг важный_роль долина земледелие вождь место общество землевладелец\n",
      "topic_388: обмен платформа рефлексия норма креативность проблема система_ценность место друг принципиальный_отличие попытка отношение социальный_структура взгляд огромный_интерес\n",
      "\n",
      "============================\n",
      "============================\n",
      "fun = 0.853395674722, optimized = True\n",
      "topic_470 | topic_120 : 0.27 [0.90], topic_3 : 0.25 [0.91], topic_410 : 0.13 [0.92], topic_435 : 0.08 [0.94], topic_491 : 0.06 [0.94]\n",
      "closest by distance to topic_470 | topic_470 : [0.00], topic_120 : [0.90], topic_3 : [0.91], topic_335 : [0.91], topic_410 : [0.92]\n",
      "\n",
      "topic_470: учёный постнаука открытие материал исследование фундаментальный_наука идея специалист работа вопрос новое передача способ будущее участие\n",
      "topic_120: наука знание вопрос дисциплина научный_знание физик область учёный факт современный_наука развитие_наука клик сожаление возможность естествознание\n",
      "topic_3: работа автор статья исследование тема монография издание труд изучение материал редактор вопрос книга коллега пора\n",
      "topic_410: перспектива будущее научный_сообщество новый_программа дисциплина специфика место профессия ивар_максут освещение проблема постнаука рекомбинация пресс изучение\n",
      "topic_435: изобретение инновация технология телефон компания изобретатель индустрия сфера белла отрасль бизнес новое разработка открытие продукт\n",
      "topic_491: спектр материал задача структура свойство новый_материал кристаллический_структура спектроскопия помощь сплав молекула новое_материал результат друг решение\n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "topic_name = u'topic_410'\n",
    "other_topic_name = u'topic_470'\n",
    "print_optimal_solution(ds[topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)\n",
    "print_optimal_solution(ds[other_topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.754684684987, optimized = True\n",
      "topic_418 | topic_8 : 0.14 [0.87], topic_241 : 0.12 [0.86], topic_240 : 0.12 [0.88], topic_3 : 0.09 [0.89], topic_416 : 0.08 [0.87]\n",
      "closest by distance to topic_418 | topic_418 : [0.00], topic_241 : [0.86], topic_8 : [0.87], topic_416 : [0.87], topic_313 : [0.87]\n",
      "\n",
      "topic_418: диссертация аспирант работа степень совет задача проблема аспирантура ситуация список академический_сообщество защита вак написание критерий\n",
      "topic_8: журнал публикация статья новость принцип знакомство любитель научный_журнал издательство профессионал результат тысяча ресурс открытый_доступ база\n",
      "topic_241: задача мышление психолог решение инсайт проблема решение_задача этап психология исследование процесс группа момент цель психология_мышление\n",
      "topic_240: решение принятие_решение ситуация выбор проблема правило общество большинство аукцион механизм риска полезность пример компания неопределённость\n",
      "topic_3: работа автор статья исследование тема монография издание труд изучение материал редактор вопрос книга коллега пора\n",
      "topic_416: точка_зрение формат мнение эксперт вопрос проблема роль мнение_эксперт_постнаука актуальный_проблема_общество пример средство интерес задача сожаление результат\n",
      "\n",
      "============================\n",
      "============================\n",
      "fun = 0.818580390386, optimized = True\n",
      "topic_8 | topic_3 : 0.31 [0.88], topic_418 : 0.26 [0.87], topic_483 : 0.09 [0.91], topic_68 : 0.09 [0.92], topic_146 : 0.06 [0.93]\n",
      "closest by distance to topic_8 | topic_8 : [0.00], topic_418 : [0.87], topic_3 : [0.88], topic_483 : [0.91], topic_313 : [0.91]\n",
      "\n",
      "topic_8: журнал публикация статья новость принцип знакомство любитель научный_журнал издательство профессионал результат тысяча ресурс открытый_доступ база\n",
      "topic_3: работа автор статья исследование тема монография издание труд изучение материал редактор вопрос книга коллега пора\n",
      "topic_418: диссертация аспирант работа степень совет задача проблема аспирантура ситуация список академический_сообщество защита вак написание критерий\n",
      "topic_483: рукопись рецензент редакция рука автор лондон консенсус ресурс рецензирование распределение имя препринт журнал случай редактор\n",
      "topic_68: пользователь узел социальный_сеть сообщение сеть связь исследователь интернет друг страница эго анализ блог отношение количество\n",
      "topic_146: информация область вопрос сторона статистика образ зрительный_система когнитивный_наука круг оценка основа факт коллега число важный_информация\n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "topic_name = u'topic_418'\n",
    "other_topic_name = u'topic_8'\n",
    "print_optimal_solution(ds[topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)\n",
    "print_optimal_solution(ds[other_topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# по топ словам действительно похожи темы, причём иногда симметрично есть, а иногда нет\n",
    "# те, что через сильные коэфициенты больше похожи?\n",
    "# проверить те, что практически симметричны \n",
    "# выведем opt для некоторых из small_dist_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.923415845239, optimized = True\n",
      "topic_309 | topic_36 : 0.50 [0.94], topic_374 : 0.16 [0.97], topic_67 : 0.12 [0.96], topic_81 : 0.10 [0.96], topic_164 : 0.05 [0.94]\n",
      "closest by distance to topic_309 | topic_309 : [0.00], topic_164 : [0.94], topic_36 : [0.94], topic_418 : [0.95], topic_323 : [0.95]\n",
      "\n",
      "topic_309: система образ новое смысл пора взгляд конец задача общий_теория социальный_система лумана парсонс вычислительный_метод движение работа\n",
      "topic_36: компьютер задача алгоритм процессор область вычисление машина ошибка программный_обеспечение суперкомпьютер секвенатор решение компьютерный_наука скорость специалист\n",
      "topic_374: смысл гуманитарный_наука подход критик перестройка идея поворот энциклопедия сфера работа оттепель новое термин традиционализм гуманитарный_дисциплина\n",
      "topic_67: теория гипотеза образ факт математический_модель помощь объяснение результат вопрос принцип механизм построение распространение подход проверка\n",
      "topic_81: движение ньютон кеплер течение окружность коперник кембридж уравнение движение_планета мах момент кривая инерция эллипс галиля\n",
      "topic_164: программа программист компилятор программирование понятие создание язык_программирование задача проектирование процесс компонент сторона сфера оперативный_память работа\n",
      "\n",
      "============================\n",
      "============================\n",
      "fun = 0.788396736373, optimized = True\n",
      "topic_36 | topic_241 : 0.39 [0.85], topic_164 : 0.11 [0.86], topic_277 : 0.10 [0.88], topic_166 : 0.09 [0.88], topic_271 : 0.07 [0.89]\n",
      "closest by distance to topic_36 | topic_36 : [0.00], topic_241 : [0.85], topic_164 : [0.86], topic_277 : [0.88], topic_166 : [0.88]\n",
      "\n",
      "topic_36: компьютер задача алгоритм процессор область вычисление машина ошибка программный_обеспечение суперкомпьютер секвенатор решение компьютерный_наука скорость специалист\n",
      "topic_241: задача мышление психолог решение инсайт проблема решение_задача этап психология исследование процесс группа момент цель психология_мышление\n",
      "topic_164: программа программист компилятор программирование понятие создание язык_программирование задача проектирование процесс компонент сторона сфера оперативный_память работа\n",
      "topic_277: робот робототехника машина паук задача инженер работа исследование создание способность цель специалист возможность развитие взаимодействие\n",
      "topic_166: код процесс_эволюция копирование искусственный_жизнь вид компьютер организм жизнь счёт вопрос оперативный_память паразит существо хозяин эволюционный_развитие\n",
      "topic_271: биолог биоинформатика биология сторона сигнальный_путь уровень белка анализ приложение работа_ген взаимодействие системный_биология предсказание операционный_система молекулярный_биология\n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "topic_name = u'topic_309'\n",
    "other_topic_name = u'topic_36'\n",
    "print_optimal_solution(ds[topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)\n",
    "print_optimal_solution(ds[other_topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.916226701177, optimized = True\n",
      "topic_243 | topic_396 : 0.13 [0.95], topic_344 : 0.12 [0.94], topic_282 : 0.10 [0.95], topic_471 : 0.10 [0.95], topic_149 : 0.09 [0.96]\n",
      "closest by distance to topic_243 | topic_243 : [0.00], topic_75 : [0.94], topic_344 : [0.94], topic_172 : [0.95], topic_272 : [0.95]\n",
      "\n",
      "topic_243: метр литр плата факт основа число рамка астрель аста проблема форма нелинейность имя пресс лифшиц\n",
      "topic_396: раздел глава область изложение специалист вопрос актуальность предмет разный_область введение сфера монография обзор изучение книга\n",
      "topic_344: концепция этнос этнограф этнография дискуссия народ общность предшественник понятие нация отношение этничность влияние новое идея\n",
      "topic_282: обряд посещение гость свадьба достопримечательность невеста место обычай машина среднее_возраст свадебный_обряд природный_объект похороны мотоцикл закон_мура\n",
      "topic_471: насилие индивид критика вебер легитимность отношение общество макс_вебер актор характер социальный_реальность форма власть господство род\n",
      "topic_149: вывод аргумент генетик суждение посылка факт собиратель вероятность заключение вопрос лебедь большинство концепция разный_регион житель\n",
      "\n",
      "============================\n",
      "============================\n",
      "fun = 0.80260105175, optimized = True\n",
      "topic_396 | topic_3 : 0.28 [0.86], topic_73 : 0.14 [0.88], topic_350 : 0.10 [0.91], topic_258 : 0.08 [0.92], topic_434 : 0.06 [0.90]\n",
      "closest by distance to topic_396 | topic_396 : [0.00], topic_3 : [0.86], topic_73 : [0.88], topic_434 : [0.90], topic_272 : [0.90]\n",
      "\n",
      "topic_396: раздел глава область изложение специалист вопрос актуальность предмет разный_область введение сфера монография обзор изучение книга\n",
      "topic_3: работа автор статья исследование тема монография издание труд изучение материал редактор вопрос книга коллега пора\n",
      "topic_73: издательство книга популярный_книга русский_язык несправедливость обложка криптография извинение концепция фикшн курс_лекция альпина_нона вопрос популярный_литература репарация\n",
      "topic_350: книга читатель автор взгляд литература серия идея автор_книга жизнь страница издание тема автограф великое анализ\n",
      "topic_258: разработка область применение использование создание технология материал микросхема дисплей помощь медицина производство будущее электрод нанометр\n",
      "topic_434: уровень научный_школа умберто_эко эко труд коллега связь учреждение ступень научный_руководитель пособие высокий_уровень организация окончание термин\n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "topic_name = u'topic_243'\n",
    "other_topic_name = u'topic_396'\n",
    "print_optimal_solution(ds[topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)\n",
    "print_optimal_solution(ds[other_topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.900289657723, optimized = True\n",
      "topic_410 | topic_470 : 0.53 [0.92], topic_397 : 0.13 [0.95], topic_230 : 0.11 [0.95], topic_132 : 0.08 [0.96], topic_388 : 0.05 [0.96]\n",
      "closest by distance to topic_410 | topic_410 : [0.00], topic_470 : [0.92], topic_317 : [0.95], topic_397 : [0.95], topic_230 : [0.95]\n",
      "\n",
      "topic_410: перспектива будущее научный_сообщество новый_программа дисциплина специфика место профессия ивар_максут освещение проблема постнаука рекомбинация пресс изучение\n",
      "topic_470: учёный постнаука открытие материал исследование фундаментальный_наука идея специалист работа вопрос новое передача способ будущее участие\n",
      "topic_397: преподаватель преподавание дисциплина студент курс принцип ректор гумбольдт работа обществознание обучение рамка выбор задача цель\n",
      "topic_230: страна китай сша индия инвестиция ввп отношение развитие япония торговля экономический_развитие фактор ес азия темп_рост\n",
      "topic_132: англия тысячелетие монт древность период стен археология айсберг важный_роль долина земледелие вождь место общество землевладелец\n",
      "topic_388: обмен платформа рефлексия норма креативность проблема система_ценность место друг принципиальный_отличие попытка отношение социальный_структура взгляд огромный_интерес\n",
      "\n",
      "============================\n",
      "============================\n",
      "fun = 0.853395674722, optimized = True\n",
      "topic_470 | topic_120 : 0.27 [0.90], topic_3 : 0.25 [0.91], topic_410 : 0.13 [0.92], topic_435 : 0.08 [0.94], topic_491 : 0.06 [0.94]\n",
      "closest by distance to topic_470 | topic_470 : [0.00], topic_120 : [0.90], topic_3 : [0.91], topic_335 : [0.91], topic_410 : [0.92]\n",
      "\n",
      "topic_470: учёный постнаука открытие материал исследование фундаментальный_наука идея специалист работа вопрос новое передача способ будущее участие\n",
      "topic_120: наука знание вопрос дисциплина научный_знание физик область учёный факт современный_наука развитие_наука клик сожаление возможность естествознание\n",
      "topic_3: работа автор статья исследование тема монография издание труд изучение материал редактор вопрос книга коллега пора\n",
      "topic_410: перспектива будущее научный_сообщество новый_программа дисциплина специфика место профессия ивар_максут освещение проблема постнаука рекомбинация пресс изучение\n",
      "topic_435: изобретение инновация технология телефон компания изобретатель индустрия сфера белла отрасль бизнес новое разработка открытие продукт\n",
      "topic_491: спектр материал задача структура свойство новый_материал кристаллический_структура спектроскопия помощь сплав молекула новое_материал результат друг решение\n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "topic_name = u'topic_410'\n",
    "other_topic_name = u'topic_470'\n",
    "print_optimal_solution(ds[topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)\n",
    "print_optimal_solution(ds[other_topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# вроде даже если opt высокий, всё равно темы вроде похожи\n",
    "# и там и там первые - ближайшие по расстоянию, логично"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "fun = 0.746066693353, optimized = True\n",
      "topic_92 | topic_428 : 0.57 [0.80], topic_348 : 0.10 [0.90], topic_424 : 0.05 [0.92], topic_86 : 0.03 [0.91], topic_299 : 0.03 [0.92]\n",
      "closest by distance to topic_92 | topic_92 : [0.00], topic_428 : [0.80], topic_226 : [0.90], topic_348 : [0.90], topic_86 : [0.91]\n",
      "\n",
      "topic_92: фильм кино зритель экран просмотр смех реплика высказывание погружение эйзенштейн участие кадр аттракцион строка голливуд\n",
      "topic_428: фильм кино кинематограф жанр режиссёр картина хоррор тема реж плохой_кино точка_зрение категория ужас зритель популярный_культура\n",
      "topic_348: речь слово ошибка высказывание средство устный_речь собеседник общение тип выражение пауза ситуация новое письменный_текст форма\n",
      "topic_424: мода восприятие знак иллюзия образ предмет воздействие одежда знание сторона постоянство опыт процесс ценность контекст\n",
      "topic_86: цирк трюк номер артист единство стадо театр целое декорация мешок сцена зритель движение оазис теснота\n",
      "topic_299: событие действие смысл случай образ основание контекст наблюдение анализ понимание вопрос иной_слово определение объяснение наблюдатель\n",
      "\n",
      "============================\n",
      "============================\n",
      "fun = 0.740950025382, optimized = True\n",
      "topic_428 | topic_92 : 0.53 [0.80], topic_3 : 0.08 [0.91], topic_416 : 0.06 [0.91], topic_226 : 0.06 [0.85], topic_194 : 0.05 [0.90]\n",
      "closest by distance to topic_428 | topic_428 : [0.00], topic_92 : [0.80], topic_226 : [0.85], topic_194 : [0.90], topic_94 : [0.90]\n",
      "\n",
      "topic_428: фильм кино кинематограф жанр режиссёр картина хоррор тема реж плохой_кино точка_зрение категория ужас зритель популярный_культура\n",
      "topic_92: фильм кино зритель экран просмотр смех реплика высказывание погружение эйзенштейн участие кадр аттракцион строка голливуд\n",
      "topic_3: работа автор статья исследование тема монография издание труд изучение материал редактор вопрос книга коллега пора\n",
      "topic_416: точка_зрение формат мнение эксперт вопрос проблема роль мнение_эксперт_постнаука актуальный_проблема_общество пример средство интерес задача сожаление результат\n",
      "topic_226: массовый_культура зомби сериал критический_теория тема современный_культура проблема культуролог живой_мертвец образ популярность кино исследование идея фильм\n",
      "topic_194: песнь песня жанр былина эпос порнография фольклор бытование правило вид носитель образ эротика устный_текст старина\n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "# посмотрим на <<симметричные>>\n",
    "topic_name = u'topic_92'\n",
    "other_topic_name = u'topic_428'\n",
    "print_optimal_solution(ds[topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)\n",
    "print_optimal_solution(ds[other_topic_name], _distances=distances, _saved_top_tokens=saved_top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "автор 0.0 0.0077551\n",
      "красота 0.0 0.00116458\n",
      "дорога 0.000428391 3.31266e-05\n",
      "проблема 0.0 0.00524335\n",
      "вопрос 0.00409053 0.00319101\n",
      "дмитрия 0.000433505 0.0\n",
      "америка 0.00236797 0.0\n",
      "журнал 0.00200578 0.00110529\n",
      "конец 0.00438831 0.00303694\n",
      "работа 0.0021662 0.000773385\n",
      "момент 0.0 0.00358029\n",
      "пора 0.0 0.00316419\n",
      "сюжет 0.0 0.00485475\n",
      "новый_форма 1.76624e-05 0.000321171\n",
      "термин 0.00238779 0.0041048\n",
      "исследовательский_программа 4.70327e-05 0.0\n",
      "традиция 0.0 0.00014228\n",
      "очередь 0.00108994 0.0\n",
      "часть 0.0 0.00405267\n",
      "лето 0.0 0.0001383\n",
      "название 0.0 0.00159147\n",
      "участник 0.003645 0.0\n",
      "дом 0.000861592 0.0\n",
      "творчество 0.0 0.00197238\n",
      "дата 0.00144042 0.0\n",
      "издание 0.000509953 0.0\n",
      "товар 0.000341337 0.0\n",
      "случай 0.0 0.00155534\n",
      "общество 0.0 0.00206616\n",
      "автор_книга 0.0 0.000632442\n",
      "третье 0.0 0.000574692\n",
      "половина 0.0 0.000100579\n",
      "принцип 0.0 0.00301114\n",
      "явление 0.0 0.00509165\n",
      "порядок 0.000697966 0.0\n",
      "тема 0.0 0.0162911\n",
      "литература 0.0 0.000808911\n",
      "число 0.000478861 0.00214819\n",
      "сторона 0.0 0.00423341\n",
      "ответ 0.00106641 0.0\n",
      "описание 0.00055194 0.0\n",
      "кривая 0.000472495 0.0\n",
      "направление 0.00119699 0.0\n",
      "тело 0.0 0.00411383\n",
      "положение 0.0 0.000614265\n",
      "вариант 0.000479312 0.00095496\n",
      "аннотация 0.0 0.000390473\n",
      "большинство 0.0 0.000581949\n",
      "музыка 0.00082286 0.0\n",
      "развитие 0.0 0.000724224\n",
      "хороший_вкус 0.0 0.00799703\n",
      "вкус 0.0 0.0072125\n",
      "молодая 0.0 0.000268406\n",
      "понятие 0.0 0.00296704\n",
      "отношение 0.00382149 0.00537767\n",
      "идея 0.0 0.00147852\n",
      "простой 0.000936573 0.0\n",
      "имя 0.0 0.00135056\n",
      "слово 0.00268457 0.0\n",
      "плата 0.0 0.000416737\n",
      "строка 0.00776079 0.0\n",
      "список 0.0 0.00194991\n",
      "пример 0.000516543 0.00384331\n",
      "карта 0.0 0.000132611\n",
      "ося 0.0015361 0.0\n",
      "форма 0.00446629 0.0\n",
      "заключение 0.0 4.1581e-05\n",
      "состояние 0.00366002 0.0\n",
      "период 0.000714523 0.0\n",
      "искусство 0.0 0.00049658\n",
      "впечатление 0.000499873 0.0\n",
      "мёртвый 0.0 0.000585726\n",
      "достижение 0.000206247 0.0\n",
      "статья 0.00183109 0.0\n",
      "разный_уровень 0.000337515 0.0\n",
      "улица 0.0 0.000451304\n",
      "целое 0.000929516 0.00321028\n",
      "помощь 0.00186818 0.000640841\n",
      "трансформация 0.0 0.000369114\n",
      "санкт 0.0 0.000664101\n",
      "петербург 0.0 0.000583534\n",
      "влияние 0.0 0.00067439\n",
      "инструмент 0.0 0.00123225\n",
      "изучение 0.0010672 0.00138153\n",
      "анализ 9.24248e-05 0.000101361\n",
      "дискурс 0.0 0.000510226\n",
      "исследование 0.0 0.000815917\n",
      "иерархия 0.000478203 0.0\n",
      "разный_тип 0.000841155 0.0\n",
      "фокус 0.00056755 0.0\n",
      "основа 2.61633e-05 2.77317e-05\n",
      "текст 0.0 0.000494576\n",
      "представление 0.00149529 0.00245472\n",
      "практик 0.000539955 0.0\n",
      "контекст 0.0054494 0.0\n",
      "признание 0.0 0.000535717\n",
      "дискуссия 0.000347946 0.0\n",
      "газета 0.000608599 0.0\n",
      "женщина 6.8246e-06 0.0\n",
      "совокупность 0.000640537 0.0\n",
      "тезис 0.0 0.000654412\n",
      "теория 0.0 0.00206382\n",
      "обстоятельство 0.0 0.000421343\n",
      "вовлеченность 0.00405845 0.0\n",
      "критика 0.000383282 0.00596429\n",
      "муж 0.00353946 0.0\n",
      "мотив 0.0 0.000353752\n",
      "мнение 0.0 0.00172975\n",
      "исследователь 0.00116563 0.00516427\n",
      "насилие 0.0 0.00392687\n",
      "мальчик 0.0 0.0012988\n",
      "воздействие 0.00551671 0.0\n",
      "старший 0.00047595 0.0\n",
      "отец 0.0 0.00106693\n",
      "причина 0.00133172 0.000263498\n",
      "факт 0.0 0.000576684\n",
      "недостаток 0.0 0.000227677\n",
      "изменение 0.00325354 0.0\n",
      "место 0.000848948 0.000817135\n",
      "правило 0.0 0.000721885\n",
      "режим 0.00058583 0.0\n",
      "реальность 0.00453185 0.0\n",
      "герой 0.000524229 0.00360695\n",
      "образ 0.00202676 0.000999935\n",
      "советский_кинематограф 0.00485988 0.0\n",
      "черта 0.0 0.00060357\n",
      "ориентация 0.0 0.000400025\n",
      "путь 0.000142631 8.36378e-05\n",
      "жизнь 0.0 0.00210502\n",
      "смысл 0.0 0.00666849\n",
      "способность 0.000333503 0.0\n",
      "сочетание 0.000322266 0.0\n",
      "тип 0.00245435 0.00209887\n",
      "функция 0.000379641 0.0\n",
      "героизм 0.000375553 0.0\n",
      "создание 0.000970891 0.0\n",
      "будущее 0.0 0.000378035\n",
      "идеология 0.0 0.00152785\n",
      "попытка 0.0 3.07447e-05\n",
      "ряд 0.00406015 0.0\n",
      "подруга 0.0 0.000306034\n",
      "встреча 0.00116352 0.0\n",
      "рамка 0.0 0.00214002\n",
      "действительность 0.0 0.000453594\n",
      "девушка 0.000429573 0.0\n",
      "версия 0.000657036 0.000237195\n",
      "фигура 0.0 0.00271732\n",
      "философ 0.0 9.82044e-06\n",
      "популярность 0.0 5.50481e-05\n",
      "действие 0.00449858 0.0\n",
      "структура 0.00235792 1.68092e-05\n",
      "метр 9.02096e-05 0.0\n",
      "статус 0.0 0.00342634\n",
      "символ 0.0 0.00159168\n",
      "интерес 0.0 0.000946298\n",
      "соответствие 0.000213111 0.00114239\n",
      "позиция 0.00336699 0.00219582\n",
      "поведение 0.00143078 0.0\n",
      "интеллектуал 0.0 0.00236354\n",
      "суждение 0.0 0.00478506\n",
      "дихотомия 0.0 0.000263348\n",
      "выражение 0.000863694 0.0\n",
      "сфера 0.0 0.00228185\n",
      "признак 0.00625354 0.0\n",
      "жена 0.00267942 3.7752e-05\n",
      "норма 0.0 0.000332168\n",
      "образец 0.0 0.00111064\n",
      "носитель 0.0 0.0026534\n",
      "произведение 0.00216284 0.000652066\n",
      "кинематограф 0.00677246 0.0447701\n",
      "приключение 0.0 0.000602689\n",
      "опасность 0.0 0.000311654\n",
      "сила 0.00080365 0.00101641\n",
      "вестерн 0.0 0.000765322\n",
      "элемент 0.00107381 0.0\n",
      "качество 0.00655215 0.0\n",
      "множество 0.000764666 0.0\n",
      "существо 0.0 0.000545581\n",
      "условие 0.00126926 8.29062e-05\n",
      "молодёжь 0.0 0.00024126\n",
      "отсутствие 0.0044883 0.00120955\n",
      "зависимость 0.00101991 0.0\n",
      "россия 0.0 0.000357156\n",
      "возможность 0.00667349 0.0002473\n",
      "переход 0.00183521 0.0\n",
      "количество 0.00250222 0.0\n",
      "производитель 0.000533554 0.000488105\n",
      "предпочтение 0.0 0.000492634\n",
      "конец_конец 0.0 0.000826091\n",
      "стол 0.000178902 0.0\n",
      "выход 0.00159517 0.0\n",
      "производство 0.00044855 0.0\n",
      "содержание 0.00128394 0.00170549\n",
      "учёный 0.0 7.93327e-05\n",
      "оценка 0.00426623 0.0\n",
      "приход 0.000708098 0.0\n",
      "цивилизация 0.0 0.000987156\n",
      "реж 0.000517232 0.0117972\n",
      "эффект 0.000194733 0.0\n",
      "потребление 0.00102342 0.0\n",
      "восстановление 0.000863312 0.0\n",
      "польза 0.0 0.000164001\n",
      "уровень 0.0 0.00163825\n",
      "необходимость 0.0 0.000615665\n",
      "деталь 0.00234414 0.0\n",
      "наличие 0.00345592 0.0\n",
      "предубеждение 0.0 0.000464822\n",
      "формула 0.0 0.00156917\n",
      "общественность 0.0 0.000627465\n",
      "применение 0.000761957 0.0\n",
      "эксперимент 0.00133902 0.0\n",
      "воспроизводство 0.0 0.000274493\n",
      "значимость 0.000703932 0.000240519\n",
      "частность 0.000359285 0.00452304\n",
      "ход 0.000532221 0.0\n",
      "появление 0.00164299 0.00105678\n",
      "счёт 0.000802988 0.00206627\n",
      "потребность 0.00025311 0.0\n",
      "группа 0.00072943 0.0\n",
      "история 0.0 0.000733981\n",
      "различие 7.05641e-06 0.0\n",
      "подход 0.0 0.00168906\n",
      "определение 0.000449081 0.00209984\n",
      "концепция 0.000771432 0.0\n",
      "огонь 0.000675177 0.0\n",
      "линия 0.00337988 0.0\n",
      "категория 0.0 0.00875766\n",
      "род 0.0 0.000136398\n",
      "точка_зрение 0.00142069 0.00925011\n",
      "течение 0.000618147 0.0\n",
      "новое 0.0023695 0.00162571\n",
      "звено 0.0 0.000214507\n",
      "глаз 0.0 5.13344e-05\n",
      "лицо 0.0 0.000163191\n",
      "чаща 0.00110199 0.004522\n",
      "значение 0.00320456 0.0\n",
      "степень 0.00099134 0.0\n",
      "выделение 0.000306637 0.0\n",
      "стивен 0.0 0.00161593\n",
      "сложение 0.000528733 0.0\n",
      "огромный_территория 0.000413453 0.0\n",
      "голова 0.00289696 0.0\n",
      "становление 0.0 0.000224473\n",
      "специалист 0.0 6.66679e-05\n",
      "область 0.0 0.000566865\n",
      "новое_литературный_обозрение 0.000409015 0.0\n",
      "классика 0.0 0.00134811\n",
      "свет 0.00102559 0.0\n",
      "масса 0.000400754 0.000121489\n",
      "разный_форма 0.00102974 0.0\n",
      "область_знание 0.000415833 0.0\n",
      "ситуация 0.00438601 0.0\n",
      "возникновение 0.0 0.000509272\n",
      "процедура 0.00155487 0.0\n",
      "обращение 0.00180524 0.00032638\n",
      "люба 0.0 0.000876431\n",
      "изобретатель 0.000820597 0.0\n",
      "современный_культура 0.0 0.000397057\n",
      "метод 9.50155e-05 0.0\n",
      "тенденция 0.0 0.00158164\n",
      "характер 0.0 0.00080408\n",
      "авторитет 0.0 0.000882733\n",
      "психоаналитик 0.0 7.41167e-05\n",
      "первое 0.0038851 0.0\n",
      "марксизм 0.0 0.00143742\n",
      "последователь 0.0 1.26079e-05\n",
      "жест 0.000562294 0.0\n",
      "публика 0.00476589 3.34478e-05\n",
      "первоисточник 0.0 0.000286097\n",
      "антология 0.0 0.00139941\n",
      "обучение 0.0 0.000165192\n",
      "заметка 0.0 0.00125015\n",
      "мысль 0.000191569 0.0\n",
      "прочтение 0.0 0.00270555\n",
      "теоретик 0.00160141 0.0\n",
      "мыслитель 0.0 0.000611471\n",
      "существование 0.000908205 0.0\n",
      "эпизод 0.00361032 0.00282904\n",
      "парадоксальный_образ 0.0 0.000787911\n",
      "приём 0.00511302 0.0\n",
      "стратегия 0.000836324 0.00160795\n",
      "наблюдение 0.00654535 0.0\n",
      "особенность 0.00427997 0.0\n",
      "искусствовед 0.000604739 0.0\n",
      "эпоха 0.0 0.000416965\n",
      "заслуга 0.0 0.000541869\n",
      "коллега 0.000362201 0.0\n",
      "разница 0.000566704 0.0\n",
      "лексика 0.000890686 0.0\n",
      "имя_собственный 0.00046295 0.0\n",
      "приближение 0.000455522 0.0\n",
      "наименование 0.0 0.0005606\n",
      "кома 0.00234871 0.0\n",
      "мишель_фуко 0.0 0.000251138\n",
      "рефлексия 0.000996861 0.0\n",
      "построение 0.00135711 0.0\n",
      "повод 0.000134859 0.0\n",
      "цензура 0.00100788 0.0\n",
      "план 0.00181242 0.0\n",
      "восприятие 0.00269313 0.00194712\n",
      "мистика 0.0 0.000611063\n",
      "истина 0.0 5.40302e-05\n",
      "машина 0.0049545 0.0\n",
      "пьер 0.0 0.000332916\n",
      "отличие 0.00120877 0.00274234\n",
      "поворот 0.0 0.000592823\n",
      "яркий_пример 0.0 0.00229348\n",
      "друг_друг 0.000465163 0.0\n",
      "сожаление 0.0 0.000995584\n",
      "взгляд 0.0 0.00283452\n",
      "деятельность 0.0 0.000261109\n",
      "анекдот 0.0 0.000228405\n",
      "сущность 0.000925773 6.27717e-05\n",
      "граница 0.0 0.000747922\n",
      "частное 0.0 0.000512292\n",
      "ассоциация 0.0060721 0.0\n",
      "компания 0.000245349 0.0\n",
      "гибкость 0.000455177 0.0\n",
      "кольцо 0.000557259 0.0\n",
      "единица 0.000676503 0.0\n",
      "распространение 0.0 8.56688e-05\n",
      "возмущение 0.000832456 0.0\n",
      "кресло 0.00124061 0.0\n",
      "реакция 0.00670623 0.0\n",
      "метка 0.000541103 0.0\n",
      "выпуск 0.000317488 0.0\n",
      "продолжение 0.0 0.000969895\n",
      "фаза 0.000453483 0.0\n",
      "ключ 0.0 0.000105661\n",
      "речь 0.00177773 0.0\n",
      "компьютер 0.000138137 0.0\n",
      "спрос 0.0 0.00116322\n",
      "новое_поколение 0.00036091 0.0\n",
      "характеристика 0.00304231 0.0\n",
      "присутствие 0.000403669 0.0\n",
      "стандарт 0.0 0.000328543\n",
      "пространство 0.00134758 0.0\n",
      "феномен 0.0 2.54022e-05\n",
      "йорк 0.0 0.000531732\n",
      "ресторан 0.0 7.05185e-05\n",
      "кино 0.0604525 0.0490338\n",
      "туризм 0.000376288 0.0\n",
      "гарри 0.0 0.000768559\n",
      "полотно 0.0 0.000512709\n",
      "помещение 0.0 0.00031923\n",
      "картина 0.0 0.0220532\n",
      "бум 0.000447281 0.0\n",
      "сценарий 0.0011353 0.0\n",
      "кинотеатр 0.0021086 0.00789362\n",
      "шоу 0.00102762 0.000632938\n",
      "падение 0.00140558 0.0\n",
      "клуб 0.0 0.000100068\n",
      "студия 0.00159925 0.0\n",
      "фильм 0.0919983 0.181007\n",
      "внимание 0.00276041 0.0\n",
      "постановка 0.00264648 0.0\n",
      "развлечение 0.00170459 0.00262917\n",
      "фестиваль 0.000986571 0.00190649\n",
      "холл 0.00267351 0.0\n",
      "любитель 0.00111219 0.00103508\n",
      "молодой 0.00227444 0.0\n",
      "дэвид 0.0 0.00300858\n",
      "включение 0.000443117 0.0\n",
      "вовлечение 0.00403368 0.0\n",
      "американец 0.0 0.00138985\n",
      "индия 0.000474135 0.0\n",
      "видение 0.0 0.00126635\n",
      "установка 0.0 0.00114524\n",
      "учреждение 0.0 0.000276\n",
      "статистика 0.000299085 0.0\n",
      "увеличение 0.000946682 0.0\n",
      "середина 0.00102975 0.0\n",
      "звезда 0.0 0.000717711\n",
      "луна 0.000274944 0.0\n",
      "параллель 0.000190731 0.0\n",
      "противостояние 0.000396778 0.000479386\n",
      "высказывание 0.014908 0.000641348\n",
      "хороший_случай 0.0 0.000716384\n",
      "фрагмент 0.00209303 0.0\n",
      "серия 0.0 0.00528265\n",
      "испытание 0.0 0.000286323\n",
      "завод 0.000230253 0.0\n",
      "парень 0.000986242 0.0\n",
      "ирония 0.0 0.00245253\n",
      "голов 0.000989741 0.0\n",
      "акцент 0.000590532 0.00141369\n",
      "русский_язык 0.0 0.00158117\n",
      "видимость 0.000842938 0.0\n",
      "возраст 0.000667688 0.0\n",
      "разнообразие 0.0 0.000651218\n",
      "современность 0.00296695 0.0\n",
      "вероятность 0.0 0.000491474\n",
      "предел 0.0 0.00236338\n",
      "научный_оборот 0.000443137 0.0\n",
      "цикл 0.00386945 0.0\n",
      "хозяин 0.000429384 0.0\n",
      "картинка 3.47865e-05 0.0\n",
      "книжка 0.0 0.00131973\n",
      "плечо 0.000378222 0.0\n",
      "доза 0.0 0.00021174\n",
      "доминирование 0.00170562 0.0\n",
      "профиль 0.00128636 0.0\n",
      "гора 0.0 0.00215279\n",
      "рука 0.000584287 0.0\n",
      "иной_слово 0.0 0.000228383\n",
      "томас 0.000561481 0.0\n",
      "усилие 0.0 0.00014476\n",
      "центр_внимание 0.000614667 0.0\n",
      "драма 0.0 0.000321231\n",
      "участие 0.0119147 0.000544823\n",
      "актёр 0.0 0.00180475\n",
      "персонаж 0.00206962 0.00357844\n",
      "пласт 0.0 0.00144442\n",
      "танец 0.000421666 0.0\n",
      "навык 0.00033141 0.0\n",
      "когнитивный_механизм 0.000458791 0.0\n",
      "аудитория 0.00248337 0.00643254\n",
      "воспоминание 0.00218259 0.0\n",
      "тайна 0.0 0.000526001\n",
      "стереотип 0.0 0.000320131\n",
      "паук 0.000590999 0.0\n",
      "интрига 0.00124283 0.000116299\n",
      "академия 0.0 0.00428448\n",
      "лада 0.000470214 0.0\n",
      "конвенция 0.0 0.000677085\n",
      "основание 0.000669114 0.0\n",
      "координата 0.0 0.000605224\n",
      "фраза 0.00272503 0.0\n",
      "аппарат 0.00390814 0.0\n",
      "кусок 0.0 0.000363607\n",
      "поток 0.00124578 0.0\n",
      "удивление 0.00432979 0.0\n",
      "секунда 0.00043735 0.0\n",
      "протяжение 0.000396446 0.00330642\n",
      "плохой_условие 0.00239131 0.0\n",
      "матрица 0.000470356 0.0\n",
      "брат 0.0 0.0024166\n",
      "ларри 0.00104314 0.0\n",
      "триллер 0.0 0.00314599\n",
      "зритель 0.0574003 0.00845762\n",
      "иллюзия 0.00343002 0.0\n",
      "кадр 0.0112707 0.0\n",
      "реальный_жизнь 0.000599449 0.0\n",
      "завтрак 0.00134964 0.0\n",
      "экран 0.0228734 0.0\n",
      "отчёт 0.00373294 0.000679807\n",
      "никакой_возможность 0.000525488 0.0\n",
      "сообщение 0.000879363 0.0\n",
      "генерация 0.000934153 0.0\n",
      "научный_точка_зрение 0.000543621 0.0\n",
      "реплика 0.0152761 0.0\n",
      "этап 0.000644845 0.0\n",
      "тестирование 0.000460338 0.0\n",
      "главный_герой 0.00106997 0.00774295\n",
      "шлем 0.000732848 0.0\n",
      "мелодрама 0.00574531 0.0\n",
      "режиссёр 0.0 0.0240915\n",
      "новичок 0.000397334 0.0\n",
      "желание 0.00165641 0.0\n",
      "альтернатива 0.000308345 0.0\n",
      "порог 0.000455538 0.0\n",
      "минута 0.00706514 0.0\n",
      "сходство 0.000346098 0.0\n",
      "отчаяние 0.0 0.000486461\n",
      "абсурд 0.0 0.000639256\n",
      "боевой 0.0 0.000484764\n",
      "задание 0.00179197 0.0\n",
      "подросток 0.00665353 1.80044e-05\n",
      "полицейский 0.0 0.000339589\n",
      "дурак 0.00244455 0.0\n",
      "повествование 0.0013783 0.000641326\n",
      "соцреализм 0.00198968 0.0\n",
      "когнитивный_диссонанс 0.000582904 0.0\n",
      "вызов 0.0 0.000591375\n",
      "билет 0.000477458 0.0\n",
      "толпа 0.0 0.000165135\n",
      "истинность 0.0 6.72881e-05\n",
      "контроль 0.00036443 0.0\n",
      "останки 0.0 0.000293602\n",
      "убийство 0.0026136 0.000597464\n",
      "голос 0.000555392 0.0\n",
      "усиление 0.000528682 0.0\n",
      "паразит 0.0 0.000299532\n",
      "исход 0.0 0.000260423\n",
      "пресса 0.000847834 0.0\n",
      "разгром 0.0 0.00315046\n",
      "призыв 0.000708138 0.0\n",
      "разговор 0.00421754 0.0\n",
      "осознание 0.000449524 0.0\n",
      "свидетель 0.0 0.000159583\n",
      "окончание 0.000451026 0.0\n",
      "десятилетие 0.0 0.00148243\n",
      "действующий_лицо 0.00203941 0.0\n",
      "мужество 0.0 0.00075977\n",
      "ребята 0.00034681 0.0\n",
      "амбиция 0.000302528 0.0\n",
      "крик 0.00052941 0.0\n",
      "красноармеец 0.000187372 0.0\n",
      "протокол 0.00150402 0.0\n",
      "мотивация 0.0 0.000126355\n",
      "указание 0.0 0.000392814\n",
      "кинофильм 0.00588492 0.0\n",
      "демонстрация 0.00115523 0.0\n",
      "капитализм 0.0 0.000872915\n",
      "штаб 0.0 0.000355158\n",
      "ужас 0.00160506 0.00854816\n",
      "братство 0.0 7.93827e-05\n",
      "направленность 0.00129263 0.0\n",
      "членство 0.0 0.000212984\n",
      "работник 0.0 0.000850042\n",
      "полгода 0.000372912 0.0\n",
      "пресс 0.0 0.000913532\n",
      "методика 0.00252238 0.0\n",
      "синхронизация 0.0 0.000532274\n",
      "фанат 0.0 0.00131836\n",
      "жаргон 0.000313447 0.0\n",
      "конечный_счёт 0.0 0.000503836\n",
      "половина_xx_век 0.000243587 0.0\n",
      "последний_десятилетие 0.0 0.000671634\n",
      "промежуток 0.00101591 0.0\n",
      "ускорение 0.000449394 0.0\n",
      "учёт 0.000409367 0.0\n",
      "возбуждение 0.000474453 0.0\n",
      "доля 0.0 0.000390746\n",
      "восторг 0.000586118 0.000594449\n",
      "шаг 0.0 8.17507e-05\n",
      "сын 0.000422548 0.0\n",
      "сцена 0.0065235 0.00504379\n",
      "инструкция 0.0 0.000227895\n",
      "круг 0.000292423 0.000224818\n",
      "целостность 0.0 0.000303746\n",
      "оператор 0.00258929 0.0\n",
      "совмещение 0.0 0.000334024\n",
      "принцип_работа 0.000461075 0.0\n",
      "рассказчик 0.0 0.0011042\n",
      "переживание 0.00136055 0.0\n",
      "радость 0.0 1.35499e-05\n",
      "стремление 0.000870259 0.0\n",
      "зуб 0.0 0.000400245\n",
      "девочка 0.00105742 0.0\n",
      "погружение 0.0132536 0.0\n",
      "метаморфоз 0.000708665 0.0\n",
      "методология 0.000766259 0.000901702\n",
      "сборник 0.0 0.0011865\n",
      "веко 0.000378575 0.0\n",
      "взрыв 0.0010797 0.0\n",
      "урок 0.0 0.000139265\n",
      "определённый_правило 0.000686259 0.0\n",
      "послание 0.0 0.000283397\n",
      "фундамент 0.0 0.0001434\n",
      "совет 0.00047267 0.0\n",
      "отрицание 0.0 0.000155029\n",
      "концептуализация 0.0 0.00172455\n",
      "изменчивость 0.000473365 0.0\n",
      "транскрипция 0.000451528 0.0\n",
      "жанр 0.000703694 0.0304193\n",
      "фантастика 0.0 0.00476182\n",
      "обида 0.0 0.000364384\n",
      "финал 0.00111076 0.000628048\n",
      "хроника 0.0033271 0.0\n",
      "терапия 0.0 7.47068e-05\n",
      "яйцо 0.0 0.00237362\n",
      "индекс_цитирование 0.000464258 0.0\n",
      "пик 0.000952793 0.0\n",
      "создатель 0.0 0.00130777\n",
      "подтверждение 0.000292114 0.0\n",
      "компьютерный_наука 0.00041834 0.0\n",
      "новое_подход 0.0 0.000461064\n",
      "настройка 0.000446739 0.0\n",
      "автономия 0.0 0.000216722\n",
      "дыхание 0.00034857 0.0\n",
      "ниша 0.000678511 0.0\n",
      "скандал 0.0 0.000186555\n",
      "развязка 0.00133082 0.0\n",
      "честность 0.0 0.000218732\n",
      "пристрастие 0.0 0.00256861\n",
      "паттерн 0.000454126 0.0\n",
      "собрание 0.0 0.000658723\n",
      "завершение 0.000840179 0.0\n",
      "чудо 0.00100074 0.0\n",
      "эпитет 0.000532454 0.0\n",
      "удовольствие 0.0 0.000913831\n",
      "половина_хх_век 0.000395853 0.0\n",
      "обзор 0.000434634 0.0\n",
      "творец 0.000433835 0.0\n",
      "метод_исследование 0.000302605 0.0\n",
      "социальный_отношение 0.0 0.000440491\n",
      "повторение 0.00120373 0.0\n",
      "моделирование 0.000426553 0.0\n",
      "необычность 0.000414944 0.0\n",
      "комната 0.00149358 0.0\n",
      "улыбка 0.00183625 0.0\n",
      "противопоставление 0.00223339 0.000103673\n",
      "фиксация 0.000473436 0.0\n",
      "лидер 0.0 0.00105315\n",
      "пророк 0.0 0.000771491\n",
      "энтузиазм 0.000562671 0.0\n",
      "кровь 0.00035858 0.0\n",
      "спина 0.000554233 0.0\n",
      "опасение 0.00128134 0.0\n",
      "обсуждение 0.0 0.000812717\n",
      "привлечение 0.000467712 0.0\n",
      "телевидение 0.0 0.00120987\n",
      "небо 0.0 0.000323217\n",
      "течение_последний 0.0 0.000247922\n",
      "бедствие 0.0 0.000692049\n",
      "кошмар 0.00253599 0.0\n",
      "мастер 0.000114596 0.00136421\n",
      "популярный_культура 0.0 0.00817109\n",
      "издательский_дом 0.0 0.000629716\n",
      "адресат 0.000461549 0.0\n",
      "полемика 0.0 0.000229079\n",
      "молчание 0.0 0.000320638\n",
      "детство 0.000945736 0.0\n",
      "товарищ 0.000911819 0.0\n",
      "сопоставление 0.000435456 0.0\n",
      "знакомство 0.000457351 0.0\n",
      "сестра 0.00163533 0.0\n",
      "рис 0.00309268 0.0\n",
      "инцидент 0.00177643 0.0\n",
      "альфред 0.0 0.000923733\n",
      "удержание 0.00128011 0.0\n",
      "призма 0.0 0.000863358\n",
      "актриса 0.0 0.000341067\n",
      "эротика 0.00213281 0.0\n",
      "телесность 0.0 0.00178627\n",
      "героиня 0.00122379 0.0\n",
      "маркер 0.00268306 0.0\n",
      "взросление 0.0 0.000202009\n",
      "отождествление 0.000447927 0.0\n",
      "входящая 0.0004148 0.0\n",
      "оборот 0.0 0.000590232\n",
      "произнесение 0.000348542 0.0\n",
      "субъект 0.0 0.00108224\n",
      "общественный_сознание 0.0 0.000688803\n",
      "дистанция 0.00147046 0.0\n",
      "слой_население 0.000428007 0.0\n",
      "американский_учёный 0.000816944 0.0\n",
      "очки 0.00202373 0.0\n",
      "новый_подход 0.0 0.000346666\n",
      "несчастие 0.0 7.76821e-05\n",
      "видео 0.0 0.00156435\n",
      "зал 0.00364509 0.0\n",
      "съёмка 0.0 0.00125888\n",
      "напряжённость 0.000476152 0.0\n",
      "весна 0.000223656 0.0\n",
      "теоретический_работа 0.000586159 0.0\n",
      "эссе 0.0 0.00388754\n",
      "различение 0.000498983 0.0\n",
      "современный_теория 0.000527444 0.0\n",
      "кант 0.0 0.000519615\n",
      "симон 0.000950601 0.0\n",
      "низ 0.0 0.000797373\n",
      "пауза 0.000394637 0.0\n",
      "конец_xv_век 0.0 0.00223279\n",
      "белых 0.0 0.000616578\n",
      "обвинение 0.0 0.00028053\n",
      "ремесло 0.000270749 0.0\n",
      "случайность 0.000491532 0.0\n",
      "злодей 0.0 0.00200345\n",
      "принадлежность 0.0 0.000754268\n",
      "почерк 0.0 0.000299918\n",
      "профессиональный_учёный 0.0 0.00238409\n",
      "господь 0.000461516 0.0\n",
      "алкоголь 0.0 0.00017663\n",
      "анализ_фильм 0.000574952 0.0\n",
      "рецензия 0.0 0.00159355\n",
      "определённый_тип 0.0 0.000945698\n",
      "киновед 0.0 0.00672011\n",
      "культовый_кино 0.0 0.00519438\n",
      "аллюзия 0.0 0.00273908\n",
      "хоррор 0.0 0.0207662\n",
      "легитимация 0.0 0.00170442\n",
      "диковинка 0.00239131 0.0\n",
      "зрелище 0.0026381 0.000186607\n",
      "выстраивание 0.000598045 0.0\n",
      "обретение 0.000803773 0.0\n",
      "определённый_момент 0.0 0.000572469\n",
      "венеция 0.000420986 0.0\n",
      "итальянец 0.000432417 0.0\n",
      "пытка 0.0 0.000306158\n",
      "комедия 0.000788963 0.00757398\n",
      "блюдо 0.000353686 0.0\n",
      "погоня 0.000973889 0.0\n",
      "пассаж 0.0 2.95665e-05\n",
      "закрепление 0.0 0.00028929\n",
      "показ 0.0032476 0.0\n",
      "графика 0.00110191 0.0\n",
      "арена 1.80187e-05 0.0\n",
      "подкрепление 0.0 0.000295877\n",
      "большой_влияние 0.000401338 0.0\n",
      "франк 0.000325558 0.0\n",
      "тв 0.00305028 0.0\n",
      "эстетика 0.000363613 0.000137688\n",
      "пробуждение 0.000388227 0.0\n",
      "скот 6.71766e-05 0.0\n",
      "чудовище 0.0 0.000557053\n",
      "сента 0.000217037 0.0\n",
      "пустынь 0.00152942 0.0\n",
      "шкала 0.00135216 0.0\n",
      "пародия 0.0 0.00121955\n",
      "кукла 0.0 0.000301841\n",
      "артхаус 0.0 0.00250328\n",
      "просмотр 0.0189628 0.0\n",
      "грайндхаус 0.0 0.00811212\n",
      "кавычка 0.0 0.000994358\n",
      "симпсон 0.0 0.0043856\n",
      "слава_жижка 0.0 0.00266921\n",
      "монстр 0.0 0.00410323\n",
      "зомби 0.00381776 0.0\n",
      "плохой_кино 0.0 0.0094306\n",
      "фэнтези 0.0 0.00344791\n",
      "хранитель 0.0 0.000282396\n",
      "домохозяйка 0.000124854 0.0\n",
      "общий_принцип 0.000511027 0.0\n",
      "оформление 0.00136355 0.0\n",
      "допущение 0.00072634 0.0\n",
      "интеллектуальный_развитие 0.0 0.000311116\n",
      "кинолента 0.00541492 0.0\n",
      "секс 0.0 0.00345153\n",
      "любовник 0.0 8.20115e-05\n",
      "прыжок 0.0025136 0.0\n",
      "сексуальность 0.0 0.00456086\n",
      "табу 0.0 0.000237003\n",
      "середина_xx_век 0.000134969 0.0\n",
      "маркетинг 0.000206324 0.0\n",
      "альянс 0.0 0.000546716\n",
      "утопия 0.0 0.00258463\n",
      "адепт 0.0 0.000457772\n",
      "горло 0.000462336 0.0\n",
      "охранник 0.0 0.00111968\n",
      "джек 0.0 0.00699653\n",
      "острота 0.000473683 0.0\n",
      "бегство 0.0 0.000193371\n",
      "ворот 0.000477895 0.0\n",
      "трюк 0.00150332 0.0\n",
      "снятие 0.000631822 0.0\n",
      "роберт 0.0 0.000998494\n",
      "детальный_анализ 0.0 0.000613238\n",
      "рубеж_xix 0.000487798 0.0\n",
      "существенный_образ 0.000447797 0.0\n",
      "сегмент 6.53385e-05 0.000631898\n",
      "подобие 0.000555326 0.0\n",
      "синоним 0.000158622 0.0\n",
      "смех 0.016133 0.0\n",
      "нерв 0.0 0.000285754\n",
      "ханна_арендт 0.0 0.00159805\n",
      "надёжность 0.000945451 0.0\n",
      "академический_исследование 0.0 0.00115009\n",
      "потрясение 0.00034962 0.0\n",
      "частотность 0.000952031 0.0\n",
      "нацист 0.0 0.00078657\n",
      "фуко 0.0 0.000936223\n",
      "плакат 0.0 0.00126328\n",
      "катаклизм 0.0 0.000308944\n",
      "пустота 0.0 0.000318175\n",
      "отверстие 0.000322132 0.0\n",
      "табла 0.00155993 0.0\n",
      "просьба 0.000466878 0.0\n",
      "терпение 0.000392089 0.0\n",
      "месть 0.0 0.000949883\n",
      "участник_эксперимент 0.000509148 0.0\n",
      "обработка_информация 0.000412768 0.0\n",
      "внутренний_структура 0.0 0.00109235\n",
      "придание 0.000312361 0.000528225\n",
      "подсознание 0.000157495 0.0\n",
      "пунктуация 0.000483743 0.0\n",
      "оперативный_память 0.000433105 0.0\n",
      "универсум 0.0 7.02449e-05\n",
      "средний_азия 0.00230392 0.0\n",
      "алексеев 0.000471071 0.0\n",
      "зрительский_восприятие 0.0033575 0.0\n",
      "родоначальник 0.00113695 0.0\n",
      "билл 0.00438882 0.0\n",
      "общий_число 0.000566909 0.0\n",
      "индивидуальный_различие 0.000939779 0.0\n",
      "студенчество 0.000492544 0.0\n",
      "голливуд 0.0075644 0.0\n",
      "сопереживание 0.000997228 0.0\n",
      "фильм_ужас 0.0 0.00281816\n",
      "аттракцион 0.00818843 0.0\n",
      "провал 0.00107489 0.0\n",
      "слабый_место 0.000280581 0.0\n",
      "претензия 0.0 0.000656561\n",
      "общий_вид 0.000297329 0.0\n",
      "символизм 0.0 0.000304475\n",
      "подтекст 0.0 0.000312228\n",
      "эйзенштейн 0.0125504 0.0\n",
      "французский_историк 0.0 0.00074439\n",
      "пирог 0.0 0.000495376\n",
      "коэн 0.0 0.00274065\n",
      "обложка 0.000512529 0.0\n",
      "избиение 0.00107655 0.00146395\n",
      "дон 0.0 0.000204024\n",
      "программный_статья 0.00239131 0.0\n",
      "отторжение 0.0 0.000320079\n",
      "прокат 0.0 0.00284779\n",
      "арендт 0.0 0.00253449\n",
      "условность 0.0 0.000579064\n",
      "клод 0.00321171 0.0\n",
      "брожение 0.000501023 0.0\n",
      "покрывало 0.000406116 0.0\n",
      "новшество 0.000469627 0.0\n",
      "холодильник 0.000463415 0.0\n",
      "кратасюк 0.0 0.000259511\n",
      "экранизация 0.000105735 0.00302526\n",
      "проститутка 0.0 0.000959605\n",
      "известный_мера 0.00384059 0.0\n",
      "единый_картина 0.00384059 0.0\n",
      "поль_зрение 0.000506725 0.0\n",
      "джейн 0.00386575 0.0\n",
      "вегетарианец 0.0 0.00155865\n",
      "кинематографист 0.00384059 0.0\n",
      "жижка 0.0 0.00232551\n",
      "робин_вуд 0.0 0.00281816\n"
     ]
    }
   ],
   "source": [
    "for idx in phi.index:\n",
    "    val = phi[topic_name][idx]\n",
    "    val_other = phi[other_topic_name][idx]\n",
    "    if val != 0 or val_other != 0:\n",
    "        print idx, val, val_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# наберём из small dist тем набор, берем не похожие друг на друга\n",
    "# 2 варианта: по th, по проверке входит ли в топ ближ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_topics_to_remove_by_threshold(small_dist_opts, distances):\n",
    "    dist_threshold = 0.88\n",
    "    sorted_by_fun = sorted(small_dist_opts.values(), key = lambda x: x.fun)\n",
    "    topics_to_remove = []\n",
    "    for opt_res in sorted_by_fun:\n",
    "        topic_name = opt_res.optimized_column\n",
    "        # check not close to current topics to remove\n",
    "        dists_to_topics_to_remove = [distances[topic_name][t] for t in topics_to_remove]\n",
    "        is_far = np.all(np.array(dists_to_topics_to_remove) > dist_threshold)\n",
    "        if is_far:\n",
    "            topics_to_remove.append(topic_name)\n",
    "    return topics_to_remove\n",
    "def get_topics_to_remove_by_closest_dist(small_dist_opts, distances):\n",
    "    n_closest = 10\n",
    "    sorted_by_fun = sorted(small_dist_opts.values(), key = lambda x: x.fun)\n",
    "    topics_to_remove = []\n",
    "    for opt_res in sorted_by_fun:\n",
    "        topic_name = opt_res.optimized_column\n",
    "        # check not close to current topics to remove\n",
    "        is_closest = lambda topic, other_topic: np.any(distances[topic].sort_values().head(n_closest).index.values == other_topic)\n",
    "        dists_to_topics_to_remove = [not is_closest(topic_name, t) for t in topics_to_remove]\n",
    "        is_far = np.all(np.array(dists_to_topics_to_remove))\n",
    "        if is_far:\n",
    "            topics_to_remove.append(topic_name)\n",
    "    return topics_to_remove\n",
    "def remove_topics_from_phi(phi, topics_to_remove):\n",
    "    return phi.drop(topics_to_remove, axis=1)\n",
    "def remove_topics_from_distances(distances, topics_to_remove):\n",
    "    distances_convex_hull = distances.drop(topics_to_remove, axis=1)\n",
    "    distances_convex_hull = distances_convex_hull.drop(topics_to_remove, axis=0)\n",
    "    return distances_convex_hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_145: кварк мезон античастица антиматерия материя частица пара асимметрия эксперимент барион протон\n",
      "topic_356: солнечный_система планета тело орбита астероид комета юпитер аппарат гигант земля планет\n",
      "topic_327: нейрон мозг нервный_клетка связь гиппокамп нервный_система аксон помощь процесс работа исследование\n",
      "topic_184: самец самка шимпанзе примат детёныш группа секс спаривание обезьяна половый_партнёр сперматозоид\n",
      "topic_117: геном днк участок ген последовательность изменение болезнь клетка подход опечатка помощь\n",
      "topic_38: реликтовый_излучение излучение космология флуктуация шум эксперимент распределение масштаб большой_взрыв параметр стержень\n",
      "topic_428: фильм кино кинематограф жанр режиссёр картина хоррор тема реж плохой_кино точка_зрение\n",
      "topic_373: ландшафт физик вакуум шарик уравнение физика закон_физика теория простота теоретик долина\n",
      "topic_230: страна китай сша индия инвестиция ввп отношение развитие япония торговля экономический_развитие\n",
      "topic_419: матерь мать женщина отец роды материнство ребёнок помощь муж счастие жизнь\n",
      "topic_75: диалект лексика язык словарь карта литературный_язык вариант говор диалектный_язык изучение фонетика\n",
      "topic_418: диссертация аспирант работа степень совет задача проблема аспирантура ситуация список академический_сообщество\n",
      "topic_272: знание историк исторический_знание исторический_наука история американец курение проблема тема табак факт\n",
      "topic_127: кислород водород азот метан архея атмосфера углерод жизнь органический_вещество реакция органика\n",
      "topic_140: политика власть общество феминизм сфера критика сексуальность отношение сила качество публичный_сфера\n"
     ]
    }
   ],
   "source": [
    "topics_to_remove_by_closest_dist = get_topics_to_remove_by_closest_dist(small_dist_opts, distances)\n",
    "print '\\n'.join([unicode_list_to_str(topic_name, saved_top_tokens[topic_name][0:11]) for topic_name in topics_to_remove_by_closest_dist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_145: кварк мезон античастица антиматерия материя частица пара асимметрия эксперимент барион протон\n",
      "topic_356: солнечный_система планета тело орбита астероид комета юпитер аппарат гигант земля планет\n",
      "topic_327: нейрон мозг нервный_клетка связь гиппокамп нервный_система аксон помощь процесс работа исследование\n",
      "topic_184: самец самка шимпанзе примат детёныш группа секс спаривание обезьяна половый_партнёр сперматозоид\n",
      "topic_117: геном днк участок ген последовательность изменение болезнь клетка подход опечатка помощь\n",
      "topic_278: белка белок клетка приона цитоплазма домен шаперон агрегат состояние фибрилла дрожжи\n",
      "topic_38: реликтовый_излучение излучение космология флуктуация шум эксперимент распределение масштаб большой_взрыв параметр стержень\n",
      "topic_78: звезда масса гелий белых_карлик белый_карлик водород солнце вещество светимость термоядерный_реакция размер\n",
      "topic_428: фильм кино кинематограф жанр режиссёр картина хоррор тема реж плохой_кино точка_зрение\n",
      "topic_373: ландшафт физик вакуум шарик уравнение физика закон_физика теория простота теоретик долина\n",
      "topic_230: страна китай сша индия инвестиция ввп отношение развитие япония торговля экономический_развитие\n",
      "topic_419: матерь мать женщина отец роды материнство ребёнок помощь муж счастие жизнь\n",
      "topic_83: рынок правительство рубль цена валюта актив политика государственный_долг центральный_банк доллар инвестор\n",
      "topic_75: диалект лексика язык словарь карта литературный_язык вариант говор диалектный_язык изучение фонетика\n",
      "topic_418: диссертация аспирант работа степень совет задача проблема аспирантура ситуация список академический_сообщество\n",
      "topic_272: знание историк исторический_знание исторический_наука история американец курение проблема тема табак факт\n",
      "topic_127: кислород водород азот метан архея атмосфера углерод жизнь органический_вещество реакция органика\n",
      "topic_140: политика власть общество феминизм сфера критика сексуальность отношение сила качество публичный_сфера\n",
      "topic_3: работа автор статья исследование тема монография издание труд изучение материал редактор\n"
     ]
    }
   ],
   "source": [
    "topics_to_remove_by_threshold = get_topics_to_remove_by_threshold(small_dist_opts, distances)\n",
    "print '\\n'.join([unicode_list_to_str(topic_name, saved_top_tokens[topic_name][0:11]) for topic_name in topics_to_remove_by_threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_topics_to_remove(_opt_res, _phi_convex_hull, _distances_convex_hull, low_th, high_th):     \n",
    "    small_dist_opts = {col: _opt_res[col] for col in _phi_convex_hull.columns if _opt_res[col].fun < low_th}\n",
    "    large_dist_opts = {col: _opt_res[col] for col in _phi_convex_hull.columns if _opt_res[col].fun > high_th}\n",
    "    print len(small_dist_opts), len(large_dist_opts)\n",
    "    topics_to_remove_by_closest_dist = get_topics_to_remove_by_closest_dist(small_dist_opts, _distances_convex_hull)\n",
    "    print 'topics to remove = ', len(topics_to_remove_by_closest_dist)\n",
    "    print '\\n'.join([unicode_list_to_str(topic_name, saved_top_tokens[topic_name][0:11]) for topic_name in topics_to_remove_by_closest_dist])\n",
    "    return topics_to_remove_by_closest_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iteration = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016-12-11 00:49:22.214000] get_optimization_result for column 0\n",
      "[2016-12-11 00:49:22.624000] get_optimization_result for column 1\n",
      "[2016-12-11 00:49:23.036000] get_optimization_result for column 2\n",
      "[2016-12-11 00:49:23.277000] get_optimization_result for column 3\n",
      "[2016-12-11 00:49:23.828000] get_optimization_result for column 4\n",
      "[2016-12-11 00:49:24.208000] get_optimization_result for column 5\n",
      "[2016-12-11 00:49:24.961000] get_optimization_result for column 6\n",
      "[2016-12-11 00:49:25.269000] get_optimization_result for column 7\n",
      "[2016-12-11 00:49:25.655000] get_optimization_result for column 8\n",
      "[2016-12-11 00:49:26.290000] get_optimization_result for column 9\n",
      "[2016-12-11 00:49:27.021000] get_optimization_result for column 10\n",
      "[2016-12-11 00:49:27.272000] get_optimization_result for column 11\n",
      "[2016-12-11 00:49:27.590000] get_optimization_result for column 12\n",
      "[2016-12-11 00:49:28.038000] get_optimization_result for column 13\n",
      "[2016-12-11 00:49:28.771000] get_optimization_result for column 14\n",
      "[2016-12-11 00:49:29.057000] get_optimization_result for column 15\n",
      "[2016-12-11 00:49:29.396000] get_optimization_result for column 16\n",
      "[2016-12-11 00:49:29.698000] get_optimization_result for column 17\n",
      "[2016-12-11 00:49:29.969000] get_optimization_result for column 18\n",
      "[2016-12-11 00:49:31] get_optimization_result for column 19\n",
      "[2016-12-11 00:49:31.249000] get_optimization_result for column 20\n",
      "[2016-12-11 00:49:31.654000] get_optimization_result for column 21\n",
      "[2016-12-11 00:49:32.369000] get_optimization_result for column 22\n",
      "[2016-12-11 00:49:32.676000] get_optimization_result for column 23\n",
      "[2016-12-11 00:49:33.044000] get_optimization_result for column 24\n",
      "[2016-12-11 00:49:33.272000] get_optimization_result for column 25\n",
      "[2016-12-11 00:49:33.735000] get_optimization_result for column 26\n",
      "[2016-12-11 00:49:34.296000] get_optimization_result for column 27\n",
      "[2016-12-11 00:49:34.754000] get_optimization_result for column 28\n",
      "[2016-12-11 00:49:35.048000] get_optimization_result for column 29\n",
      "[2016-12-11 00:49:35.229000] get_optimization_result for column 30\n",
      "[2016-12-11 00:49:35.465000] get_optimization_result for column 31\n",
      "[2016-12-11 00:49:35.941000] get_optimization_result for column 32\n",
      "[2016-12-11 00:49:36.355000] get_optimization_result for column 33\n",
      "[2016-12-11 00:49:37.194000] get_optimization_result for column 34\n",
      "[2016-12-11 00:49:37.344000] get_optimization_result for column 35\n",
      "[2016-12-11 00:49:37.575000] get_optimization_result for column 36\n",
      "[2016-12-11 00:49:38.294000] get_optimization_result for column 37\n",
      "[2016-12-11 00:49:38.408000] get_optimization_result for column 38\n",
      "[2016-12-11 00:49:38.836000] get_optimization_result for column 39\n",
      "[2016-12-11 00:49:39.278000] get_optimization_result for column 40\n",
      "[2016-12-11 00:49:39.568000] get_optimization_result for column 41\n",
      "[2016-12-11 00:49:39.919000] get_optimization_result for column 42\n",
      "[2016-12-11 00:49:40.079000] get_optimization_result for column 43\n",
      "[2016-12-11 00:49:40.412000] get_optimization_result for column 44\n",
      "[2016-12-11 00:49:40.575000] get_optimization_result for column 45\n",
      "[2016-12-11 00:49:41.589000] get_optimization_result for column 46\n",
      "[2016-12-11 00:49:41.895000] get_optimization_result for column 47\n",
      "[2016-12-11 00:49:42.252000] get_optimization_result for column 48\n",
      "[2016-12-11 00:49:42.852000] get_optimization_result for column 49\n",
      "[2016-12-11 00:49:42.941000] get_optimization_result for column 50\n",
      "[2016-12-11 00:49:43.349000] get_optimization_result for column 51\n",
      "[2016-12-11 00:49:43.657000] get_optimization_result for column 52\n",
      "[2016-12-11 00:49:43.818000] get_optimization_result for column 53\n",
      "[2016-12-11 00:49:43.968000] get_optimization_result for column 54\n",
      "[2016-12-11 00:49:44.720000] get_optimization_result for column 55\n",
      "[2016-12-11 00:49:44.926000] get_optimization_result for column 56\n",
      "[2016-12-11 00:49:45.668000] get_optimization_result for column 57\n",
      "[2016-12-11 00:49:45.760000] get_optimization_result for column 58\n",
      "[2016-12-11 00:49:46.031000] get_optimization_result for column 59\n",
      "[2016-12-11 00:49:46.350000] get_optimization_result for column 60\n",
      "[2016-12-11 00:49:46.847000] get_optimization_result for column 61\n",
      "[2016-12-11 00:49:47.172000] get_optimization_result for column 62\n",
      "[2016-12-11 00:49:47.465000] get_optimization_result for column 63\n",
      "[2016-12-11 00:49:48.047000] get_optimization_result for column 64\n",
      "[2016-12-11 00:49:48.352000] get_optimization_result for column 65\n",
      "[2016-12-11 00:49:48.678000] get_optimization_result for column 66\n",
      "[2016-12-11 00:49:49.192000] get_optimization_result for column 67\n",
      "[2016-12-11 00:49:49.526000] get_optimization_result for column 68\n",
      "[2016-12-11 00:49:49.894000] get_optimization_result for column 69\n",
      "[2016-12-11 00:49:50.165000] get_optimization_result for column 70\n",
      "[2016-12-11 00:49:50.790000] get_optimization_result for column 71\n",
      "[2016-12-11 00:49:51.193000] get_optimization_result for column 72\n",
      "[2016-12-11 00:49:51.917000] get_optimization_result for column 73\n",
      "[2016-12-11 00:49:52.511000] get_optimization_result for column 74\n",
      "[2016-12-11 00:49:52.962000] get_optimization_result for column 75\n",
      "[2016-12-11 00:49:53.282000] get_optimization_result for column 76\n",
      "[2016-12-11 00:49:54.587000] get_optimization_result for column 77\n",
      "[2016-12-11 00:49:54.999000] get_optimization_result for column 78\n",
      "[2016-12-11 00:49:55.867000] get_optimization_result for column 79\n",
      "[2016-12-11 00:49:56.133000] get_optimization_result for column 80\n",
      "[2016-12-11 00:49:57.173000] get_optimization_result for column 81\n",
      "[2016-12-11 00:49:57.629000] get_optimization_result for column 82\n",
      "[2016-12-11 00:49:58.044000] get_optimization_result for column 83\n",
      "[2016-12-11 00:49:58.363000] get_optimization_result for column 84\n",
      "[2016-12-11 00:49:58.646000] get_optimization_result for column 85\n",
      "[2016-12-11 00:49:59.034000] get_optimization_result for column 86\n",
      "[2016-12-11 00:49:59.530000] get_optimization_result for column 87\n",
      "[2016-12-11 00:49:59.907000] get_optimization_result for column 88\n",
      "[2016-12-11 00:50:00.370000] get_optimization_result for column 89\n",
      "[2016-12-11 00:50:00.630000] get_optimization_result for column 90\n",
      "[2016-12-11 00:50:00.998000] get_optimization_result for column 91\n",
      "[2016-12-11 00:50:01.334000] get_optimization_result for column 92\n",
      "[2016-12-11 00:50:01.869000] get_optimization_result for column 93\n",
      "[2016-12-11 00:50:02.490000] get_optimization_result for column 94\n",
      "[2016-12-11 00:50:03.479000] get_optimization_result for column 95\n",
      "[2016-12-11 00:50:04.171000] get_optimization_result for column 96\n",
      "[2016-12-11 00:50:04.603000] get_optimization_result for column 97\n",
      "[2016-12-11 00:50:04.945000] get_optimization_result for column 98\n",
      "[2016-12-11 00:50:05.337000] get_optimization_result for column 99\n",
      "[2016-12-11 00:50:05.850000] get_optimization_result for column 100\n",
      "[2016-12-11 00:50:06.154000] get_optimization_result for column 101\n",
      "[2016-12-11 00:50:06.328000] get_optimization_result for column 102\n",
      "[2016-12-11 00:50:06.807000] get_optimization_result for column 103\n",
      "[2016-12-11 00:50:07.680000] get_optimization_result for column 104\n",
      "[2016-12-11 00:50:07.978000] get_optimization_result for column 105\n",
      "[2016-12-11 00:50:08.249000] get_optimization_result for column 106\n",
      "[2016-12-11 00:50:08.978000] get_optimization_result for column 107\n",
      "[2016-12-11 00:50:09.265000] get_optimization_result for column 108\n",
      "[2016-12-11 00:50:09.330000] get_optimization_result for column 109\n",
      "[2016-12-11 00:50:09.693000] get_optimization_result for column 110\n",
      "[2016-12-11 00:50:09.933000] get_optimization_result for column 111\n",
      "[2016-12-11 00:50:10.612000] get_optimization_result for column 112\n",
      "[2016-12-11 00:50:11.472000] get_optimization_result for column 113\n",
      "[2016-12-11 00:50:12.084000] get_optimization_result for column 114\n",
      "[2016-12-11 00:50:12.389000] get_optimization_result for column 115\n",
      "[2016-12-11 00:50:13.243000] get_optimization_result for column 116\n",
      "[2016-12-11 00:50:14.017000] get_optimization_result for column 117\n",
      "[2016-12-11 00:50:14.615000] get_optimization_result for column 118\n",
      "[2016-12-11 00:50:15.088000] get_optimization_result for column 119\n",
      "[2016-12-11 00:50:15.376000] get_optimization_result for column 120\n",
      "[2016-12-11 00:50:15.860000] get_optimization_result for column 121\n",
      "[2016-12-11 00:50:16.587000] get_optimization_result for column 122\n",
      "[2016-12-11 00:50:16.858000] get_optimization_result for column 123\n",
      "[2016-12-11 00:50:17.396000] get_optimization_result for column 124\n",
      "[2016-12-11 00:50:19.057000] get_optimization_result for column 125\n",
      "[2016-12-11 00:50:19.369000] get_optimization_result for column 126\n",
      "[2016-12-11 00:50:19.723000] get_optimization_result for column 127\n",
      "[2016-12-11 00:50:20.124000] get_optimization_result for column 128\n",
      "[2016-12-11 00:50:20.517000] get_optimization_result for column 129\n",
      "[2016-12-11 00:50:21.212000] get_optimization_result for column 130\n",
      "[2016-12-11 00:50:22.149000] get_optimization_result for column 131\n",
      "[2016-12-11 00:50:22.782000] get_optimization_result for column 132\n",
      "[2016-12-11 00:50:23.678000] get_optimization_result for column 133\n",
      "[2016-12-11 00:50:24.136000] get_optimization_result for column 134\n",
      "[2016-12-11 00:50:24.818000] get_optimization_result for column 135\n",
      "[2016-12-11 00:50:25.152000] get_optimization_result for column 136\n",
      "[2016-12-11 00:50:25.610000] get_optimization_result for column 137\n",
      "[2016-12-11 00:50:25.896000] get_optimization_result for column 138\n",
      "[2016-12-11 00:50:26.147000] get_optimization_result for column 139\n",
      "[2016-12-11 00:50:26.362000] get_optimization_result for column 140\n",
      "[2016-12-11 00:50:27.140000] get_optimization_result for column 141\n",
      "[2016-12-11 00:50:27.611000] get_optimization_result for column 142\n",
      "[2016-12-11 00:50:27.854000] get_optimization_result for column 143\n",
      "[2016-12-11 00:50:27.958000] get_optimization_result for column 144\n",
      "[2016-12-11 00:50:28.293000] get_optimization_result for column 145\n",
      "[2016-12-11 00:50:28.511000] get_optimization_result for column 146\n",
      "[2016-12-11 00:50:28.875000] get_optimization_result for column 147\n",
      "[2016-12-11 00:50:29.379000] get_optimization_result for column 148\n",
      "[2016-12-11 00:50:29.777000] get_optimization_result for column 149\n",
      "[2016-12-11 00:50:30.295000] get_optimization_result for column 150\n",
      "[2016-12-11 00:50:30.538000] get_optimization_result for column 151\n",
      "[2016-12-11 00:50:30.831000] get_optimization_result for column 152\n",
      "[2016-12-11 00:50:31.468000] get_optimization_result for column 153\n",
      "[2016-12-11 00:50:31.756000] get_optimization_result for column 154\n",
      "[2016-12-11 00:50:32.157000] get_optimization_result for column 155\n",
      "[2016-12-11 00:50:32.963000] get_optimization_result for column 156\n",
      "[2016-12-11 00:50:33.319000] get_optimization_result for column 157\n",
      "[2016-12-11 00:50:33.910000] get_optimization_result for column 158\n",
      "[2016-12-11 00:50:34.454000] get_optimization_result for column 159\n",
      "[2016-12-11 00:50:34.809000] get_optimization_result for column 160\n",
      "[2016-12-11 00:50:35.250000] get_optimization_result for column 161\n",
      "[2016-12-11 00:50:36.054000] get_optimization_result for column 162\n",
      "[2016-12-11 00:50:36.391000] get_optimization_result for column 163\n",
      "[2016-12-11 00:50:36.571000] get_optimization_result for column 164\n",
      "[2016-12-11 00:50:36.860000] get_optimization_result for column 165\n",
      "[2016-12-11 00:50:36.998000] get_optimization_result for column 166\n",
      "[2016-12-11 00:50:37.436000] get_optimization_result for column 167\n",
      "[2016-12-11 00:50:37.749000] get_optimization_result for column 168\n",
      "[2016-12-11 00:50:38.039000] get_optimization_result for column 169\n",
      "[2016-12-11 00:50:38.337000] get_optimization_result for column 170\n",
      "[2016-12-11 00:50:38.692000] get_optimization_result for column 171\n",
      "[2016-12-11 00:50:38.869000] get_optimization_result for column 172\n",
      "[2016-12-11 00:50:39.164000] get_optimization_result for column 173\n",
      "[2016-12-11 00:50:39.526000] get_optimization_result for column 174\n",
      "[2016-12-11 00:50:39.894000] get_optimization_result for column 175\n",
      "[2016-12-11 00:50:40.132000] get_optimization_result for column 176\n",
      "[2016-12-11 00:50:40.385000] get_optimization_result for column 177\n",
      "[2016-12-11 00:50:40.835000] get_optimization_result for column 178\n",
      "[2016-12-11 00:50:41.482000] get_optimization_result for column 179\n",
      "[2016-12-11 00:50:41.802000] get_optimization_result for column 180\n",
      "[2016-12-11 00:50:42.688000] get_optimization_result for column 181\n",
      "[2016-12-11 00:50:43.084000] get_optimization_result for column 182\n",
      "[2016-12-11 00:50:43.361000] get_optimization_result for column 183\n",
      "[2016-12-11 00:50:43.933000] get_optimization_result for column 184\n",
      "[2016-12-11 00:50:44.485000] get_optimization_result for column 185\n",
      "[2016-12-11 00:50:44.735000] get_optimization_result for column 186\n",
      "[2016-12-11 00:50:44.857000] get_optimization_result for column 187\n",
      "[2016-12-11 00:50:45.092000] get_optimization_result for column 188\n",
      "[2016-12-11 00:50:45.553000] get_optimization_result for column 189\n",
      "[2016-12-11 00:50:45.999000] get_optimization_result for column 190\n",
      "[2016-12-11 00:50:46.266000] get_optimization_result for column 191\n",
      "[2016-12-11 00:50:46.503000] get_optimization_result for column 192\n",
      "[2016-12-11 00:50:46.579000] get_optimization_result for column 193\n",
      "[2016-12-11 00:50:46.669000] get_optimization_result for column 194\n",
      "[2016-12-11 00:50:47.082000] get_optimization_result for column 195\n",
      "[2016-12-11 00:50:47.493000] get_optimization_result for column 196\n",
      "[2016-12-11 00:50:47.779000] get_optimization_result for column 197\n",
      "[2016-12-11 00:50:48.112000] get_optimization_result for column 198\n",
      "[2016-12-11 00:50:48.490000] get_optimization_result for column 199\n",
      "[2016-12-11 00:50:48.782000] get_optimization_result for column 200\n",
      "[2016-12-11 00:50:49.071000] get_optimization_result for column 201\n",
      "[2016-12-11 00:50:49.369000] get_optimization_result for column 202\n",
      "[2016-12-11 00:50:49.564000] get_optimization_result for column 203\n",
      "[2016-12-11 00:50:50.509000] get_optimization_result for column 204\n",
      "[2016-12-11 00:50:50.632000] get_optimization_result for column 205\n",
      "[2016-12-11 00:50:50.912000] get_optimization_result for column 206\n",
      "[2016-12-11 00:50:52.369000] get_optimization_result for column 207\n",
      "[2016-12-11 00:50:53.196000] get_optimization_result for column 208\n",
      "[2016-12-11 00:50:53.257000] get_optimization_result for column 209\n",
      "[2016-12-11 00:50:53.744000] get_optimization_result for column 210\n",
      "[2016-12-11 00:50:54.155000] get_optimization_result for column 211\n",
      "[2016-12-11 00:50:54.496000] get_optimization_result for column 212\n",
      "[2016-12-11 00:50:54.841000] get_optimization_result for column 213\n",
      "[2016-12-11 00:50:55.172000] get_optimization_result for column 214\n",
      "[2016-12-11 00:50:55.859000] get_optimization_result for column 215\n",
      "[2016-12-11 00:50:56.282000] get_optimization_result for column 216\n",
      "[2016-12-11 00:50:56.509000] get_optimization_result for column 217\n",
      "[2016-12-11 00:50:56.978000] get_optimization_result for column 218\n",
      "[2016-12-11 00:50:57.462000] get_optimization_result for column 219\n",
      "[2016-12-11 00:50:57.644000] get_optimization_result for column 220\n",
      "[2016-12-11 00:50:58.005000] get_optimization_result for column 221\n",
      "[2016-12-11 00:50:58.650000] get_optimization_result for column 222\n",
      "[2016-12-11 00:50:59.199000] get_optimization_result for column 223\n",
      "[2016-12-11 00:50:59.610000] get_optimization_result for column 224\n",
      "[2016-12-11 00:50:59.938000] get_optimization_result for column 225\n",
      "[2016-12-11 00:51:00.544000] get_optimization_result for column 226\n",
      "[2016-12-11 00:51:01.040000] get_optimization_result for column 227\n",
      "[2016-12-11 00:51:01.525000] get_optimization_result for column 228\n",
      "[2016-12-11 00:51:01.791000] get_optimization_result for column 229\n",
      "[2016-12-11 00:51:02.052000] get_optimization_result for column 230\n",
      "[2016-12-11 00:51:02.845000] get_optimization_result for column 231\n",
      "[2016-12-11 00:51:03.253000] get_optimization_result for column 232\n",
      "[2016-12-11 00:51:03.726000] get_optimization_result for column 233\n",
      "[2016-12-11 00:51:04.565000] get_optimization_result for column 234\n",
      "[2016-12-11 00:51:04.874000] get_optimization_result for column 235\n",
      "[2016-12-11 00:51:05.696000] get_optimization_result for column 236\n",
      "[2016-12-11 00:51:06.177000] get_optimization_result for column 237\n",
      "[2016-12-11 00:51:06.512000] get_optimization_result for column 238\n",
      "[2016-12-11 00:51:06.897000] get_optimization_result for column 239\n",
      "[2016-12-11 00:51:07.396000] get_optimization_result for column 240\n",
      "[2016-12-11 00:51:07.875000] get_optimization_result for column 241\n",
      "[2016-12-11 00:51:08.226000] get_optimization_result for column 242\n",
      "[2016-12-11 00:51:09.152000] get_optimization_result for column 243\n",
      "[2016-12-11 00:51:09.768000] get_optimization_result for column 244\n",
      "[2016-12-11 00:51:10.202000] get_optimization_result for column 245\n",
      "[2016-12-11 00:51:10.363000] get_optimization_result for column 246\n",
      "[2016-12-11 00:51:10.568000] get_optimization_result for column 247\n",
      "[2016-12-11 00:51:11.063000] get_optimization_result for column 248\n",
      "[2016-12-11 00:51:11.472000] get_optimization_result for column 249\n",
      "[2016-12-11 00:51:11.926000] get_optimization_result for column 250\n",
      "[2016-12-11 00:51:12.451000] get_optimization_result for column 251\n",
      "[2016-12-11 00:51:12.778000] get_optimization_result for column 252\n",
      "[2016-12-11 00:51:13.095000] get_optimization_result for column 253\n",
      "[2016-12-11 00:51:13.564000] get_optimization_result for column 254\n",
      "[2016-12-11 00:51:14.481000] get_optimization_result for column 255\n",
      "[2016-12-11 00:51:14.680000] get_optimization_result for column 256\n",
      "[2016-12-11 00:51:14.811000] get_optimization_result for column 257\n",
      "[2016-12-11 00:51:15.458000] get_optimization_result for column 258\n",
      "[2016-12-11 00:51:15.935000] get_optimization_result for column 259\n",
      "[2016-12-11 00:51:16.028000] get_optimization_result for column 260\n",
      "[2016-12-11 00:51:16.399000] get_optimization_result for column 261\n",
      "[2016-12-11 00:51:16.604000] get_optimization_result for column 262\n",
      "[2016-12-11 00:51:16.921000] get_optimization_result for column 263\n",
      "[2016-12-11 00:51:17.443000] get_optimization_result for column 264\n",
      "[2016-12-11 00:51:17.813000] get_optimization_result for column 265\n",
      "[2016-12-11 00:51:18.042000] get_optimization_result for column 266\n",
      "[2016-12-11 00:51:18.454000] get_optimization_result for column 267\n",
      "[2016-12-11 00:51:18.790000] get_optimization_result for column 268\n",
      "[2016-12-11 00:51:19.306000] get_optimization_result for column 269\n",
      "[2016-12-11 00:51:20.173000] get_optimization_result for column 270\n",
      "[2016-12-11 00:51:20.800000] get_optimization_result for column 271\n",
      "[2016-12-11 00:51:22.221000] get_optimization_result for column 272\n",
      "[2016-12-11 00:51:22.525000] get_optimization_result for column 273\n",
      "[2016-12-11 00:51:22.968000] get_optimization_result for column 274\n",
      "[2016-12-11 00:51:23.241000] get_optimization_result for column 275\n",
      "[2016-12-11 00:51:23.606000] get_optimization_result for column 276\n",
      "[2016-12-11 00:51:23.795000] get_optimization_result for column 277\n",
      "[2016-12-11 00:51:24.294000] get_optimization_result for column 278\n",
      "[2016-12-11 00:51:25.054000] get_optimization_result for column 279\n",
      "[2016-12-11 00:51:25.561000] get_optimization_result for column 280\n",
      "[2016-12-11 00:51:26.024000] get_optimization_result for column 281\n",
      "[2016-12-11 00:51:26.641000] get_optimization_result for column 282\n",
      "[2016-12-11 00:51:27.030000] get_optimization_result for column 283\n",
      "[2016-12-11 00:51:27.533000] get_optimization_result for column 284\n",
      "[2016-12-11 00:51:27.817000] get_optimization_result for column 285\n",
      "[2016-12-11 00:51:28.121000] get_optimization_result for column 286\n",
      "[2016-12-11 00:51:28.484000] get_optimization_result for column 287\n",
      "[2016-12-11 00:51:28.733000] get_optimization_result for column 288\n",
      "[2016-12-11 00:51:29.063000] get_optimization_result for column 289\n",
      "[2016-12-11 00:51:29.501000] get_optimization_result for column 290\n",
      "[2016-12-11 00:51:30.013000] get_optimization_result for column 291\n",
      "[2016-12-11 00:51:30.493000] get_optimization_result for column 292\n",
      "[2016-12-11 00:51:31.136000] get_optimization_result for column 293\n",
      "[2016-12-11 00:51:31.448000] get_optimization_result for column 294\n",
      "[2016-12-11 00:51:31.997000] get_optimization_result for column 295\n",
      "[2016-12-11 00:51:32.378000] get_optimization_result for column 296\n",
      "[2016-12-11 00:51:32.835000] get_optimization_result for column 297\n",
      "[2016-12-11 00:51:33.276000] get_optimization_result for column 298\n",
      "[2016-12-11 00:51:33.707000] get_optimization_result for column 299\n",
      "[2016-12-11 00:51:34.050000] get_optimization_result for column 300\n",
      "[2016-12-11 00:51:34.666000] get_optimization_result for column 301\n",
      "[2016-12-11 00:51:35.032000] get_optimization_result for column 302\n",
      "[2016-12-11 00:51:35.275000] get_optimization_result for column 303\n",
      "[2016-12-11 00:51:35.461000] get_optimization_result for column 304\n",
      "[2016-12-11 00:51:35.777000] get_optimization_result for column 305\n",
      "[2016-12-11 00:51:36.194000] get_optimization_result for column 306\n",
      "[2016-12-11 00:51:36.606000] get_optimization_result for column 307\n",
      "[2016-12-11 00:51:36.901000] get_optimization_result for column 308\n",
      "[2016-12-11 00:51:37.459000] get_optimization_result for column 309\n",
      "[2016-12-11 00:51:37.836000] get_optimization_result for column 310\n",
      "[2016-12-11 00:51:38.251000] get_optimization_result for column 311\n",
      "[2016-12-11 00:51:38.480000] get_optimization_result for column 312\n",
      "[2016-12-11 00:51:38.563000] get_optimization_result for column 313\n",
      "[2016-12-11 00:51:38.981000] get_optimization_result for column 314\n",
      "[2016-12-11 00:51:39.338000] get_optimization_result for column 315\n",
      "[2016-12-11 00:51:39.995000] get_optimization_result for column 316\n",
      "[2016-12-11 00:51:40.334000] get_optimization_result for column 317\n",
      "[2016-12-11 00:51:40.466000] get_optimization_result for column 318\n",
      "[2016-12-11 00:51:40.847000] get_optimization_result for column 319\n",
      "[2016-12-11 00:51:41.249000] get_optimization_result for column 320\n",
      "[2016-12-11 00:51:41.896000] get_optimization_result for column 321\n",
      "[2016-12-11 00:51:43.031000] get_optimization_result for column 322\n",
      "[2016-12-11 00:51:43.930000] get_optimization_result for column 323\n",
      "[2016-12-11 00:51:44.397000] get_optimization_result for column 324\n",
      "[2016-12-11 00:51:44.844000] get_optimization_result for column 325\n",
      "[2016-12-11 00:51:45.109000] get_optimization_result for column 326\n",
      "[2016-12-11 00:51:45.371000] get_optimization_result for column 327\n",
      "[2016-12-11 00:51:45.710000] get_optimization_result for column 328\n",
      "[2016-12-11 00:51:46.278000] get_optimization_result for column 329\n",
      "[2016-12-11 00:51:46.599000] get_optimization_result for column 330\n",
      "[2016-12-11 00:51:46.851000] get_optimization_result for column 331\n",
      "[2016-12-11 00:51:47.507000] get_optimization_result for column 332\n",
      "[2016-12-11 00:51:47.981000] get_optimization_result for column 333\n",
      "[2016-12-11 00:51:48.255000] get_optimization_result for column 334\n",
      "[2016-12-11 00:51:48.669000] get_optimization_result for column 335\n",
      "[2016-12-11 00:51:49.115000] get_optimization_result for column 336\n",
      "[2016-12-11 00:51:49.600000] get_optimization_result for column 337\n",
      "[2016-12-11 00:51:50.023000] get_optimization_result for column 338\n",
      "[2016-12-11 00:51:50.662000] get_optimization_result for column 339\n",
      "[2016-12-11 00:51:50.981000] get_optimization_result for column 340\n",
      "[2016-12-11 00:51:51.616000] get_optimization_result for column 341\n",
      "[2016-12-11 00:51:51.927000] get_optimization_result for column 342\n",
      "[2016-12-11 00:51:52.159000] get_optimization_result for column 343\n",
      "[2016-12-11 00:51:52.521000] get_optimization_result for column 344\n",
      "[2016-12-11 00:51:53.084000] get_optimization_result for column 345\n",
      "[2016-12-11 00:51:53.503000] get_optimization_result for column 346\n",
      "[2016-12-11 00:51:53.892000] get_optimization_result for column 347\n",
      "[2016-12-11 00:51:54.393000] get_optimization_result for column 348\n",
      "[2016-12-11 00:51:54.749000] get_optimization_result for column 349\n",
      "[2016-12-11 00:51:56.459000] get_optimization_result for column 350\n",
      "[2016-12-11 00:51:56.746000] get_optimization_result for column 351\n",
      "[2016-12-11 00:51:57.014000] get_optimization_result for column 352\n",
      "[2016-12-11 00:51:57.965000] get_optimization_result for column 353\n",
      "[2016-12-11 00:51:58.423000] get_optimization_result for column 354\n",
      "[2016-12-11 00:51:58.689000] get_optimization_result for column 355\n",
      "[2016-12-11 00:51:58.969000] get_optimization_result for column 356\n",
      "[2016-12-11 00:51:59.109000] get_optimization_result for column 357\n",
      "[2016-12-11 00:51:59.554000] get_optimization_result for column 358\n",
      "[2016-12-11 00:51:59.879000] get_optimization_result for column 359\n",
      "[2016-12-11 00:52:00.206000] get_optimization_result for column 360\n",
      "[2016-12-11 00:52:00.437000] get_optimization_result for column 361\n",
      "[2016-12-11 00:52:01.079000] get_optimization_result for column 362\n",
      "[2016-12-11 00:52:01.625000] get_optimization_result for column 363\n",
      "[2016-12-11 00:52:02.509000] get_optimization_result for column 364\n",
      "[2016-12-11 00:52:02.944000] get_optimization_result for column 365\n",
      "[2016-12-11 00:52:03.309000] get_optimization_result for column 366\n",
      "[2016-12-11 00:52:03.825000] get_optimization_result for column 367\n",
      "[2016-12-11 00:52:04.231000] get_optimization_result for column 368\n",
      "[2016-12-11 00:52:04.526000] get_optimization_result for column 369\n",
      "[2016-12-11 00:52:04.702000] get_optimization_result for column 370\n",
      "[2016-12-11 00:52:04.987000] get_optimization_result for column 371\n",
      "[2016-12-11 00:52:05.233000] get_optimization_result for column 372\n",
      "[2016-12-11 00:52:05.479000] get_optimization_result for column 373\n",
      "[2016-12-11 00:52:06.063000] get_optimization_result for column 374\n",
      "[2016-12-11 00:52:06.795000] get_optimization_result for column 375\n",
      "[2016-12-11 00:52:07.074000] get_optimization_result for column 376\n",
      "[2016-12-11 00:52:07.515000] get_optimization_result for column 377\n",
      "[2016-12-11 00:52:07.881000] get_optimization_result for column 378\n",
      "[2016-12-11 00:52:08.648000] get_optimization_result for column 379\n",
      "[2016-12-11 00:52:09.289000] get_optimization_result for column 380\n",
      "[2016-12-11 00:52:09.694000] get_optimization_result for column 381\n",
      "[2016-12-11 00:52:09.971000] get_optimization_result for column 382\n",
      "[2016-12-11 00:52:10.465000] get_optimization_result for column 383\n",
      "[2016-12-11 00:52:10.791000] get_optimization_result for column 384\n",
      "[2016-12-11 00:52:11.345000] get_optimization_result for column 385\n",
      "[2016-12-11 00:52:11.745000] get_optimization_result for column 386\n",
      "[2016-12-11 00:52:12.231000] get_optimization_result for column 387\n",
      "[2016-12-11 00:52:12.767000] get_optimization_result for column 388\n",
      "[2016-12-11 00:52:12.988000] get_optimization_result for column 389\n",
      "[2016-12-11 00:52:13.825000] get_optimization_result for column 390\n",
      "[2016-12-11 00:52:14.234000] get_optimization_result for column 391\n",
      "[2016-12-11 00:52:14.742000] get_optimization_result for column 392\n",
      "[2016-12-11 00:52:15.173000] get_optimization_result for column 393\n",
      "[2016-12-11 00:52:15.559000] get_optimization_result for column 394\n",
      "[2016-12-11 00:52:15.852000] get_optimization_result for column 395\n",
      "[2016-12-11 00:52:16.229000] get_optimization_result for column 396\n",
      "[2016-12-11 00:52:16.354000] get_optimization_result for column 397\n",
      "[2016-12-11 00:52:16.587000] get_optimization_result for column 398\n",
      "[2016-12-11 00:52:17.178000] get_optimization_result for column 399\n",
      "[2016-12-11 00:52:17.670000] get_optimization_result for column 400\n",
      "[2016-12-11 00:52:18.500000] get_optimization_result for column 401\n",
      "[2016-12-11 00:52:18.890000] get_optimization_result for column 402\n",
      "[2016-12-11 00:52:19.304000] get_optimization_result for column 403\n",
      "[2016-12-11 00:52:19.778000] get_optimization_result for column 404\n",
      "[2016-12-11 00:52:20.506000] get_optimization_result for column 405\n",
      "[2016-12-11 00:52:20.784000] get_optimization_result for column 406\n",
      "[2016-12-11 00:52:21.142000] get_optimization_result for column 407\n",
      "[2016-12-11 00:52:21.503000] get_optimization_result for column 408\n",
      "[2016-12-11 00:52:21.927000] get_optimization_result for column 409\n",
      "[2016-12-11 00:52:22.185000] get_optimization_result for column 410\n",
      "[2016-12-11 00:52:22.763000] get_optimization_result for column 411\n",
      "[2016-12-11 00:52:22.931000] get_optimization_result for column 412\n",
      "[2016-12-11 00:52:23.162000] get_optimization_result for column 413\n",
      "[2016-12-11 00:52:23.536000] get_optimization_result for column 414\n",
      "[2016-12-11 00:52:23.899000] get_optimization_result for column 415\n",
      "[2016-12-11 00:52:24.179000] get_optimization_result for column 416\n",
      "[2016-12-11 00:52:24.713000] get_optimization_result for column 417\n",
      "[2016-12-11 00:52:24.963000] get_optimization_result for column 418\n",
      "[2016-12-11 00:52:25.137000] get_optimization_result for column 419\n",
      "[2016-12-11 00:52:25.493000] get_optimization_result for column 420\n",
      "[2016-12-11 00:52:25.948000] get_optimization_result for column 421\n",
      "[2016-12-11 00:52:26.383000] get_optimization_result for column 422\n",
      "[2016-12-11 00:52:26.566000] get_optimization_result for column 423\n",
      "[2016-12-11 00:52:27.048000] get_optimization_result for column 424\n",
      "[2016-12-11 00:52:27.775000] get_optimization_result for column 425\n",
      "[2016-12-11 00:52:28.228000] get_optimization_result for column 426\n",
      "[2016-12-11 00:52:28.635000] get_optimization_result for column 427\n",
      "[2016-12-11 00:52:29.040000] get_optimization_result for column 428\n",
      "[2016-12-11 00:52:29.485000] get_optimization_result for column 429\n",
      "[2016-12-11 00:52:30.080000] get_optimization_result for column 430\n",
      "[2016-12-11 00:52:30.281000] get_optimization_result for column 431\n",
      "[2016-12-11 00:52:30.772000] get_optimization_result for column 432\n",
      "[2016-12-11 00:52:31.095000] get_optimization_result for column 433\n",
      "[2016-12-11 00:52:31.541000] get_optimization_result for column 434\n",
      "[2016-12-11 00:52:31.873000] get_optimization_result for column 435\n",
      "[2016-12-11 00:52:32.217000] get_optimization_result for column 436\n",
      "[2016-12-11 00:52:32.382000] get_optimization_result for column 437\n",
      "[2016-12-11 00:52:32.581000] get_optimization_result for column 438\n",
      "[2016-12-11 00:52:32.997000] get_optimization_result for column 439\n",
      "[2016-12-11 00:52:33.316000] get_optimization_result for column 440\n",
      "[2016-12-11 00:52:34.150000] get_optimization_result for column 441\n",
      "[2016-12-11 00:52:34.536000] get_optimization_result for column 442\n",
      "[2016-12-11 00:52:34.774000] get_optimization_result for column 443\n",
      "[2016-12-11 00:52:35.019000] get_optimization_result for column 444\n",
      "[2016-12-11 00:52:35.530000] get_optimization_result for column 445\n",
      "[2016-12-11 00:52:35.838000] get_optimization_result for column 446\n",
      "[2016-12-11 00:52:36.371000] get_optimization_result for column 447\n",
      "[2016-12-11 00:52:36.744000] get_optimization_result for column 448\n",
      "[2016-12-11 00:52:37.070000] get_optimization_result for column 449\n",
      "[2016-12-11 00:52:37.408000] get_optimization_result for column 450\n",
      "[2016-12-11 00:52:38.283000] get_optimization_result for column 451\n",
      "[2016-12-11 00:52:38.471000] get_optimization_result for column 452\n",
      "[2016-12-11 00:52:38.895000] get_optimization_result for column 453\n",
      "[2016-12-11 00:52:39.152000] get_optimization_result for column 454\n",
      "[2016-12-11 00:52:39.637000] get_optimization_result for column 455\n",
      "[2016-12-11 00:52:40.204000] get_optimization_result for column 456\n",
      "[2016-12-11 00:52:40.559000] get_optimization_result for column 457\n",
      "[2016-12-11 00:52:40.816000] get_optimization_result for column 458\n",
      "[2016-12-11 00:52:40.982000] get_optimization_result for column 459\n",
      "[2016-12-11 00:52:41.207000] get_optimization_result for column 460\n",
      "[2016-12-11 00:52:41.419000] get_optimization_result for column 461\n",
      "[2016-12-11 00:52:41.718000] get_optimization_result for column 462\n",
      "[2016-12-11 00:52:42.061000] get_optimization_result for column 463\n",
      "[2016-12-11 00:52:42.350000] get_optimization_result for column 464\n",
      "[2016-12-11 00:52:42.729000] get_optimization_result for column 465\n",
      "[2016-12-11 00:52:43.538000] get_optimization_result for column 466\n",
      "[2016-12-11 00:52:44.240000] get_optimization_result for column 467\n",
      "[2016-12-11 00:52:44.585000] get_optimization_result for column 468\n",
      "[2016-12-11 00:52:45.409000] get_optimization_result for column 469\n",
      "[2016-12-11 00:52:46.071000] get_optimization_result for column 470\n",
      "[2016-12-11 00:52:46.511000] get_optimization_result for column 471\n",
      "[2016-12-11 00:52:46.811000] get_optimization_result for column 472\n",
      "[2016-12-11 00:52:47.139000] get_optimization_result for column 473\n",
      "[2016-12-11 00:52:47.514000] get_optimization_result for column 474\n",
      "[2016-12-11 00:52:47.905000] get_optimization_result for column 475\n",
      "[2016-12-11 00:52:48.672000] get_optimization_result for column 476\n",
      "[2016-12-11 00:52:49.294000] get_optimization_result for column 477\n",
      "[2016-12-11 00:52:49.724000] get_optimization_result for column 478\n",
      "[2016-12-11 00:52:50.161000] get_optimization_result for column 479\n",
      "[2016-12-11 00:52:50.564000] get_optimization_result for column 480\n",
      "[2016-12-11 00:52:50.784000] get_optimization_result for column 481\n",
      "[2016-12-11 00:52:51.310000] get_optimization_result for column 482\n",
      "[2016-12-11 00:52:51.563000] get_optimization_result for column 483\n",
      "[2016-12-11 00:52:52.211000] get_optimization_result for column 484\n"
     ]
    }
   ],
   "source": [
    "ds2 = get_optimization_result(hellinger_dist, None, phi_convex_hull, distances_convex_hull)\n",
    "ds = ds2\n",
    "save_pickle_file(ds, 'dists_h_none2.p')\n",
    "fs = [ds[col].fun for col in phi_convex_hull.columns]\n",
    "sns.distplot(fs, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 8\n",
      "topics to remove =  9\n",
      "topic_57: кварк адрон элементарный_частица протон нейтрон частица суперсимметрия мезон свойство электрический_заряд глюон\n",
      "topic_355: планет звезда экзопланета планета зона_обитаемость телескоп жизнь экзопланет кеплер спутник способ\n",
      "topic_278: белка белок клетка приона цитоплазма домен шаперон агрегат состояние фибрилла дрожжи\n",
      "topic_439: детектор тёмный_материя эксперимент антенна скрытый_масса результат излучение энергия сигнал событие бак\n",
      "topic_92: фильм кино зритель экран просмотр смех реплика высказывание погружение эйзенштейн участие\n",
      "topic_358: мутация признак вид отбор геном замена ген изменение естественный_отбор генотип популяция\n",
      "topic_83: рынок правительство рубль цена валюта актив политика государственный_долг центральный_банк доллар инвестор\n",
      "topic_475: обезьяна шимпанзе коммуникативный_система онтогенез синтаксис сородич способность гоминид происхождение_язык сантиметр качество\n",
      "topic_3: работа автор статья исследование тема монография издание труд изучение материал редактор\n"
     ]
    }
   ],
   "source": [
    "low_th, high_th = 0.76, 0.89\n",
    "topics_to_remove_by_closest_dist = find_topics_to_remove(ds,  phi_convex_hull, distances_convex_hull, low_th, high_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phi_convex_hull = remove_topics_from_phi(phi_convex_hull, topics_to_remove_by_closest_dist)\n",
    "distances_convex_hull = remove_topics_from_distances(distances_convex_hull, topics_to_remove_by_closest_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iteration = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016-12-11 00:57:49.218000] get_optimization_result for column 0\n",
      "[2016-12-11 00:57:49.840000] get_optimization_result for column 1\n",
      "[2016-12-11 00:57:50.233000] get_optimization_result for column 2\n",
      "[2016-12-11 00:57:50.500000] get_optimization_result for column 3\n",
      "[2016-12-11 00:57:50.969000] get_optimization_result for column 4\n",
      "[2016-12-11 00:57:51.263000] get_optimization_result for column 5\n",
      "[2016-12-11 00:57:51.586000] get_optimization_result for column 6\n",
      "[2016-12-11 00:57:51.941000] get_optimization_result for column 7\n",
      "[2016-12-11 00:57:52.421000] get_optimization_result for column 8\n",
      "[2016-12-11 00:57:52.799000] get_optimization_result for column 9\n",
      "[2016-12-11 00:57:53.323000] get_optimization_result for column 10\n",
      "[2016-12-11 00:57:53.519000] get_optimization_result for column 11\n",
      "[2016-12-11 00:57:54.463000] get_optimization_result for column 12\n",
      "[2016-12-11 00:57:55.475000] get_optimization_result for column 13\n",
      "[2016-12-11 00:57:55.799000] get_optimization_result for column 14\n",
      "[2016-12-11 00:57:56.122000] get_optimization_result for column 15\n",
      "[2016-12-11 00:57:56.306000] get_optimization_result for column 16\n",
      "[2016-12-11 00:57:56.572000] get_optimization_result for column 17\n",
      "[2016-12-11 00:57:57.173000] get_optimization_result for column 18\n",
      "[2016-12-11 00:57:57.481000] get_optimization_result for column 19\n",
      "[2016-12-11 00:57:57.626000] get_optimization_result for column 20\n",
      "[2016-12-11 00:57:58.674000] get_optimization_result for column 21\n",
      "[2016-12-11 00:57:59.010000] get_optimization_result for column 22\n",
      "[2016-12-11 00:57:59.484000] get_optimization_result for column 23\n",
      "[2016-12-11 00:57:59.800000] get_optimization_result for column 24\n",
      "[2016-12-11 00:58:00.235000] get_optimization_result for column 25\n",
      "[2016-12-11 00:58:00.863000] get_optimization_result for column 26\n",
      "[2016-12-11 00:58:01.433000] get_optimization_result for column 27\n",
      "[2016-12-11 00:58:01.833000] get_optimization_result for column 28\n",
      "[2016-12-11 00:58:02.210000] get_optimization_result for column 29\n",
      "[2016-12-11 00:58:02.609000] get_optimization_result for column 30\n",
      "[2016-12-11 00:58:02.819000] get_optimization_result for column 31\n",
      "[2016-12-11 00:58:03.176000] get_optimization_result for column 32\n",
      "[2016-12-11 00:58:04.015000] get_optimization_result for column 33\n",
      "[2016-12-11 00:58:04.561000] get_optimization_result for column 34\n",
      "[2016-12-11 00:58:04.919000] get_optimization_result for column 35\n",
      "[2016-12-11 00:58:05.721000] get_optimization_result for column 36\n",
      "[2016-12-11 00:58:06.352000] get_optimization_result for column 37\n",
      "[2016-12-11 00:58:06.680000] get_optimization_result for column 38\n",
      "[2016-12-11 00:58:07.102000] get_optimization_result for column 39\n",
      "[2016-12-11 00:58:07.330000] get_optimization_result for column 40\n",
      "[2016-12-11 00:58:07.538000] get_optimization_result for column 41\n",
      "[2016-12-11 00:58:08.228000] get_optimization_result for column 42\n",
      "[2016-12-11 00:58:08.458000] get_optimization_result for column 43\n",
      "[2016-12-11 00:58:08.740000] get_optimization_result for column 44\n",
      "[2016-12-11 00:58:09.124000] get_optimization_result for column 45\n",
      "[2016-12-11 00:58:09.427000] get_optimization_result for column 46\n",
      "[2016-12-11 00:58:09.492000] get_optimization_result for column 47\n",
      "[2016-12-11 00:58:09.973000] get_optimization_result for column 48\n",
      "[2016-12-11 00:58:10.369000] get_optimization_result for column 49\n",
      "[2016-12-11 00:58:11.006000] get_optimization_result for column 50\n",
      "[2016-12-11 00:58:11.366000] get_optimization_result for column 51\n",
      "[2016-12-11 00:58:11.553000] get_optimization_result for column 52\n",
      "[2016-12-11 00:58:11.857000] get_optimization_result for column 53\n",
      "[2016-12-11 00:58:12.722000] get_optimization_result for column 54\n",
      "[2016-12-11 00:58:12.882000] get_optimization_result for column 55\n",
      "[2016-12-11 00:58:13.630000] get_optimization_result for column 56\n",
      "[2016-12-11 00:58:13.973000] get_optimization_result for column 57\n",
      "[2016-12-11 00:58:14.291000] get_optimization_result for column 58\n",
      "[2016-12-11 00:58:14.706000] get_optimization_result for column 59\n",
      "[2016-12-11 00:58:14.972000] get_optimization_result for column 60\n",
      "[2016-12-11 00:58:15.268000] get_optimization_result for column 61\n",
      "[2016-12-11 00:58:15.882000] get_optimization_result for column 62\n",
      "[2016-12-11 00:58:16.293000] get_optimization_result for column 63\n",
      "[2016-12-11 00:58:16.732000] get_optimization_result for column 64\n",
      "[2016-12-11 00:58:17.302000] get_optimization_result for column 65\n",
      "[2016-12-11 00:58:17.635000] get_optimization_result for column 66\n",
      "[2016-12-11 00:58:17.988000] get_optimization_result for column 67\n",
      "[2016-12-11 00:58:18.289000] get_optimization_result for column 68\n",
      "[2016-12-11 00:58:18.854000] get_optimization_result for column 69\n",
      "[2016-12-11 00:58:19.377000] get_optimization_result for column 70\n",
      "[2016-12-11 00:58:20.415000] get_optimization_result for column 71\n",
      "[2016-12-11 00:58:20.669000] get_optimization_result for column 72\n",
      "[2016-12-11 00:58:21.307000] get_optimization_result for column 73\n",
      "[2016-12-11 00:58:21.519000] get_optimization_result for column 74\n",
      "[2016-12-11 00:58:21.999000] get_optimization_result for column 75\n",
      "[2016-12-11 00:58:22.318000] get_optimization_result for column 76\n",
      "[2016-12-11 00:58:22.995000] get_optimization_result for column 77\n",
      "[2016-12-11 00:58:23.387000] get_optimization_result for column 78\n",
      "[2016-12-11 00:58:24.079000] get_optimization_result for column 79\n",
      "[2016-12-11 00:58:25.076000] get_optimization_result for column 80\n",
      "[2016-12-11 00:58:25.564000] get_optimization_result for column 81\n",
      "[2016-12-11 00:58:25.902000] get_optimization_result for column 82\n",
      "[2016-12-11 00:58:26.037000] get_optimization_result for column 83\n",
      "[2016-12-11 00:58:26.198000] get_optimization_result for column 84\n",
      "[2016-12-11 00:58:26.598000] get_optimization_result for column 85\n",
      "[2016-12-11 00:58:27.104000] get_optimization_result for column 86\n",
      "[2016-12-11 00:58:27.410000] get_optimization_result for column 87\n",
      "[2016-12-11 00:58:27.597000] get_optimization_result for column 88\n",
      "[2016-12-11 00:58:28.275000] get_optimization_result for column 89\n",
      "[2016-12-11 00:58:29.469000] get_optimization_result for column 90\n",
      "[2016-12-11 00:58:30.208000] get_optimization_result for column 91\n",
      "[2016-12-11 00:58:30.493000] get_optimization_result for column 92\n",
      "[2016-12-11 00:58:31.110000] get_optimization_result for column 93\n",
      "[2016-12-11 00:58:31.452000] get_optimization_result for column 94\n",
      "[2016-12-11 00:58:31.741000] get_optimization_result for column 95\n",
      "[2016-12-11 00:58:32.778000] get_optimization_result for column 96\n",
      "[2016-12-11 00:58:33.063000] get_optimization_result for column 97\n",
      "[2016-12-11 00:58:33.687000] get_optimization_result for column 98\n",
      "[2016-12-11 00:58:34.159000] get_optimization_result for column 99\n",
      "[2016-12-11 00:58:34.624000] get_optimization_result for column 100\n",
      "[2016-12-11 00:58:34.786000] get_optimization_result for column 101\n",
      "[2016-12-11 00:58:35.065000] get_optimization_result for column 102\n",
      "[2016-12-11 00:58:35.465000] get_optimization_result for column 103\n",
      "[2016-12-11 00:58:35.823000] get_optimization_result for column 104\n",
      "[2016-12-11 00:58:36.045000] get_optimization_result for column 105\n",
      "[2016-12-11 00:58:36.518000] get_optimization_result for column 106\n",
      "[2016-12-11 00:58:36.730000] get_optimization_result for column 107\n",
      "[2016-12-11 00:58:37.095000] get_optimization_result for column 108\n",
      "[2016-12-11 00:58:37.442000] get_optimization_result for column 109\n",
      "[2016-12-11 00:58:37.901000] get_optimization_result for column 110\n",
      "[2016-12-11 00:58:38.105000] get_optimization_result for column 111\n",
      "[2016-12-11 00:58:38.721000] get_optimization_result for column 112\n",
      "[2016-12-11 00:58:39.464000] get_optimization_result for column 113\n",
      "[2016-12-11 00:58:39.969000] get_optimization_result for column 114\n",
      "[2016-12-11 00:58:40.414000] get_optimization_result for column 115\n",
      "[2016-12-11 00:58:40.778000] get_optimization_result for column 116\n",
      "[2016-12-11 00:58:41.114000] get_optimization_result for column 117\n",
      "[2016-12-11 00:58:41.294000] get_optimization_result for column 118\n",
      "[2016-12-11 00:58:41.601000] get_optimization_result for column 119\n",
      "[2016-12-11 00:58:41.962000] get_optimization_result for column 120\n",
      "[2016-12-11 00:58:42.711000] get_optimization_result for column 121\n",
      "[2016-12-11 00:58:43.081000] get_optimization_result for column 122\n",
      "[2016-12-11 00:58:43.351000] get_optimization_result for column 123\n",
      "[2016-12-11 00:58:44.052000] get_optimization_result for column 124\n",
      "[2016-12-11 00:58:44.475000] get_optimization_result for column 125\n",
      "[2016-12-11 00:58:45.178000] get_optimization_result for column 126\n",
      "[2016-12-11 00:58:45.801000] get_optimization_result for column 127\n",
      "[2016-12-11 00:58:46.121000] get_optimization_result for column 128\n",
      "[2016-12-11 00:58:47.273000] get_optimization_result for column 129\n",
      "[2016-12-11 00:58:48.184000] get_optimization_result for column 130\n",
      "[2016-12-11 00:58:48.493000] get_optimization_result for column 131\n",
      "[2016-12-11 00:58:48.812000] get_optimization_result for column 132\n",
      "[2016-12-11 00:58:48.904000] get_optimization_result for column 133\n",
      "[2016-12-11 00:58:49.444000] get_optimization_result for column 134\n",
      "[2016-12-11 00:58:49.680000] get_optimization_result for column 135\n",
      "[2016-12-11 00:58:49.907000] get_optimization_result for column 136\n",
      "[2016-12-11 00:58:50.577000] get_optimization_result for column 137\n",
      "[2016-12-11 00:58:50.996000] get_optimization_result for column 138\n",
      "[2016-12-11 00:58:51.304000] get_optimization_result for column 139\n",
      "[2016-12-11 00:58:51.736000] get_optimization_result for column 140\n",
      "[2016-12-11 00:58:52.014000] get_optimization_result for column 141\n",
      "[2016-12-11 00:58:52.296000] get_optimization_result for column 142\n",
      "[2016-12-11 00:58:52.684000] get_optimization_result for column 143\n",
      "[2016-12-11 00:58:53.502000] get_optimization_result for column 144\n",
      "[2016-12-11 00:58:53.716000] get_optimization_result for column 145\n",
      "[2016-12-11 00:58:54.243000] get_optimization_result for column 146\n",
      "[2016-12-11 00:58:54.523000] get_optimization_result for column 147\n",
      "[2016-12-11 00:58:54.787000] get_optimization_result for column 148\n",
      "[2016-12-11 00:58:55.261000] get_optimization_result for column 149\n",
      "[2016-12-11 00:58:55.625000] get_optimization_result for column 150\n",
      "[2016-12-11 00:58:56.157000] get_optimization_result for column 151\n",
      "[2016-12-11 00:58:56.579000] get_optimization_result for column 152\n",
      "[2016-12-11 00:58:57.088000] get_optimization_result for column 153\n",
      "[2016-12-11 00:58:57.532000] get_optimization_result for column 154\n",
      "[2016-12-11 00:58:58.088000] get_optimization_result for column 155\n",
      "[2016-12-11 00:58:58.234000] get_optimization_result for column 156\n",
      "[2016-12-11 00:58:58.541000] get_optimization_result for column 157\n",
      "[2016-12-11 00:58:59.275000] get_optimization_result for column 158\n",
      "[2016-12-11 00:58:59.517000] get_optimization_result for column 159\n",
      "[2016-12-11 00:58:59.936000] get_optimization_result for column 160\n",
      "[2016-12-11 00:59:00.257000] get_optimization_result for column 161\n",
      "[2016-12-11 00:59:00.565000] get_optimization_result for column 162\n",
      "[2016-12-11 00:59:01.363000] get_optimization_result for column 163\n",
      "[2016-12-11 00:59:01.705000] get_optimization_result for column 164\n",
      "[2016-12-11 00:59:02.024000] get_optimization_result for column 165\n",
      "[2016-12-11 00:59:02.200000] get_optimization_result for column 166\n",
      "[2016-12-11 00:59:02.420000] get_optimization_result for column 167\n",
      "[2016-12-11 00:59:02.751000] get_optimization_result for column 168\n",
      "[2016-12-11 00:59:03.068000] get_optimization_result for column 169\n",
      "[2016-12-11 00:59:03.452000] get_optimization_result for column 170\n",
      "[2016-12-11 00:59:03.862000] get_optimization_result for column 171\n",
      "[2016-12-11 00:59:04.237000] get_optimization_result for column 172\n",
      "[2016-12-11 00:59:04.501000] get_optimization_result for column 173\n",
      "[2016-12-11 00:59:05.123000] get_optimization_result for column 174\n",
      "[2016-12-11 00:59:05.594000] get_optimization_result for column 175\n",
      "[2016-12-11 00:59:06.026000] get_optimization_result for column 176\n",
      "[2016-12-11 00:59:06.511000] get_optimization_result for column 177\n",
      "[2016-12-11 00:59:06.870000] get_optimization_result for column 178\n",
      "[2016-12-11 00:59:07.290000] get_optimization_result for column 179\n",
      "[2016-12-11 00:59:07.682000] get_optimization_result for column 180\n",
      "[2016-12-11 00:59:08.019000] get_optimization_result for column 181\n",
      "[2016-12-11 00:59:08.304000] get_optimization_result for column 182\n",
      "[2016-12-11 00:59:08.753000] get_optimization_result for column 183\n",
      "[2016-12-11 00:59:09.026000] get_optimization_result for column 184\n",
      "[2016-12-11 00:59:09.539000] get_optimization_result for column 185\n",
      "[2016-12-11 00:59:09.859000] get_optimization_result for column 186\n",
      "[2016-12-11 00:59:10.167000] get_optimization_result for column 187\n",
      "[2016-12-11 00:59:10.457000] get_optimization_result for column 188\n",
      "[2016-12-11 00:59:10.844000] get_optimization_result for column 189\n",
      "[2016-12-11 00:59:11.226000] get_optimization_result for column 190\n",
      "[2016-12-11 00:59:11.619000] get_optimization_result for column 191\n",
      "[2016-12-11 00:59:12.234000] get_optimization_result for column 192\n",
      "[2016-12-11 00:59:12.497000] get_optimization_result for column 193\n",
      "[2016-12-11 00:59:12.908000] get_optimization_result for column 194\n",
      "[2016-12-11 00:59:13.183000] get_optimization_result for column 195\n",
      "[2016-12-11 00:59:13.375000] get_optimization_result for column 196\n",
      "[2016-12-11 00:59:13.576000] get_optimization_result for column 197\n",
      "[2016-12-11 00:59:14.146000] get_optimization_result for column 198\n",
      "[2016-12-11 00:59:14.419000] get_optimization_result for column 199\n",
      "[2016-12-11 00:59:14.830000] get_optimization_result for column 200\n",
      "[2016-12-11 00:59:14.965000] get_optimization_result for column 201\n",
      "[2016-12-11 00:59:15.226000] get_optimization_result for column 202\n",
      "[2016-12-11 00:59:15.747000] get_optimization_result for column 203\n",
      "[2016-12-11 00:59:16.534000] get_optimization_result for column 204\n",
      "[2016-12-11 00:59:16.895000] get_optimization_result for column 205\n",
      "[2016-12-11 00:59:17.243000] get_optimization_result for column 206\n",
      "[2016-12-11 00:59:17.772000] get_optimization_result for column 207\n",
      "[2016-12-11 00:59:18.384000] get_optimization_result for column 208\n",
      "[2016-12-11 00:59:19.035000] get_optimization_result for column 209\n",
      "[2016-12-11 00:59:19.383000] get_optimization_result for column 210\n",
      "[2016-12-11 00:59:19.840000] get_optimization_result for column 211\n",
      "[2016-12-11 00:59:20.164000] get_optimization_result for column 212\n",
      "[2016-12-11 00:59:20.545000] get_optimization_result for column 213\n",
      "[2016-12-11 00:59:20.974000] get_optimization_result for column 214\n",
      "[2016-12-11 00:59:21.472000] get_optimization_result for column 215\n",
      "[2016-12-11 00:59:21.772000] get_optimization_result for column 216\n",
      "[2016-12-11 00:59:22.290000] get_optimization_result for column 217\n",
      "[2016-12-11 00:59:22.722000] get_optimization_result for column 218\n",
      "[2016-12-11 00:59:22.788000] get_optimization_result for column 219\n",
      "[2016-12-11 00:59:22.900000] get_optimization_result for column 220\n",
      "[2016-12-11 00:59:22.975000] get_optimization_result for column 221\n",
      "[2016-12-11 00:59:23.485000] get_optimization_result for column 222\n",
      "[2016-12-11 00:59:23.895000] get_optimization_result for column 223\n",
      "[2016-12-11 00:59:24.358000] get_optimization_result for column 224\n",
      "[2016-12-11 00:59:24.573000] get_optimization_result for column 225\n",
      "[2016-12-11 00:59:24.934000] get_optimization_result for column 226\n",
      "[2016-12-11 00:59:25.483000] get_optimization_result for column 227\n",
      "[2016-12-11 00:59:26.033000] get_optimization_result for column 228\n",
      "[2016-12-11 00:59:26.415000] get_optimization_result for column 229\n",
      "[2016-12-11 00:59:26.912000] get_optimization_result for column 230\n",
      "[2016-12-11 00:59:27.227000] get_optimization_result for column 231\n",
      "[2016-12-11 00:59:27.357000] get_optimization_result for column 232\n",
      "[2016-12-11 00:59:27.895000] get_optimization_result for column 233\n",
      "[2016-12-11 00:59:28.169000] get_optimization_result for column 234\n",
      "[2016-12-11 00:59:28.528000] get_optimization_result for column 235\n",
      "[2016-12-11 00:59:28.689000] get_optimization_result for column 236\n",
      "[2016-12-11 00:59:29.037000] get_optimization_result for column 237\n",
      "[2016-12-11 00:59:29.737000] get_optimization_result for column 238\n",
      "[2016-12-11 00:59:30.265000] get_optimization_result for column 239\n",
      "[2016-12-11 00:59:30.583000] get_optimization_result for column 240\n",
      "[2016-12-11 00:59:31.073000] get_optimization_result for column 241\n",
      "[2016-12-11 00:59:31.301000] get_optimization_result for column 242\n",
      "[2016-12-11 00:59:31.941000] get_optimization_result for column 243\n",
      "[2016-12-11 00:59:32.571000] get_optimization_result for column 244\n",
      "[2016-12-11 00:59:33.163000] get_optimization_result for column 245\n",
      "[2016-12-11 00:59:33.360000] get_optimization_result for column 246\n",
      "[2016-12-11 00:59:33.889000] get_optimization_result for column 247\n",
      "[2016-12-11 00:59:34.347000] get_optimization_result for column 248\n",
      "[2016-12-11 00:59:34.543000] get_optimization_result for column 249\n",
      "[2016-12-11 00:59:35.312000] get_optimization_result for column 250\n",
      "[2016-12-11 00:59:35.708000] get_optimization_result for column 251\n",
      "[2016-12-11 00:59:36.450000] get_optimization_result for column 252\n",
      "[2016-12-11 00:59:36.998000] get_optimization_result for column 253\n",
      "[2016-12-11 00:59:37.282000] get_optimization_result for column 254\n",
      "[2016-12-11 00:59:38.100000] get_optimization_result for column 255\n",
      "[2016-12-11 00:59:38.657000] get_optimization_result for column 256\n",
      "[2016-12-11 00:59:39.046000] get_optimization_result for column 257\n",
      "[2016-12-11 00:59:39.422000] get_optimization_result for column 258\n",
      "[2016-12-11 00:59:39.996000] get_optimization_result for column 259\n",
      "[2016-12-11 00:59:40.642000] get_optimization_result for column 260\n",
      "[2016-12-11 00:59:40.853000] get_optimization_result for column 261\n",
      "[2016-12-11 00:59:41.131000] get_optimization_result for column 262\n",
      "[2016-12-11 00:59:41.460000] get_optimization_result for column 263\n",
      "[2016-12-11 00:59:41.729000] get_optimization_result for column 264\n",
      "[2016-12-11 00:59:42.275000] get_optimization_result for column 265\n",
      "[2016-12-11 00:59:42.539000] get_optimization_result for column 266\n",
      "[2016-12-11 00:59:43.033000] get_optimization_result for column 267\n",
      "[2016-12-11 00:59:43.293000] get_optimization_result for column 268\n",
      "[2016-12-11 00:59:43.667000] get_optimization_result for column 269\n",
      "[2016-12-11 00:59:43.904000] get_optimization_result for column 270\n",
      "[2016-12-11 00:59:44.244000] get_optimization_result for column 271\n",
      "[2016-12-11 00:59:44.876000] get_optimization_result for column 272\n",
      "[2016-12-11 00:59:45.390000] get_optimization_result for column 273\n",
      "[2016-12-11 00:59:45.698000] get_optimization_result for column 274\n",
      "[2016-12-11 00:59:46.310000] get_optimization_result for column 275\n",
      "[2016-12-11 00:59:46.784000] get_optimization_result for column 276\n",
      "[2016-12-11 00:59:47.219000] get_optimization_result for column 277\n",
      "[2016-12-11 00:59:47.572000] get_optimization_result for column 278\n",
      "[2016-12-11 00:59:48.090000] get_optimization_result for column 279\n",
      "[2016-12-11 00:59:48.542000] get_optimization_result for column 280\n",
      "[2016-12-11 00:59:48.891000] get_optimization_result for column 281\n",
      "[2016-12-11 00:59:49.321000] get_optimization_result for column 282\n",
      "[2016-12-11 00:59:49.584000] get_optimization_result for column 283\n",
      "[2016-12-11 00:59:49.812000] get_optimization_result for column 284\n",
      "[2016-12-11 00:59:50.269000] get_optimization_result for column 285\n",
      "[2016-12-11 00:59:50.425000] get_optimization_result for column 286\n",
      "[2016-12-11 00:59:50.880000] get_optimization_result for column 287\n",
      "[2016-12-11 00:59:51.231000] get_optimization_result for column 288\n",
      "[2016-12-11 00:59:51.524000] get_optimization_result for column 289\n",
      "[2016-12-11 00:59:52.004000] get_optimization_result for column 290\n",
      "[2016-12-11 00:59:52.333000] get_optimization_result for column 291\n",
      "[2016-12-11 00:59:52.848000] get_optimization_result for column 292\n",
      "[2016-12-11 00:59:53.353000] get_optimization_result for column 293\n",
      "[2016-12-11 00:59:53.754000] get_optimization_result for column 294\n",
      "[2016-12-11 00:59:54.133000] get_optimization_result for column 295\n",
      "[2016-12-11 00:59:54.934000] get_optimization_result for column 296\n",
      "[2016-12-11 00:59:55.322000] get_optimization_result for column 297\n",
      "[2016-12-11 00:59:55.430000] get_optimization_result for column 298\n",
      "[2016-12-11 00:59:55.909000] get_optimization_result for column 299\n",
      "[2016-12-11 00:59:56.216000] get_optimization_result for column 300\n",
      "[2016-12-11 00:59:56.799000] get_optimization_result for column 301\n",
      "[2016-12-11 00:59:56.930000] get_optimization_result for column 302\n",
      "[2016-12-11 00:59:57.003000] get_optimization_result for column 303\n",
      "[2016-12-11 00:59:57.371000] get_optimization_result for column 304\n",
      "[2016-12-11 00:59:58.158000] get_optimization_result for column 305\n",
      "[2016-12-11 00:59:58.601000] get_optimization_result for column 306\n",
      "[2016-12-11 00:59:58.827000] get_optimization_result for column 307\n",
      "[2016-12-11 00:59:59.107000] get_optimization_result for column 308\n",
      "[2016-12-11 00:59:59.511000] get_optimization_result for column 309\n",
      "[2016-12-11 00:59:59.827000] get_optimization_result for column 310\n",
      "[2016-12-11 01:00:00.337000] get_optimization_result for column 311\n",
      "[2016-12-11 01:00:00.709000] get_optimization_result for column 312\n",
      "[2016-12-11 01:00:00.927000] get_optimization_result for column 313\n",
      "[2016-12-11 01:00:01.423000] get_optimization_result for column 314\n",
      "[2016-12-11 01:00:01.756000] get_optimization_result for column 315\n",
      "[2016-12-11 01:00:02.435000] get_optimization_result for column 316\n",
      "[2016-12-11 01:00:03.455000] get_optimization_result for column 317\n",
      "[2016-12-11 01:00:03.756000] get_optimization_result for column 318\n",
      "[2016-12-11 01:00:04.432000] get_optimization_result for column 319\n",
      "[2016-12-11 01:00:04.869000] get_optimization_result for column 320\n",
      "[2016-12-11 01:00:05.120000] get_optimization_result for column 321\n",
      "[2016-12-11 01:00:05.374000] get_optimization_result for column 322\n",
      "[2016-12-11 01:00:05.724000] get_optimization_result for column 323\n",
      "[2016-12-11 01:00:06.172000] get_optimization_result for column 324\n",
      "[2016-12-11 01:00:06.485000] get_optimization_result for column 325\n",
      "[2016-12-11 01:00:06.900000] get_optimization_result for column 326\n",
      "[2016-12-11 01:00:07.253000] get_optimization_result for column 327\n",
      "[2016-12-11 01:00:07.503000] get_optimization_result for column 328\n",
      "[2016-12-11 01:00:07.788000] get_optimization_result for column 329\n",
      "[2016-12-11 01:00:07.974000] get_optimization_result for column 330\n",
      "[2016-12-11 01:00:08.623000] get_optimization_result for column 331\n",
      "[2016-12-11 01:00:09.259000] get_optimization_result for column 332\n",
      "[2016-12-11 01:00:09.667000] get_optimization_result for column 333\n",
      "[2016-12-11 01:00:10.024000] get_optimization_result for column 334\n",
      "[2016-12-11 01:00:10.389000] get_optimization_result for column 335\n",
      "[2016-12-11 01:00:11.206000] get_optimization_result for column 336\n",
      "[2016-12-11 01:00:11.782000] get_optimization_result for column 337\n",
      "[2016-12-11 01:00:11.975000] get_optimization_result for column 338\n",
      "[2016-12-11 01:00:12.213000] get_optimization_result for column 339\n",
      "[2016-12-11 01:00:12.734000] get_optimization_result for column 340\n",
      "[2016-12-11 01:00:12.885000] get_optimization_result for column 341\n",
      "[2016-12-11 01:00:13.269000] get_optimization_result for column 342\n",
      "[2016-12-11 01:00:13.789000] get_optimization_result for column 343\n",
      "[2016-12-11 01:00:14.104000] get_optimization_result for column 344\n",
      "[2016-12-11 01:00:14.262000] get_optimization_result for column 345\n",
      "[2016-12-11 01:00:15.495000] get_optimization_result for column 346\n",
      "[2016-12-11 01:00:15.944000] get_optimization_result for column 347\n",
      "[2016-12-11 01:00:16.306000] get_optimization_result for column 348\n",
      "[2016-12-11 01:00:16.569000] get_optimization_result for column 349\n",
      "[2016-12-11 01:00:16.969000] get_optimization_result for column 350\n",
      "[2016-12-11 01:00:17.348000] get_optimization_result for column 351\n",
      "[2016-12-11 01:00:17.496000] get_optimization_result for column 352\n",
      "[2016-12-11 01:00:17.826000] get_optimization_result for column 353\n",
      "[2016-12-11 01:00:18.025000] get_optimization_result for column 354\n",
      "[2016-12-11 01:00:18.558000] get_optimization_result for column 355\n",
      "[2016-12-11 01:00:18.803000] get_optimization_result for column 356\n",
      "[2016-12-11 01:00:19.695000] get_optimization_result for column 357\n",
      "[2016-12-11 01:00:20.119000] get_optimization_result for column 358\n",
      "[2016-12-11 01:00:20.437000] get_optimization_result for column 359\n",
      "[2016-12-11 01:00:20.836000] get_optimization_result for column 360\n",
      "[2016-12-11 01:00:21.356000] get_optimization_result for column 361\n",
      "[2016-12-11 01:00:21.892000] get_optimization_result for column 362\n",
      "[2016-12-11 01:00:22.216000] get_optimization_result for column 363\n",
      "[2016-12-11 01:00:22.583000] get_optimization_result for column 364\n",
      "[2016-12-11 01:00:24.159000] get_optimization_result for column 365\n",
      "[2016-12-11 01:00:24.820000] get_optimization_result for column 366\n",
      "[2016-12-11 01:00:25.602000] get_optimization_result for column 367\n",
      "[2016-12-11 01:00:26.113000] get_optimization_result for column 368\n",
      "[2016-12-11 01:00:26.313000] get_optimization_result for column 369\n",
      "[2016-12-11 01:00:26.930000] get_optimization_result for column 370\n",
      "[2016-12-11 01:00:27.539000] get_optimization_result for column 371\n",
      "[2016-12-11 01:00:28.016000] get_optimization_result for column 372\n",
      "[2016-12-11 01:00:28.214000] get_optimization_result for column 373\n",
      "[2016-12-11 01:00:28.692000] get_optimization_result for column 374\n",
      "[2016-12-11 01:00:28.940000] get_optimization_result for column 375\n",
      "[2016-12-11 01:00:29.728000] get_optimization_result for column 376\n",
      "[2016-12-11 01:00:30.041000] get_optimization_result for column 377\n",
      "[2016-12-11 01:00:30.459000] get_optimization_result for column 378\n",
      "[2016-12-11 01:00:30.966000] get_optimization_result for column 379\n",
      "[2016-12-11 01:00:31.383000] get_optimization_result for column 380\n",
      "[2016-12-11 01:00:31.595000] get_optimization_result for column 381\n",
      "[2016-12-11 01:00:31.795000] get_optimization_result for column 382\n",
      "[2016-12-11 01:00:31.964000] get_optimization_result for column 383\n",
      "[2016-12-11 01:00:32.418000] get_optimization_result for column 384\n",
      "[2016-12-11 01:00:32.941000] get_optimization_result for column 385\n",
      "[2016-12-11 01:00:33.394000] get_optimization_result for column 386\n",
      "[2016-12-11 01:00:33.879000] get_optimization_result for column 387\n",
      "[2016-12-11 01:00:34.191000] get_optimization_result for column 388\n",
      "[2016-12-11 01:00:34.474000] get_optimization_result for column 389\n",
      "[2016-12-11 01:00:34.683000] get_optimization_result for column 390\n",
      "[2016-12-11 01:00:35.175000] get_optimization_result for column 391\n",
      "[2016-12-11 01:00:35.806000] get_optimization_result for column 392\n",
      "[2016-12-11 01:00:36.343000] get_optimization_result for column 393\n",
      "[2016-12-11 01:00:37.526000] get_optimization_result for column 394\n",
      "[2016-12-11 01:00:38.116000] get_optimization_result for column 395\n",
      "[2016-12-11 01:00:38.467000] get_optimization_result for column 396\n",
      "[2016-12-11 01:00:39.039000] get_optimization_result for column 397\n",
      "[2016-12-11 01:00:39.588000] get_optimization_result for column 398\n",
      "[2016-12-11 01:00:39.999000] get_optimization_result for column 399\n",
      "[2016-12-11 01:00:40.794000] get_optimization_result for column 400\n",
      "[2016-12-11 01:00:41.167000] get_optimization_result for column 401\n",
      "[2016-12-11 01:00:41.567000] get_optimization_result for column 402\n",
      "[2016-12-11 01:00:41.879000] get_optimization_result for column 403\n",
      "[2016-12-11 01:00:42.455000] get_optimization_result for column 404\n",
      "[2016-12-11 01:00:42.836000] get_optimization_result for column 405\n",
      "[2016-12-11 01:00:43.165000] get_optimization_result for column 406\n",
      "[2016-12-11 01:00:43.556000] get_optimization_result for column 407\n",
      "[2016-12-11 01:00:43.620000] get_optimization_result for column 408\n",
      "[2016-12-11 01:00:43.861000] get_optimization_result for column 409\n",
      "[2016-12-11 01:00:44.235000] get_optimization_result for column 410\n",
      "[2016-12-11 01:00:44.565000] get_optimization_result for column 411\n",
      "[2016-12-11 01:00:44.985000] get_optimization_result for column 412\n",
      "[2016-12-11 01:00:45.352000] get_optimization_result for column 413\n",
      "[2016-12-11 01:00:46.039000] get_optimization_result for column 414\n",
      "[2016-12-11 01:00:46.540000] get_optimization_result for column 415\n",
      "[2016-12-11 01:00:46.948000] get_optimization_result for column 416\n",
      "[2016-12-11 01:00:47.282000] get_optimization_result for column 417\n",
      "[2016-12-11 01:00:47.744000] get_optimization_result for column 418\n",
      "[2016-12-11 01:00:48.448000] get_optimization_result for column 419\n",
      "[2016-12-11 01:00:48.662000] get_optimization_result for column 420\n",
      "[2016-12-11 01:00:49.244000] get_optimization_result for column 421\n",
      "[2016-12-11 01:00:50.027000] get_optimization_result for column 422\n",
      "[2016-12-11 01:00:50.269000] get_optimization_result for column 423\n",
      "[2016-12-11 01:00:50.864000] get_optimization_result for column 424\n",
      "[2016-12-11 01:00:51.189000] get_optimization_result for column 425\n",
      "[2016-12-11 01:00:51.284000] get_optimization_result for column 426\n",
      "[2016-12-11 01:00:51.611000] get_optimization_result for column 427\n",
      "[2016-12-11 01:00:51.967000] get_optimization_result for column 428\n",
      "[2016-12-11 01:00:52.176000] get_optimization_result for column 429\n",
      "[2016-12-11 01:00:52.631000] get_optimization_result for column 430\n",
      "[2016-12-11 01:00:53.303000] get_optimization_result for column 431\n",
      "[2016-12-11 01:00:53.796000] get_optimization_result for column 432\n",
      "[2016-12-11 01:00:54.317000] get_optimization_result for column 433\n",
      "[2016-12-11 01:00:54.726000] get_optimization_result for column 434\n",
      "[2016-12-11 01:00:54.999000] get_optimization_result for column 435\n",
      "[2016-12-11 01:00:55.392000] get_optimization_result for column 436\n",
      "[2016-12-11 01:00:55.910000] get_optimization_result for column 437\n",
      "[2016-12-11 01:00:56.095000] get_optimization_result for column 438\n",
      "[2016-12-11 01:00:56.395000] get_optimization_result for column 439\n",
      "[2016-12-11 01:00:56.797000] get_optimization_result for column 440\n",
      "[2016-12-11 01:00:57.189000] get_optimization_result for column 441\n",
      "[2016-12-11 01:00:57.549000] get_optimization_result for column 442\n",
      "[2016-12-11 01:00:58.491000] get_optimization_result for column 443\n",
      "[2016-12-11 01:00:59] get_optimization_result for column 444\n",
      "[2016-12-11 01:00:59.443000] get_optimization_result for column 445\n",
      "[2016-12-11 01:00:59.824000] get_optimization_result for column 446\n",
      "[2016-12-11 01:01:00.368000] get_optimization_result for column 447\n",
      "[2016-12-11 01:01:00.872000] get_optimization_result for column 448\n",
      "[2016-12-11 01:01:01.240000] get_optimization_result for column 449\n",
      "[2016-12-11 01:01:01.379000] get_optimization_result for column 450\n",
      "[2016-12-11 01:01:01.662000] get_optimization_result for column 451\n",
      "[2016-12-11 01:01:02.710000] get_optimization_result for column 452\n",
      "[2016-12-11 01:01:03.068000] get_optimization_result for column 453\n",
      "[2016-12-11 01:01:03.375000] get_optimization_result for column 454\n",
      "[2016-12-11 01:01:03.723000] get_optimization_result for column 455\n",
      "[2016-12-11 01:01:04.068000] get_optimization_result for column 456\n",
      "[2016-12-11 01:01:04.567000] get_optimization_result for column 457\n",
      "[2016-12-11 01:01:05.033000] get_optimization_result for column 458\n",
      "[2016-12-11 01:01:05.333000] get_optimization_result for column 459\n",
      "[2016-12-11 01:01:05.659000] get_optimization_result for column 460\n",
      "[2016-12-11 01:01:06.038000] get_optimization_result for column 461\n",
      "[2016-12-11 01:01:06.443000] get_optimization_result for column 462\n",
      "[2016-12-11 01:01:06.805000] get_optimization_result for column 463\n",
      "[2016-12-11 01:01:06.986000] get_optimization_result for column 464\n",
      "[2016-12-11 01:01:07.297000] get_optimization_result for column 465\n",
      "[2016-12-11 01:01:07.609000] get_optimization_result for column 466\n",
      "[2016-12-11 01:01:08.118000] get_optimization_result for column 467\n",
      "[2016-12-11 01:01:08.868000] get_optimization_result for column 468\n",
      "[2016-12-11 01:01:09.269000] get_optimization_result for column 469\n",
      "[2016-12-11 01:01:09.741000] get_optimization_result for column 470\n",
      "[2016-12-11 01:01:10.218000] get_optimization_result for column 471\n",
      "[2016-12-11 01:01:10.526000] get_optimization_result for column 472\n",
      "[2016-12-11 01:01:11.169000] get_optimization_result for column 473\n",
      "[2016-12-11 01:01:11.330000] get_optimization_result for column 474\n",
      "[2016-12-11 01:01:11.621000] get_optimization_result for column 475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28628cc0>"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFoCAYAAADZ17inAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf0DCf+MzFYwyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3174cfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds3 = get_optimization_result(hellinger_dist, None, phi_convex_hull, distances_convex_hull)\n",
    "ds = ds3\n",
    "save_pickle_file(ds3, 'dists_h_none3.p')\n",
    "fs = [ds[col].fun for col in phi_convex_hull.columns]\n",
    "sns.distplot(fs, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 8\n",
      "topics to remove =  3\n",
      "topic_399: распад стандартный_модель вероятность антивещество кварк событие орёл бозон детектор глюон процесс\n",
      "topic_71: планета атмосфера земля венера планет нептун слой поверхность метан сатурн юпитер\n",
      "topic_359: тёмный_материя наблюдение тёмный_энергия галактика эпоха скопление_галактика линия скопление плотность красный_смещение космология\n"
     ]
    }
   ],
   "source": [
    "low_th, high_th = 0.76, 0.89\n",
    "small_dist_opts = {col: ds[col] for col in phi_convex_hull.columns if ds[col].fun < low_th}\n",
    "large_dist_opts = {col: ds[col] for col in phi_convex_hull.columns if ds[col].fun > high_th}\n",
    "print len(small_dist_opts), len(large_dist_opts)\n",
    "topics_to_remove_by_closest_dist = get_topics_to_remove_by_closest_dist(small_dist_opts, distances_convex_hull)\n",
    "print 'topics to remove = ', len(topics_to_remove_by_closest_dist)\n",
    "print '\\n'.join([unicode_list_to_str(topic_name, saved_top_tokens[topic_name][0:11]) for topic_name in topics_to_remove_by_closest_dist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phi_convex_hull = remove_topics_from_phi(phi_convex_hull, topics_to_remove_by_closest_dist)\n",
    "distances_convex_hull = remove_topics_from_distances(distances_convex_hull, topics_to_remove_by_closest_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iteration = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds4 = get_optimization_result(hellinger_dist, None, phi_convex_hull, distances_convex_hull)\n",
    "ds = ds4\n",
    "save_pickle_file(ds, 'dists_h_none4.p')\n",
    "fs = [ds[col].fun for col in phi_convex_hull.columns]\n",
    "sns.distplot(fs, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_th, high_th = 0.76, 0.89\n",
    "small_dist_opts = {col: ds[col] for col in phi_convex_hull.columns if ds[col].fun < low_th}\n",
    "large_dist_opts = {col: ds[col] for col in phi_convex_hull.columns if ds[col].fun > high_th}\n",
    "print len(small_dist_opts), len(large_dist_opts)\n",
    "topics_to_remove_by_closest_dist = get_topics_to_remove_by_closest_dist(small_dist_opts, distances_convex_hull)\n",
    "print 'topics to remove = ', len(topics_to_remove_by_closest_dist)\n",
    "print '\\n'.join([unicode_list_to_str(topic_name, saved_top_tokens[topic_name][0:11]) for topic_name in topics_to_remove_by_closest_dist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phi_convex_hull = remove_topics_from_phi(phi_convex_hull, topics_to_remove_by_closest_dist)\n",
    "distances_convex_hull = remove_topics_from_distances(distances_convex_hull, topics_to_remove_by_closest_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_file.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
